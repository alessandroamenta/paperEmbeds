title,url,abstract,content
Towards Attack-tolerant Federated Learning via Critical Parameter Analysis,http://arxiv.org/abs/2308.09318,"Federated learning is used to train a shared model in a decentralized way
without clients sharing private data with each other. Federated learning
systems are susceptible to poisoning attacks when malicious clients send false
updates to the central server. Existing defense strategies are ineffective
under non-IID data settings. This paper proposes a new defense strategy, FedCPA
(Federated learning with Critical Parameter Analysis). Our attack-tolerant
aggregation method is based on the observation that benign local models have
similar sets of top-k and bottom-k critical parameters, whereas poisoned local
models do not. Experiments with different attack scenarios on multiple datasets
demonstrate that our model outperforms existing defense strategies in defending
against poisoning attacks.","Towards Attack-tolerant Federated Learning via Critical Parameter Analysis
Sungwon Han*1Sungwon Park*1Fangzhao Wu2Sundong Kim3
Bin Zhu2Xing Xie2Meeyoung Cha4,1
1KAIST2Microsoft Research Asia3GIST4Institute for Basic Science
Abstract
Federated learning is used to train a shared model in a
decentralized way without clients sharing private data with
each other. Federated learning systems are susceptible to
poisoning attacks when malicious clients send false updates
to the central server. Existing defense strategies are ineffec-
tive under non-IID data settings. This paper proposes a new
defense strategy, FedCPA (Federated learning with Criti-
cal Parameter Analysis) . Our attack-tolerant aggregation
method is based on the observation that benign local models
have similar sets of top- kand bottom- kcritical parameters,
whereas poisoned local models do not. Experiments with
different attack scenarios on multiple datasets demonstrate
that our model outperforms existing defense strategies in
defending against poisoning attacks.
1. Introduction
The proliferation of computing devices like mobile phones
has led to an increase in proprietary user data. The abun-
dance of user data offers the opportunity to create numer-
ous applications but also raises concerns about data pri-
vacy. Federated learning (FL) is a cutting-edge collabora-
tive technique that addresses the privacy challenge by en-
abling machine learning on decentralized devices without
exchanging locally stored data [26]. For example, a promi-
nent FL model, FedAvg [17], works as follows: Given a
central server and multiple clients, the central server selects
a random subset of clients and sends the global model to
them. Then, each selected client uses its own data to op-
timize the local model and sends back the model update
to the central server. The central server takes the average
of these received updates to construct a new global model.
This FL framework enables a decentralized system to train
a globally shared model via aggregating updates from local
models while preserving data privacy.
However, the averaging operation used in the central
server leaves room for poisoning attacks [2, 16] when mali-
*Equal contribution to this work.cious clients pose as ordinary clients and submit fraudulent
model updates. Attackers can not only impede the con-
vergence of model training and degrade performance [23]
(which is called untargeted attacks ) but they can also
manipulate model updates by injecting a backdoor into the
resulting global model without substantially degrading its
performance [25] (which is called targeted attacks ).
Several defense strategies have been proposed to elim-
inate false updates from potentially malicious clients and
maintain benign updates on FL systems. For instance, one
idea is to use outlier-resistant statistics such as the median
or trimmed mean [31, 32] rather than the average in model
aggregation. Blanchard et al. [3] proposed Krum, which
removes atypical model updates with low local density
compared to their k-nearest neighbors. Fung et al. [8]
and Fu et al. [7] proposed weighted averaging of local
updates in proportion to each update’s normality level.
Nevertheless, these defense strategies cannot detect adver-
saries in so-called non-IID (non-independent, identically
distributed) situations, where data distributions vary sub-
stantially among clients. Existing defense strategies project
model updates as individual Euclidean vectors and evaluate
their abnormality based on their distances from other model
updates. Meanwhile, the non-IID property leads to diverse
benign updates, which makes malicious and benign updates
indistinguishable in Euclidean space. As a result, existing
defense strategies become ineffective [2, 19].
This paper presents FedCPA (Federated learning with
Critical Parameter Analysis), an attack-tolerant aggregation
method for FL under non-IID data settings. Inspired by a
recent observation that not all model parameters contribute
equally to optimization [6, 28], we assess the importance
of the model parameters in every client’s update. Our
analysis shows that benign model updates share similar sets
of top- kand bottom- kimportant parameters, even under
non-IID data. However, this pattern is not observed for
malicious model updates. Based on this observation, we
propose a new defense strategy tailored for FL systems to
measure model similarity, which extends beyond the extant
Euclidean-based similarity and provides an efficient way to
discard updates from clients that are likely malicious.arXiv:2308.09318v1  [cs.LG]  18 Aug 2023FedCPA consists of two steps: (1) computing the
normality score of each client’s model concerning param-
eter importance and (2) aggregating local updates via a
weighted average to remove the effect of likely-malicious
updates. In the first step, the importance of each parameter
is computed by multiplying its value by its change after
local training. The resulting parameters are then ranked in
order of importance. Top- kand bottom- kmost important
parameters are extracted for each client’s model and used
to compute the similarity among clients’ models. Then,
we define the normality of the model update to measure
its similarity with other model updates. Model updates
that differ from other updates are considered malicious.
In the second step, outlier local updates are filtered out by
adjusting their weights regarding their normality scores.
Our evaluation demonstrates that FedCPA protects
against both untargeted and targeted attacks better than ex-
isting methods such as Multi-Krum [3], FoolsGold [8], and
ResidualBase [7]. We make the following contributions:
• We empirically show that benign local models in fed-
erated learning exhibit similar patterns in how param-
eter importance changes during training. The top and
bottom parameters have smaller rank order disruptions
than the medium-ranked parameters.
• Based on the data observation that holds over non-IID
cases, we present a new metric for measuring model
similarity (Eq. 5). With this measure, FedCPA can
efficiently assess the normality of each local update,
enabling attack-tolerant aggregation.
• Extensive experiments demonstrate the superiority
ofFedCPA in terms of defense performance. For
example, FedCPA reduces the success rate of targeted
attacks by a factor of 3 (from 51.4% to 21.9%) on
CIFAR-10 and by a factor of 2 (from 74.6% to 43.2%)
on TinyImageNet.
The proposed model can be used in various federated
learning contexts as a more robust and attack-tolerant
decentralized computing framework. Codes are available
athttps://github.com/Sungwon-Han/FEDCPA .
2. Related Work
2.1. Model Poisoning Attacks
Due to its decentralized nature, federated learning is sus-
ceptible to model poisoning attacks and allows malicious
clients to send harmful updates to the central server without
supervision [27]. As local training data is not shared,
malicious participants launch attacks without a full under-
standing of the entire dataset [5]. Model poisoning attacks
can be categorized into untargeted and targeted attacks.In an untargeted attack scenario, attackers aim to indis-
criminately degrade the model’s overall performance across
all classes [22]. Simple and widely used methods of un-
targeted attack include label-flipping and adding Gaussian
noise, which can be executed without prior knowledge of
the entire training data distribution [23]. A label-flipping
attack involves malicious clients sending false update sig-
nals by randomly altering the class label of the training
data [29]. On the other hand, Gaussian noise attacks send
random noise with the same distribution as the local model
prior to the attack in place of the benign client updates [5].
In atargeted attack , the objective of a malicious client is
to deliberately introduce a backdoor into the global model,
which predicts a specific target label for any input overlaid
with the backdoor trigger but otherwise behaves like a nor-
mal model with a similar overall performance [1, 9, 30].
The backdoor trigger can be a small square to be blended
into the original image or a fixed watermark on the im-
age [4, 15].
2.2. Defense Strategies in Federated Learning
Operation based strategy. The main objective of defense
strategies is to screen harmful updates from malicious
clients. The first representative line of work involves
dimension-wise aggregation, which employs outlier-
resilient operations instead of a simple average. For exam-
ple,Median aggregates local updates by computing the me-
dian value for each dimension of the updates [31]. Trimmed
Mean is another aggregation method that eliminates a
specified percentage of the smallest and largest values, then
computes the average of the remaining values [32].
When the training data is of a non-IID distribution, the
median aggregation method becomes less effective because
it overlooks underrepresented updates. To tackle this lim-
itation, RFA suggests using an approximate geometric me-
dian operation [20]. ResidualBase , on the other hand, in-
troduces residual-based aggregation to determine parame-
ter confidence after calculating the residual of each model
parameter via a median estimator [7].
Anomaly detection based strategy. The next line of work
involves using anomaly detection to identify and remove
malicious updates during aggregation. One representative
work is Krum , which uses the Euclidean norm space to iden-
tify updates far from benign as malicious [3]. In Krum,
a local model update that shows the highest similarity to
n−m−2of its neighboring updates is identified as be-
nign, with mdenoting the anticipated number of malicious
clients. Multi-Krum extends this idea by selecting multi-
ple benign local updates iteratively using Krum. Another
approach, FoolsGold , identifies the coordinated actions of
targeted attacks [8]. Operating under the assumption that
malicious clients engaged in a targeted attack exhibit sim-
ilar update patterns, Foolsgold adjusts the learning rate ofmodel updates, scaling it in proportion to the diversity of
the updates. Norm Bound excludes clients whose local up-
dates exceed a certain threshold for the norm, as malicious
clients tend to produce updates with larger norms [24].
3. Problem Statement
Federated Learning. Suppose a set of Nclients in total
in a federated learning system as Cand a set of training
sample data in the i-th client as Di(i∈ {1, ..., N}). FL
aims to train a single global model parameterized as ϕwith-
out directly sharing the local dataset Diwith others. Given
loss objective Liin the i-th client and its empirical loss li,
the main objective for optimizing ϕcan be expressed as
arg min
ϕL(ϕ) =Ei∈[1..N][Li(ϕ,Di)],
where Li(ϕ,Di) =E(x,y)∈Di[li(x, y;ϕ)]. (1)
Following the literature [8], we choose FedAvg [17] as
the default setting to optimize Eq. 1 in the following way.
FedAvg divides each training iteration into multiple steps.
At the beginning of the t-th iteration ( t≥0), the central
server randomly selects a subset of clients and distributes
its global model ϕt. Then, selected clients update their local
model weights θt
iwith their dataset Diand send these up-
dates as ∆t
i=θt
i−ϕtto the central server. Then, the central
server aggregates receive local model updates and modifies
the global model weight ϕt+1as follows (hereafter called
thecentral aggregation process ):
ϕt+1=ϕt+P
i∈[1..N]|Di| ·∆t
iP
i∈[1..N]|Di|. (2)
This process repeats until the global model converges.
Threat model. Consider a scenario where Mmalicious
clients ( M < N ) infiltrate the FL system to disturb or
manipulate the central aggregation process by transmitting
false local updates. Because FL systems are decentralized,
attackers cannot access updates from benign users and
hence have a limited view of the entire data distribution.
We consider two different types of poisoning attacks. One
is untargeted attacks, in which attackers may send Gaussian
noise to the central server or train the local model with
randomly swapped labels. Such tampering can harm the
global model’s performance. The other type is targeted
attacks, in which attackers send model updates containing
a backdoor with a carefully designed backdoor trigger.
This will cause the global model to incorrectly classify test
samples under a specific target label.
Attack-tolerant central aggregation. Most FL systems
assume that all participants are benign and that their lo-
cal updates are reliable. This assumption leaves the systemvulnerable to attacks that try to alter or manipulate updates
for malicious purposes. Attack-tolerant central aggregation
methods have been proposed to mitigate the impact of ma-
licious updates [7, 31, 32].
LetCmdenote a set of malicious clients and Cba set
of benign clients, C=Cm∪ Cb. Then, the objective of
attack-tolerant central aggregation is to design the aggrega-
tion function g∗(·), which can be defined as follows,
ϕt+1=ϕt+P
i∈[1..N]1(i∈ Cb)·∆t
i
N−M
=ϕt+X
i∈[1..N]g∗(i)·∆t
i, (3)
where 1(i∈ Cb)is an indicator function that becomes one if
client i∈ Cband zero if client i /∈ Cb. The term |Di|in Eq. 2
is omitted here to prevent magnifying the effect of false up-
dates by attackers with increased sizes of their datasets.
4. Critical Parameter Analysis
Given the problem statement, our goal, as formulated in
Eq. 3, is to determine which updates are malicious and neu-
tralize their impact during the central aggregation process.
Prior studies used L2distance-based similarity, assuming
that false updates are positioned far from benign updates
in the Euclidean space [3, 7]. Such an approach performs
poorly in the non-IID setting [2], where benign updates be-
come diverse enough to be separated from malicious up-
dates. Motivated by a recent study that demonstrated pa-
rameters play diverse roles in model training [6, 13, 28], we
adopt an alternative approach to examine parameter impor-
tance and identify common patterns among benign updates
distinguishable from malicious updates. Our new defense
strategy is robust under non-IID data distributions.
Letθt
idenote the model parameters of client iat
communication round t. After the local training, the
model update is defined as ∆t
i=θt
i−ϕt. As originally
used in [28], we evaluate the importance piof the model
parameters of client iwith the following equation:
pi[n] =|∆i[n]·θi[n]|, (4)
where the notation [n]represents the n-th component value
of a given vector.
The role of Eq. 4 is two-fold. First, the magnitude of
the update provides information about the intensity of the
learning signal imposed on each parameter for optimiza-
tion [13]. Second, the magnitude of the weight represents
how much the parameter contributes to the model’s predic-
tion [6]. By considering both the update and the weight, we
can comprehensively assess the importance of each model
parameter. Specifically, when the value of pi[n]is large, the
parameter is considered critical and can significantly impact(a) Changes of importance in benign clients
 (b) Disparity in changes by attacks
 (c) Disparity in changes with different β
Figure 1: Analysis of importance-rank changes of parameters in federated learning: (a) Averaged change in importance-ranks
of parameters in benign local models after one training round with the standard deviation area shaded. (b) Comparison
of change patterns under two different poisoning attack scenarios, where the disparity is measured by the difference in
importance-rank changes between benign and poisoned models after one training round. (c) The disparity in change patterns
of the untargeted attack under varying data heterogeneity determined by β.
the optimization process. If pi[n]is small, the parameter is
considered non-critical and is rarely used for training.
Given a federated learning system with multiple clients
and parameter importance information of each local model,
we conduct an analysis to answer the questions below.
•Q1. Do benign local models exhibit similar patterns
of changing parameter importance during training?
•Q2. Are there any differences in the change of
parameter importance between the training of normal
and malicious objectives?
•Q3. If any patterns are discovered, are they persistent
across different non-IID settings and datasets?
The first question asks about the common change
pattern in the importance-ordering of local model param-
eters among benign clients. To answer this question, we
conducted multiple rounds of communication in the FL
system using the CIFAR-10 dataset. For each round t >1,
the central server shares its global model, ϕt, with clients.
Clients then record the parameter importance of the shared
global model ϕtviapt
global [n] =|∆t[n]·ϕt[n]|, where
∆t[n] =ϕt[n]−ϕt−1[n]is the change of the global model
made from the previous t−1round. Note that pt
global is
identical for all clients since they receive the same model.
The parameters were then ordered according to the global
model’s parameter importance pt
global (x-axis in Figure 1).
After the local training, each client icomputes the model’s
importance again, expressed as pt
i. We analyzed the
changes in orderings between pt
global andpt
ifor each round
t >1, and the averaged results are displayed in Fig. 11.
Figure 1a shows experimental results of importance-rank
changes in benign clients. We can see that most rank
1Note that the scale of the y-axis in Fig. 1 lies within [0, 1.1E7], as we
used the ResNet18 model with 1.1E7 trainable parameters.changes concentrate on parameters of medium importance,
whereas the top-importance parameters tend to remain sta-
ble and the bottom-importance parameters tend to change
less in importance ranks. This finding suggests different
roles for parameters in the model; The top-importance pa-
rameters may be less susceptible to changes due to their
significant role in shaping the model’s predictions. On the
other hand, the bottom-importance parameters have only a
small effect on the prediction, and hence they may be ne-
glected, resulting in fewer importance-rank changes dur-
ing the optimization process. A similar observation is also
made in [28] on the role of model parameters.
The experiment was then repeated in the presence of a
poisoning attack. We prepared two models derived from the
same global model: one was trained with a normal objective
and the other with a malicious objective. The disparity in
importance-rank changes between the two models was then
computed for both targeted and untargeted attack scenarios.
The results are shown in Figure 1b. We can see that the poi-
soned models for both attack scenarios cause greater pertur-
bations in the top- and bottom-importance parameters. This
phenomenon may be explained by the fact that a poisoning
attack seeks to alter the most critical parameters for disrupt-
ing model optimization and injecting malicious information
by awakening the unused parameters (i.e., less important
parameters) to cause overfitting to noise.
Finally, we examined if this phenomenon holds for
various non-IID data settings and datasets. The level of
non-IIDness was adjusted by the beta hyper-parameter ( β)
in the Dirichlet distribution of clients. The experimental
results are shown in Figure 1c and Figure 4 in the Ap-
pendix. They both confirm that the pattern persists across
varying levels of non-IIDness (adjusted by the βvalue) and
multiple datasets. These observations can be summarized
to answer the initial questions as follows:•A1.When it comes to importance-rank changes of pa-
rameters, benign local models in FL systems tend to
have similar top and bottom parameters in terms of
importance ranks.
•A2. Poisoned local models in FL systems tend to
have different sets of parameters with top and bottom
importance compared with benign models, which can
either degrade optimization or induce overfitting.
•A3. The above importance-rank change patterns
of parameters persist for different levels of data
heterogeneity and datasets.
5. Main Defense Approach: FedCPA
We present an effective defense method against poisoning
attacks, called FedCPA . Our key idea is to define a new
model similarity metric through critical parameter analysis
and measure the normality of each local update based
on this similarity. The model then attempts to filter out
and reduce the impact of potentially malicious updates
using attack-tolerant central aggregation. We describe each
procedure in detail.
Defining local model similarity. Given two local models
and their parameter importance computed by Eq. 4, we
measure the local model similarity with two criteria:
top/bottom- kcritical sets similarity and importance rank
correlation. First, we extract the indices of the top- kand
bottom- kimportant parameters from each client (i.e., Θtop
i,
Θbottom
i in client i) and compare them by calculating the
Jaccard similarity between each pair of parameter sets.
Second, to further assess the similarity of the parameter im-
portance pattern, we compute the Spearman correlation of
the importance values between two models for both top- k
and bottom- kparameter sets. The correlation is calculated
over the parameter sets that are common in the two models
(i.e., Θtop
i∩j= Θtop
i∩Θtop
j,Θbottom
i∩j= Θbottom
i∩Θbottom
j ).
These criteria are derived from our observations that the
benign local model tends to have similar sets of parameters
with top and bottom importance, while poisoned models do
not. The similarity measure between local models θiand
θjis defined as the following equation:
sim(θi, θj) =J(Θtop
i,Θtop
j) +J(Θbottom
i,Θbottom
j)
+ρ(ri(Θtop
i∩j), rj(Θtop
i∩j))
+ρ(ri(Θbottom
i∩j), rj(Θbottom
i∩j)), (5)
where J(·,·)denotes the Jaccard similarity and ρ(·,·)de-
notes the Spearman correlation between two inputs, which
is normalized to [0, 1] to align the scale. Here, riandrjrep-
resent the functions that map indices to their ranks in terms
of parameter importance for clients iandj, respectively.Algorithm 1 Central aggregation process with FedCPA
Input: Global model weight ϕt, global model weight from
previous round ϕt−1, a set of local clients Ctwith their
models θt
i, and updates ∆t
i, given index i.
// Computing parameter importance
foreach client i∈ Ctdo
pt
i[n] =|∆t
i[n]·θt
i[n]|in Eq. 4
Θbottom
i,Θtop
i= arg sort( pt
i)[:k],arg sort( pt
i)[−k:]
end
// Measuring normality score
foreach client i∈ Ctdo
foreach client j∈ Ct, j̸=ido
Θtop
i∩j= Θtop
i∩Θtop
j,Θbottom
i∩j= Θbottom
i∩Θbottom
j
si,j=sim(θt
i, θt
j)in Eq. 5
end
N(θt
i)= sim (θt
i, ϕt−1) +1
|Ct|P
j∈Ctsi,jin Eq. 7
˜N(θt
i)= Scale( N(θt
i))
λt
i=Clip0∼1(ln˜N(θt
i)
1−˜N(θt
i)+ 0.5)in Eq. 8
end
// Attack-tolerant update
ϕt+1←ϕt+1P
i∈Ct1(λt
i>0)P
i∈Ctλt
i·∆t
iin Eq. 9
Normality score for local model. Assuming that adver-
sarial models would have dissimilar patterns of parameter
importance from other benign models, we regard a model
with low similarity to others as likely malicious. Given the
set of clients Ctparticipating in communication round t,
normality score N(θt
i)of the local model θt
ican be defined
as follows:
N(θt
i) =1
|Ct|X
j∈Ctsim(θt
i, θt
j). (6)
However, relying solely on similarities among local
models is susceptible to a Sybil attack, where most clients
selected at the beginning of the round are malicious by
chance [8]. In this scenario, the normality score for adver-
sarial models can be overestimated, as their updates tend to
be similar. To enhance the stability of the defense, we also
compare the local model with the global model ϕt−1from
the previous t−1round, resulting in the following normal-
ity score,
N(θt
i) =sim(θt
i, ϕt−1) +1
|Ct|X
j∈Ctsim(θt
i, θt
j). (7)
Attack-tolerant central aggregation. We aggregate lo-
cal updates through a weighted average, with the weight λt
i
determined by the normality score N(θt
i). This allows us to
filter out the effect of likely malicious updates, while pre-
serving the knowledge gained from likely benign clients’
updates. To convert normality scores into weights, we scaleMethod CIFAR-10 SVHN TinyImageNet
(γp= 0.5) ACC(↑) ASR( ↓)ACC ASR ACC ASR
No Defense 72.1 71.0 93.0 22.2 39.5 96.6
Median 65.6 77.8 90.7 23.0 32.5 96.1
Trimmed Mean 70.1 51.4 92.2 20.9 39.3 97.2
Multi Krum 69.9 63.8 92.1 21.4 37.1 74.6
FoolsGold 45.5 54.3 79.6 23.5 24.3 92.4
Norm Bound 68.2 61.2 93.1 20.8 36.6 96.7
RFA 72.8 56.4 92.3 20.8 37.1 93.9
ResidualBase 70.6 59.9 93.1 21.1 39.6 96.9
FedCPA 68.8 21.9 93.3 20.6 30.1 43.2Method CIFAR-10 SVHN TinyImageNet
(γp= 0.8) ACC(↑) ASR( ↓)ACC ASR ACC ASR
No Defense 69.3 50.9 92.5 22.0 38.8 96.1
Median 62.4 70.6 90.0 23.6 31.5 96.2
Trimmed Mean 71.4 19.0 91.7 21.4 37.9 97.0
Multi Krum 69.0 40.4 90.7 23.4 36.3 19.0
FoolsGold 49.1 46.8 69.8 32.3 28.5 69.1
Norm Bound 64.9 53.1 92.7 20.9 35.7 97.1
RFA 70.1 44.8 91.8 22.1 36.3 11.4
ResidualBase 69.9 54.0 92.5 21.9 38.6 96.2
FedCPA 72.3 12.5 93.1 20.8 38.7 4.8
Table 1: Comparison of defense performance over three datasets under targeted attack scenarios with different levels of
pollution ratio γp= 0.5,0.8. ACC and ASR refer to the final accuracy and the attack success rate, respectively. The symbol
(↑) indicates that a higher value is preferable, while ( ↓) represents the opposite. The best results are marked bold.
Method ( γp= 0.8)CIFAR-10 SVHN TinyImageNet
No Defense 69.8 90.6 33.0
Median 59.8 89.9 28.7
Trimmed Mean 72.9 91.0 34.1
Multi Krum 72.7 92.6 35.9
FoolsGold 18.6 47.6 4.6
Norm Bound 64.9 90.8 29.3
RFA 72.6 92.7 36.5
ResidualBase 73.6 92.1 36.0
FedCPA 74.9 93.2 36.8Method ( γp= 1.0)CIFAR-10 SVHN TinyImageNet
No Defense 63.8 86.1 24.4
Median 56.8 89.6 21.2
Trimmed Mean 66.2 87.9 27.2
Multi Krum 73.0 92.6 35.9
FoolsGold 24.9 41.9 1.3
Norm Bound 63.5 86.6 24.1
RFA 71.5 92.4 36.3
ResidualBase 70.3 91.8 30.5
FedCPA 74.4 93.2 34.9
Table 2: Comparison of defense performance over three datasets under label flipping attack scenarios with different levels of
pollution ratio γp= 0.8,1.0. The best results are marked bold.
each score to the range from 0 to 1 with Min-Max normal-
ization, i.e., ˜N(θt
i)←Scale (N(θt
i)). Following the litera-
ture [8], we apply the inverse sigmoid function to a normal-
ized score to enhance the differentiation of weight values
and avoid over-penalization of low, non-zero similarity val-
ues on benign clients, resulting in the following weight,
λt
i=Clip0∼1(ln˜N(θt
i)
1−˜N(θt
i)+ 0.5). (8)
where Clip0∼1(·)denotes a function that rounds and clips
any values exceeding the 0-1 range. Given the local up-
date from client ias∆i, the global model at communication
round tis updated as follows:
ϕt+1←ϕt+1P
i∈Ct1(λt
i>0)X
i∈Ctλt
i·∆t
i, (9)
where 1(λt
i>0)is an indicator function that produces one
ifλt
iis larger than zero and zero otherwise. The overall
procedure of FedCPA is described in the Algorithm 1.6. Experiments
We evaluate the effectiveness of FedCPA in defending
against several attack scenarios over multiple datasets.
Component analyses are conducted to confirm the con-
tribution of each component to robustness under varying
simulation hyper-parameters.
6.1. Defense Performance Evaluation
Data. Three benchmark datasets on image classification
tasks are utilized in our experiment: (1) CIFAR-10 [11] in-
cludes 60,000 samples of 32x32 pixels with 10 classes; (2)
SVHN [18] includes 73,257 training samples and 26,032
test samples of 32x32 sized digits; (3) TinyImageNet [12]
contains 100,000 samples from 200 classes.
In our experiments, the non-IID property of feder-
ated learning in the three datasets is simulated using the
Dirichlet distribution, following previous works [10, 14].
The Dirichlet distribution can be denoted as Dir(N, β),
where Nis the total number of clients and βrefers to the
parameter that adjusts the level of heterogeneity in the
decentralized data distributions. A lower value of βresults
in greater non-IIDness. We set Nandβto 20 and 0.5 as
default values, respectively.Method CIFAR-10 SVHN TinyImageNet
No Defense 32.7 47.8 2.1
Median 67.8 91.5 28.8
Trimmed Mean 55.6 72.5 12.1
Multi Krum 52.8 68.4 15.0
FoolsGold 13.9 6.7 0.5
Norm Bound 28.2 42.9 1.2
RFA 72.0 92.2 35.8
ResidualBase 74.6 93.7 37.0
FedCPA 74.8 93.6 36.1
Table 3: Accuracy (%) under the Gaussian noise attack over
three datasets. The best results are marked bold.
Implementation details. We set the number of commu-
nication rounds to 100, with one epoch of local training per
round. Following the literature [10, 14], we use ResNet18
as the default backbone network. The SGD optimizer
is employed. The learning rate, momentum, and weight
decay parameter for the optimizer are set to 0.01, 0.9, and
1e-5. The batch size is set to 64. The hyper-parameter k
for top and bottom- kparameter sets is set to 0.01 (1%).
To simulate a more realistic federated setting, half of the
clients (i.e., N/2) are randomly chosen in each round of
training. Data augmentation techniques such as random
crop, horizontal flip, and color jitter are applied during the
local training. In the case of the targeted attack, we follow
the original literature [9] and generate a noise input pattern
called backdoor. The size of the backdoor is set to 5 ×5,
and its location is in the bottom-right corner of the images.
For the untargeted Gaussian attack, we set the standard
deviation of the Gaussian noise to 0.05.
Baselines. A total of eight baselines are compared: (1)
No Defense represents the classical FedAvg algorithm
without any consideration of attack scenarios; (2) Median
and (3) Trimmed Mean [31, 32] utilize the outlier-resistant
statistics, mean and trimmed mean of local updates, for
aggregation; (4) Multi Krum [3] iteratively selects a likely-
benign local update with the lowest Euclidean distance
from other updates; (5) FoolsGold [8] identifies grouped
actions of attacks by inspecting similarity among local up-
dates; (6) Norm Bound [24] filters out the updates whose
norm is above a predefined threshold; (7) RFA [20] applies
the geometric median operation for robust aggregation; (8)
Residual Base [7] introduces a repeated median estimator
to compute the confidence of each update.
For all baselines, we followed the original implementa-
tions and hyper-parameter settings. The confidence interval
and clipping threshold in the ResidualBase algorithm
are set to 2.0 and 0.05, respectively. In RFA, we set the
smoothing parameter to 1e-6 and the maximum number of
Weiszfeld iterations to 100.SetupTargeted Label flipping GaussianTotalACC ASR ACC ACC
No Defense 2.8 6.2 6.5 7.0 5.6
Median 7.8 7.5 7.5 4.0 6.7
Trimmed Mean 4.2 4.7 4.8 5.3 4.8
Multi Krum 5.7 4.7 2.8 5.7 4.7
FoolsGold 9.0 5.5 9.0 9.0 8.1
Norm Bound 5.2 5.5 6.8 8.0 6.4
RFA 3.8 3.7 2.7 3.0 3.3
ResidualBase 2.7 6.0 3.5 1.3 3.4
FedCPA 3.2 1.0 1.3 1.7 1.8
Table 4: Performance comparison summaries among
defense strategies. Averaged rank for each evaluation
metric under different attack scenarios, including both
untargeted and targeted attacks, is reported. Our FedCPA
presents superb defense performance.
Evaluation. All methods are assessed under the same ex-
perimental settings (e.g., β, the number of clients, commu-
nication rounds, and epochs for local training). Given a total
ofNclients, we set 20% of the clients to play an adversarial
role as default. Three attack scenarios are evaluated, one for
targeted and two for untargeted attacks. The targeted attack
injects a crafted backdoor trigger pattern into some training
images and changes their labels to the target class to manip-
ulate the model training. The untargeted attacks consist of
the label flipping attack, which randomly alters the labels to
generate false update signals [29], and the Gaussian noise
attack, which sends Gaussian noise as an update [5]. For
both the targeted and label flipping attacks, experiments
were conducted with two different levels of pollution ratio
(γp), representing the fraction of poisoned samples added
to the dataset. In the targeted attack experiments, we use
a pollution ratio of 0.5 and 0.8, while a pollution ratio of
0.8 and 1.0 is used in the label flipping attack experiments.
As an evaluation metric, the final accuracy on the test set is
reported for the untargeted attack scenarios, while both the
attack success rate and the final accuracy are reported for
the targeted attack scenario. All measures are calculated by
averaging the last ten rounds of results.
Results. Tables 1-4 present the evaluation results and
their summaries for different attack scenarios. FedCPA
shows the best or comparable classification accuracy and
attack success rate against other defense strategies over all
datasets. Our method consistently performs satisfactorily
against all types of attacks, whereas some baselines may
struggle against specific attacks (e.g., ResidualBase in
the targeted attack scenario). Notably, FedCPA reduces
the success rate of targeted attacks by a factor of 2 to 4
compared to other baselines on the CIFAR-10 and TinyIm-(a) Effect of the ratio of attackers
 (b) Effect of the level of non-IIDness
 (c) Effect of the number of clients
Figure 2: Robustness test results against targeted attacks on CIFAR-10 with varying experimental settings. The results
demonstrate that FedCPA consistently achieves the best defense performance (lowest ASR) compared with the baselines.
SetupTargeted Untargeted
ACC ASR ACC
All components 72.3 12.5 74.9
without topk 70.4 18.9 74.0
without bottomk 60.5 36.8 67.6
without global 68.8 24.1 74.8
without local 65.0 20.2 72.4
Table 5: Ablation study results of FedCPA on CIFAR-10.
The best results are marked bold. Our method with full
components reports the best defense performance against
both targeted and untargeted attacks.
ageNet datasets. These results highlight the effectiveness
of our method in providing robustness for FL systems.
6.2. Component Analysis
Ablation study. We conduct an ablation study to evaluate
the contribution of each component in our full model. The
following variations are compared: (1) without topk only
considers and compares parameters of bottom- kimportance
to compute the normality score of models, while (2) without
bottomk is vice-versa; (3) without global omits the simi-
larity term in the normality score between the local model
and the global model from the previous round (Eq. 6); (4)
without local only utilizes global model similarity for the
normality measure (i.e., N(θt
i) =sim(θt
i, ϕt−1)).
Table 5 shows that the full model with all components
performs the best against both targeted and untargeted at-
tacks (i.e., label flipping attacks) among all variations,
which implies that each component plays an important role
in detecting malicious updates. Interestingly, without con-
sidering the bottom- kimportant parameters, the ablation
study showed the greatest decrease in defense performance
among all the ablations. These results support our hypoth-
esis that poisoning attacks cause a local model to overfit
maliciousness by utilizing unused parameters. Therefore,Top/bottom- kratioTargeted Untargeted
ACC ASR ACC
k= 0.005 (0.5%) 61.0 63.4 71.4
k= 0.01 (1%) 72.3 12.5 74.9
k= 0.02 (2%) 67.7 15.6 74.0
k= 0.05 (5%) 60.2 51.6 74.3
Table 6: Hyper-parameter analysis under both targeted and
untargeted attacks on CIFAR-10 with different values of k.
simply focusing on the bottom- kimportant parameters is
also effective in detecting adversarial clients.
Robustness test. Next, we conduct experiments in set-
tings with varying key experimental parameters to assess
the robustness of our approach. These include (a) the num-
ber of malicious clients |Cm|, (b) the total number of partic-
ipating clients N, and (c) the degree of non-IIDness, con-
trolled by βin the Dirichlet distribution.
The performance comparison between FedCPA and the
baselines on the CIFAR-10 dataset is shown in Figure 2.
Only the results for the targeted attack scenario are reported
due to the space limitation. More results can be found in
the appendix. We can see that, under various experimental
settings, FedCPA consistently demonstrates superior
defense performance.
Hyper-parameter analysis. We investigate the effect
of hyper-parameter kon defense performance. Hyper-
parameter kdetermines the proportion of model parameters
selected to create the parameter sets Θtop
iandΘbottom
i (i.e.,
the top- kand bottom- kmost important parameters) for each
client i. The smaller k, the fewer parameters are compared
to compute the normality score of the model.
The results for various values of kare presented in
Table 6. Our method demonstrates satisfactory results for
most measures under both targeted and untargeted attackFigure 3: Qualitative analysis under a targeted attack scenario over TinyImagenet, where the highlighted part visualizes how
the model recognizes class characteristics based on the Grad-CAM algorithm.
(i.e., label flipping attack) scenarios when kis within a
reasonable range of 1-2%. However, setting kto a value too
small or too large significantly decreases the performance.
This is because the normality measure with a small kmay
not have enough evidence to distinguish malicious updates,
while the measure with a large kcan be disturbed by the
importance changes caused by data heterogeneity.
Qualitative Analysis We also perform a qualitative
analysis to assess how effectively FedCPA can filter out
malicious knowledge during training under targeted attack
scenarios. Figure 3 compares the performance of different
defense strategies in interpreting class characteristics after
training. To evaluate each model’s interpretation, we
corrupted test set images with a small patch of noise used
by attackers and used the Grad-CAM algorithm [21] to
visualize the model’s attention for each input. Blue-framed
images represent success cases randomly sampled from
the dataset, while red-framed images represent failure
cases. Our method tends to extract key features from
the image compared to other cases where the model is
contaminated by malicious knowledge and only focuses
on the injected noise patch. Even in failure cases, our
approach gives attention to other visual traits along withthe noise, demonstrating its robustness against attacks.
7. Conclusion
We presented FedCPA , a defense strategy against poison-
ing attacks in federated learning systems. Our method is
based on the observation that benign local models tend to
have similar sets of important parameters, while adversarial
models do not. To distinguish malicious updates, we pro-
pose a new normality measure that considers the pattern of
important parameters in local models. Then, we aggregate
local updates via a weighted average, where the weight of a
local update is determined by its normality score. Extensive
experiments with both targeted and untargeted attack sce-
narios on multiple datasets demonstrate the effectiveness of
FedCPA in defending against poisoning attacks. Our work
contributes to the ongoing efforts on attack-tolerant feder-
ated learning and provides new insights for future research.
Acknowledgements. This research was supported by the In-
stitute for Basic Science (IBS-R029-C2). Sungwon Han, Sungwon
Park, and Meeyoung Cha were supported by the National Research
Foundation of Korea (NRF) grant (RS-2022-00165347). Sundong
Kim also received the NRF grant funded by the Ministry of Sci-
ence and ICT (RS-2023-00240062).References
[1] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah
Estrin, and Vitaly Shmatikov. How to backdoor federated
learning. In Proceedings of AISTATS , pages 2938–2948.
PMLR, 2020. 2
[2] Gilad Baruch, Moran Baruch, and Yoav Goldberg. A little is
enough: Circumventing defenses for distributed learning. In
Advances in NeurIPS , volume 32, 2019. 1, 3
[3] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guer-
raoui, and Julien Stainer. Machine learning with adver-
saries: Byzantine tolerant gradient descent. In Advances in
NeurIPS , volume 30, 2017. 1, 2, 3, 7
[4] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn
Song. Targeted backdoor attacks on deep learning systems
using data poisoning. arXiv preprint arXiv:1712.05526 ,
2017. 2
[5] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong.
Local model poisoning attacks to {Byzantine-Robust }fed-
erated learning. In Proceedings of USENIX Security , pages
1605–1622, 2020. 2, 7
[6] Jonathan Frankle and Michael Carbin. The lottery ticket hy-
pothesis: Finding sparse, trainable neural networks. In Pro-
ceedings of ICLR , 2019. 1, 3
[7] Shuhao Fu, Chulin Xie, Bo Li, and Qifeng Chen. Attack-
resistant federated learning with residual-based reweighting.
arXiv preprint arXiv:1912.11464 , 2019. 1, 2, 3, 7
[8] Clement Fung, Chris JM Yoon, and Ivan Beschastnikh. The
limitations of federated learning in sybil settings. In Pro-
ceedings of RAID , 2020. 1, 2, 3, 5, 6, 7
[9] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Bad-
nets: Identifying vulnerabilities in the machine learning
model supply chain. arXiv preprint arXiv:1708.06733 , 2017.
2, 7, 11
[10] Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim,
Chuhan Wu, Xing Xie, and Meeyoung Cha. Fedx: Unsuper-
vised federated learning with cross knowledge distillation. In
Proceedings of ECCV , pages 691–707, 2022. 6, 7, 11
[11] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009. 6
[12] Ya Le and Xuan Yang. Tiny imagenet visual recognition
challenge. Stanford CS 231N , 7(7):3, 2015. 6
[13] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip Torr.
Snip: Single-shot network pruning based on connection sen-
sitivity. In Proceedings of ICLR , 2019. 3
[14] Qinbin Li, Bingsheng He, and Dawn Song. Model-
contrastive federated learning. In Proceedings of CVPR ,
pages 10713–10722, 2021. 6, 7, 11
[15] Yunfei Liu, Xingjun Ma, James Bailey, and Feng Lu. Reflec-
tion backdoor: A natural backdoor attack on deep neural net-
works. In Proceedings of ECCV , pages 182–199. Springer,
2020. 2
[16] Lingjuan Lyu, Han Yu, and Qiang Yang. Threats to federated
learning: A survey. arXiv preprint arXiv:2003.02133 , 2020.
1
[17] Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data.
InProceedings of AISTATS , pages 1273–1282, 2017. 1, 3
[18] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-
sacco, Bo Wu, and Andrew Y Ng. Reading digits in natural
images with unsupervised feature learning. 2011. 6
[19] Sungwon Park, Sungwon Han, Fangzhao Wu, Sundong Kim,
Bin Zhu, Xing Xie, and Meeyoung Cha. Feddefender:
Client-side attack-tolerant federated learning. arXiv preprint
arXiv:2307.09048 , 2023. 1
[20] Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui. Ro-
bust aggregation for federated learning. IEEE Transactions
on Signal Processing , 70:1142–1154, 2022. 2, 7
[21] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das,
Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
Grad-cam: Visual explanations from deep networks via
gradient-based localization. In Proceedings of ICCV , pages
618–626, 2017. 9
[22] Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octavian Su-
ciu, Christoph Studer, Tudor Dumitras, and Tom Goldstein.
Poison frogs! targeted clean-label poisoning attacks on neu-
ral networks. In Advances in NeurIPS , volume 31, 2018. 2
[23] Jacob Steinhardt, Pang Wei W Koh, and Percy S Liang. Cer-
tified defenses for data poisoning attacks. In Advances in
NeurIPS , volume 30, 2017. 1, 2
[24] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and
H Brendan McMahan. Can you really backdoor federated
learning? arXiv preprint arXiv:1911.07963 , 2019. 3, 7
[25] Brandon Tran, Jerry Li, and Aleksander Madry. Spectral
signatures in backdoor attacks. Advances in NeurIPS , 31,
2018. 1
[26] Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi,
H Brendan McMahan, Maruan Al-Shedivat, Galen Andrew,
Salman Avestimehr, Katharine Daly, Deepesh Data, et al.
A field guide to federated optimization. arXiv preprint
arXiv:2107.06917 , 2021. 1
[27] Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and
Xing Xie. Fedattack: Effective and covert poisoning attack
on federated recommendation via hard sampling. In Pro-
ceedings of ACM SIGKDD , 2022. 2
[28] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan
Wang, Zongyuan Ge, and Yi Chang. Robust early-learning:
Hindering the memorization of noisy labels. In Proceedings
of ICLR , 2021. 1, 3, 4
[29] Han Xiao, Huang Xiao, and Claudia Eckert. Adversarial la-
bel flips attack on support vector machines. In Proceedings
of ECAI , pages 870–875. IOS Press, 2012. 2, 7
[30] Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. Dba: Dis-
tributed backdoor attacks against federated learning. In Pro-
ceedings of ICLR , 2020. 2
[31] Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.
Generalized Byzantine-tolerant SGD. arXiv preprint
arXiv:1802.10116 , 2018. 1, 2, 3, 7
[32] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter
Bartlett. Byzantine-robust distributed learning: Towards op-
timal statistical rates. In Proceedings of ICML , pages 5650–
5659, 2018. 1, 2, 3, 7(a) CIFAR-10
 (b) SVHN
 (c) TinyImageNet
Figure 4: Comparison of change patterns over three datasets under two different poisoning attack scenarios, untargeted
and targeted attack, where the disparity is measured by the difference in changes of importance rank between benign and
poisoned models after one training round.
A. Appendix
A.1. Release & Implementation details
We adopt ResNet18 as the default backbone architecture, building
upon prior research in federated learning [14, 10]. In the case of
the targeted attack, we follow the original literature [9] and gener-
ate a noise input pattern called a backdoor. The size of the back-
door is set to 5 ×5, and its location is in the bottom-right corner of
the images. For the untargeted Gaussian attack, we set the standard
deviation of the Gaussian noise to 0.05.
We follow the original works’ implementations and hyper-
parameter settings to reproduce all baselines. For Multi-Krum
and Norm Bounding algorithms, we assume the central server al-
ready knows the upper bound of attacker numbers when decid-
ing on hyper-parameters. The confidence interval and clipping
threshold in the ResidualBase algorithm are set to 2.0 and 0.05,
respectively. We calculate the geometric mean for RFA by set-
ting the smoothing parameter to 1e-6 and the maximum number
of Weiszfeld iterations to 100. More details on implementations
are at https://github.com/Sungwon-Han/FEDCPA .
A.2. Time Complexity Analysis
For all experiments, we utilized four A100 GPUs. Table 7 com-
pares the time costs in seconds of every defense strategy per each
round of training. Note that FedCPA is not a huge burden and
only took 10% more processing time than the classical FedAvg
algorithm (i.e., No Defense).
A.3. Extra Results on Critical Parameter Analysis
In Section 4, we have shown that benign and poisoned local
models exhibit distinct patterns in terms of parameter importance,
with the poisoned model causing more significant disruptions to
the top and bottom parameters. We conducted the same analysis
across different datasets to validate our observation. The results of
our analysis are presented in Figure 4, which compares the change
patterns in importance rank between benign and poisoned models
under two different attack scenarios, untargeted and targeted
attacks. For the untargeted attack scenario, we used the label
flipping attack method. After one training round, We measure
the disparity in importance rank between benign and poisonedMethod Time costs in seconds
No Defense 87
Median 86
Trimmed Mean 87
Multi Krum 87
FoolsGold 90
Norm Bound 86
RFA 91
ResidualBase 185
FedCPA 96
Table 7: Comparison on time complexity among defense
strategies against poisoning attacks. The CIFAR-10 dataset
is used for the analysis.
models. The results demonstrate that our observation remains
consistent across the various datasets.
A.4. Extra Results on Robustness Tests
We evaluate the robustness of FedCPA through experiments con-
ducted under different settings, varying key simulation parameters
such as (a) the number of malicious clients |Cm|, (b) the total num-
ber of participating clients N, and (c) the degree of non-IIDness,
controlled by the βparameter in the Dirichlet distribution. A
lower βvalue results in a higher level of non-IIDness.
This section presents additional comparison results among
different defense strategies under an untargeted attack scenario
(i.e., label flipping attack) on the CIFAR-10 dataset. Results
presented in Figure 5 show that FedCPA consistently performs
comparably well despite variations in simulation parameters.
A.5. Full Results on Performance Evaluation
Table 8-12 shows the complete evaluation results on defense
performance over three datasets under various poisoning attack
scenarios: targeted attack with γp= 0.5,0.8, untargeted label
flipping attack with γp= 0.8,1.0, and untargeted Gaussian
attack. The results are obtained by averaging over the last ten
rounds and are reported with mean and standard deviation values.(a) Effect of the ratio of attackers
 (b) Effect of the level of non-IIDness
 (c) Effect of the number of clients
Figure 5: Robustness test results under label flipping attack across different simulation hyper-parameters: (a) the attacker
ratio, (b) the level of non-IIDness, and (c) the number of clients over the CIFAR-10 dataset.
Method CIFAR-10 SVHN TinyImageNet
(γp= 0.5) ACC ASR ACC ASR ACC ASR
No Defense 72.1±3.07 71.0 ±0.61 93.0±0.48 22.2 ±12.02 39.5±2.71 96.6 ±0.41
Median 65.6±3.54 77.8 ±1.09 90.7±0.44 23.0 ±7.02 32.5±3.43 96.1 ±0.58
Trimmed Mean 70.1±3.15 51.4 ±0.82 92.2±0.57 20.9 ±20.66 39.3±1.13 97.2 ±0.26
Multi Krum 69.9±0.89 63.8 ±1.24 92.1±0.82 21.4 ±10.88 37.1±2.85 74.6 ±6.93
FoolsGold 45.5±12.24 54.3 ±18.25 79.6±5.32 23.5 ±36.78 24.3±7.37 92.4 ±14.82
Norm Bound 68.2±4.12 61.2 ±25.00 93.1±0.69 20.8 ±0.91 36.6±0.38 96.7 ±0.69
RFA 72.8±3.09 56.4 ±13.52 92.3±1.09 20.8 ±1.57 37.1±0.48 93.9 ±0.63
ResidualBase 70.6±3.12 59.9 ±0.61 93.1±0.34 21.1 ±15.45 39.6±1.27 96.9 ±0.19
FedCPA 68.8±3.74 21.9 ±0.73 93.3±9.36 20.6 ±2.69 30.1±1.51 43.2 ±44.66
Table 8: Comparison of defense performance over three datasets under targeted attack scenarios with pollution ratio γp= 0.5.
Mean and standard deviation over ten last rounds are reported.
Method CIFAR-10 SVHN TinyImageNet
(γp= 0.8) ACC ASR ACC ASR ACC ASR
No Defense 69.3±3.74 50.9 ±25.09 92.5±0.93 22.0 ±2.21 38.8±1.12 96.1 ±1.34
Median 62.4±3.32 70.6 ±16.51 90.0±1.53 23.6 ±3.39 31.5±0.99 96.2 ±0.59
Trimmed Mean 71.4±2.77 19.0 ±10.29 91.7±1.25 21.4 ±1.78 37.9±1.12 97.0 ±0.81
Multi Krum 69.0±2.21 40.4 ±21.85 90.7±2.33 23.4 ±4.06 36.3±1.78 19.0 ±13.91
FoolsGold 49.1±9.46 46.8 ±34.83 69.8±24.56 32.3 ±27.72 28.5±4.27 69.1 ±43.20
Norm Bound 64.9±4.28 53.1 ±30.29 92.7±1.31 20.9 ±1.42 35.7±1.00 97.1 ±0.83
RFA 70.1±3.37 44.8 ±21.58 91.8±1.44 22.1 ±2.01 36.3±1.05 11.4 ±5.80
ResidualBase 69.9±3.59 54.0 ±27.50 92.5±0.81 21.9 ±2.34 38.6±0.47 96.2 ±0.81
FedCPA 72.3±0.88 12.5 ±1.02 93.1±1.02 20.8 ±1.35 38.7±0.63 4.8 ±1.40
Table 9: Comparison of defense performance over three datasets under targeted attack scenarios with pollution ratio γp= 0.8.
Mean and standard deviation over ten last rounds are reported.Method ( γp= 0.8)CIFAR-10 SVHN TinyImageNet
No Defense 69.8±3.49 90.6 ±1.80 33.0 ±4.76
Median 59.8±3.16 89.9 ±1.55 28.7 ±4.73
Trimmed Mean 72.9±3.47 91.0 ±1.49 34.1 ±3.73
Multi Krum 72.7±3.61 92.6 ±0.99 35.9 ±2.22
FoolsGold 18.6±7.53 47.6 ±19.76 4.6 ±3.36
Norm Bound 64.9±4.19 90.8 ±2.06 29.3 ±5.18
RFA 72.6±2.31 92.7 ±0.96 36.5 ±0.78
ResidualBase 73.6±3.40 92.1 ±1.03 36.0 ±3.38
FedCPA 74.9±3.30 93.2 ±0.72 36.8 ±1.53
Table 10: Comparison of defense performance over three datasets under label flipping attack scenarios with pollution ratio
γp= 0.8. Mean and standard deviation over ten last rounds are reported.
Method ( γp= 1.0)CIFAR-10 SVHN TinyImageNet
No Defense 63.8±5.85 86.1 ±5.21 24.4 ±8.94
Median 56.8±7.23 89.6 ±2.49 21.2 ±8.71
Trimmed Mean 66.2±5.12 87.9 ±3.97 27.2 ±8.25
Multi Krum 73.0±3.78 92.6 ±1.42 35.9 ±3.10
FoolsGold 24.9±10.72 41.9 ±17.53 1.3 ±1.60
Norm Bound 63.5±4.45 86.6 ±7.05 24.1 ±8.86
RFA 71.5±2.66 92.4 ±1.06 36.3 ±1.12
ResidualBase 70.3±3.95 91.8 ±1.38 30.5 ±8.23
FedCPA 74.4±2.85 93.2 ±0.57 34.9 ±2.18
Table 11: Comparison of defense performance over three datasets under label flipping attack scenarios with pollution ratio
γp= 1.0. Mean and standard deviation over ten last rounds are reported.
Method CIFAR-10 SVHN TinyImageNet
No Defense 32.7±4.18 47.8 ±8.72 2.1 ±1.09
Median 67.8±4.30 91.5 ±1.21 28.8 ±3.44
Trimmed Mean 55.6±4.38 72.5 ±9.72 12.1 ±5.63
Multi Krum 52.8±5.86 68.4 ±13.72 15.0 ±4.55
FoolsGold 13.9±4.13 6.7 ±0.00 0.5 ±0.08
Norm Bound 28.2±2.49 42.9 ±10.39 1.2 ±0.67
RFA 72.0±2.85 92.2 ±0.49 35.8 ±0.80
ResidualBase 74.6±2.11 93.7 ±0.39 37.0 ±1.05
FedCPA 74.8±2.42 93.6 ±0.58 36.1 ±1.37
Table 12: Comparison of defense performance over three datasets under Gaussian noise attack scenarios. Mean and standard
deviation over ten last rounds are reported."
Stochastic Segmentation with Conditional Categorical Diffusion Models,http://arxiv.org/abs/2303.08888,"Semantic segmentation has made significant progress in recent years thanks to
deep neural networks, but the common objective of generating a single
segmentation output that accurately matches the image's content may not be
suitable for safety-critical domains such as medical diagnostics and autonomous
driving. Instead, multiple possible correct segmentation maps may be required
to reflect the true distribution of annotation maps. In this context,
stochastic semantic segmentation methods must learn to predict conditional
distributions of labels given the image, but this is challenging due to the
typically multimodal distributions, high-dimensional output spaces, and limited
annotation data. To address these challenges, we propose a conditional
categorical diffusion model (CCDM) for semantic segmentation based on Denoising
Diffusion Probabilistic Models. Our model is conditioned to the input image,
enabling it to generate multiple segmentation label maps that account for the
aleatoric uncertainty arising from divergent ground truth annotations. Our
experimental results show that CCDM achieves state-of-the-art performance on
LIDC, a stochastic semantic segmentation dataset, and outperforms established
baselines on the classical segmentation dataset Cityscapes.","Stochastic Segmentation with Conditional Categorical Diffusion Models
Lukas Zbinden∗Lars Doorenbos∗Theodoros Pissas
Adrian Thomas Huber Raphael Sznitman Pablo M ´arquez-Neila
University of Bern, Bern, Switzerland
{lukas.zbinden,lars.doorenbos,theodoros.pissas,raphael.sznitman,pablo.marquez }@unibe.ch
Abstract
Semantic segmentation has made significant progress in
recent years thanks to deep neural networks, but the com-
mon objective of generating a single segmentation output
that accurately matches the image’s content may not be
suitable for safety-critical domains such as medical diag-
nostics and autonomous driving. Instead, multiple possi-
ble correct segmentation maps may be required to reflect
the true distribution of annotation maps. In this context,
stochastic semantic segmentation methods must learn to
predict conditional distributions of labels given the image,
but this is challenging due to the typically multimodal distri-
butions, high-dimensional output spaces, and limited anno-
tation data. To address these challenges, we propose a con-
ditional categorical diffusion model (CCDM) for seman-
tic segmentation based on Denoising Diffusion Probabilis-
tic Models. Our model is conditioned to the input image,
enabling it to generate multiple segmentation label maps
that account for the aleatoric uncertainty arising from di-
vergent ground truth annotations. Our experimental results
show that CCDM achieves state-of-the-art performance on
LIDC, a stochastic semantic segmentation dataset, and out-
performs established baselines on the classical segmenta-
tion dataset Cityscapes.
1. Introduction
Semantic segmentation has significantly progressed in
recent years due to powerful deep neural networks. For
most methods, the key objective is to generate a single seg-
mentation output that accurately matches the image’s con-
tent. However, this may not be suitable for safety-critical
domains such as medical diagnostics and autonomous driv-
ing, as images in these applications often suffer from inher-
ent ambiguity or annotations that have differences in opin-
ion. In these cases, generating a single coherent segmen-
tation may be hopeless to fully describe the set of correct
*Equal contribution
Ground-truth Generated samplesFigure 1: Examples from the LIDC dataset, where expert
radiologists were asked to annotate lung nodules. Despite
their expertise, they disagree significantly on many cases.
Standard segmentation networks fail to capture these vari-
ations, thereby giving a false sense of confidence in model
predictions. Our approach learns the distribution of possible
labels, allowing us to generate realistic and diverse segmen-
tations.
labeling.
Instead, multiple possible correct segmentation maps
may be required to reflect the true distribution of annota-
tions. For instance, Fig. 1 illustrates the task of lung nod-
ule segmentation from CT scans where expert annotators
provide multiple valid segmentation maps. In this con-
text, stochastic semantic segmentation methods must learn
to predict conditional distributions of labels given the im-
age. Doing so is challenging, however, as the distribution is
typically multimodal, the output space is high-dimensional,
and annotation data is limited.
Denoising Diffusion Probabilistic Models (DDPMs) ap-
pear well-suited to overcome these challenges. DDPMs
have recently drawn strong interest in computer vision as
a framework for learning complex distributions in high-
dimensional spaces. After achieving state-of-the-art per-
formance on image synthesis [13], they have been success-
fully extended to solve tasks such as text-to-image gener-
ation [41], counterfactual explanation generation [24], in-
painting [34], but also image classification [56] and seman-arXiv:2303.08888v5  [cs.CV]  11 Sep 2023tic segmentation [1, 3, 48] amongst others.
While DDPMs were originally formulated as probabilis-
tic models able to learn high-dimensional data distributions
of discrete and ordered variables ( e.g., RGB pixel values),
re-formulations and modifications that allow for categori-
cal variables ( e.g., labels) [21] are one of the key reasons
why DDPMs are being explored in a broad range of com-
puter vision tasks [12]. Specifically, the ability to model the
spatial distribution of categorical variables is well suited for
numerous computer vision tasks, including semantic seg-
mentation [6, 8, 10, 14, 16, 17, 27, 31, 33, 54, 55]. Yet
until now, segmentation methods using DDPMs have relied
on the original discrete and ordered formulation and differ-
ent heuristics to yield categorical outputs [1, 3, 48]. Conse-
quently, the potential advantages of adopting diffusion mod-
els of categorical variables for stochastic image segmenta-
tion are still unknown.
In light of the above, we propose a conditional cate-
gorical diffusion model (CCDM) for semantic segmenta-
tion based on DDPMs, which models both the observed
and the latent variables as categorical distributions. This
enables the model to explicitly generate labels maps of dis-
crete, unordered variables, thereby circumventing the need
for switching between continuous and discrete domains, as
in previous methods. The model is conditioned to the input
image, making it possible to generate multiple segmentation
label maps that account for the aleatoric uncertainty arising
from image ambiguity. We show experimentally that our
approach achieves state-of-the-art performance on LIDC, a
stochastic semantic segmentation dataset, according to sev-
eral performance measures. Moreover, when applied to the
classical segmentation dataset Cityscapes, our method pro-
vides competitive results, outperforming established base-
lines.
In summary, our main contributions are the following:
• We propose a conditional categorical diffusion model
capable of learning the label distribution given an in-
put image that can be used to produce diverse segmen-
tation samples that capture aleatoric uncertainty.
• For the task of learning a multi-rater semantic segmen-
tation label distribution, our method achieves state-of-
the-art performance on LIDC, being the first diffusion-
based approach proposed for this task.
• We report competitive performance on a challenging
semantic segmentation task, Cityscapes, outperform-
ing several established baselines using a lightweight
model that also leverages an off-the-shelf pre-trained
feature extractor.
2. Related work
Stochastic segmentation: Methods for stochastic se-mantic segmentation aim at capturing the aleatoric uncer-
tainty and inherent unpredictability of the labels used for
segmentation. Different frameworks have been proposed to
yield segmentations according to the underlying label dis-
tribution.
Initial works aimed at equipping a standard U-Net [40]
with a probabilistic element to generate multiple predic-
tions for the same image, typically accomplished by adding
a conditional variational autoencoder (cV AE) [45], where
the low-dimensional latent space of the cV AE encodes the
possible segmentation variants. In [28], samples from this
latent space are upscaled and concatenated at the last layer
of the U-Net. Multiple methods extend this set-up to a hier-
archical version [4, 29, 53]. Other works use normalizing
flows to allow for a more expressive distribution than the
Gaussian distribution in the cV AE [43, 46], switch to a dis-
crete latent space [37], or add variational dropout and use
the inter-grader variability directly as a training target [23].
Several other methods do not rely on the probabilistic
U-Net. Monteiro et al. [35] propose a network that uses a
low-rank multivariate normal distribution to model the logit
distribution. Kassapis et al. [25] leverage adversarial train-
ing to learn possible label maps based on the logits of a
trained segmentation network. Zhang et al. [52] employ an
autoregressive PixelCNN to model the conditional distribu-
tion between pixels. Finally, Gao et al. [15] use a mixture
of stochastic experts, where each expert network estimates
a mode of the uncertainty, and a gating network predicts the
probabilities that an input image is segmented by one of the
experts. Our method is the first to explore the use of cate-
gorical diffusion models for stochastic segmentation.
Diffusion models: Generative diffusion models [44]
have drawn much attention following their popularization
by [19]. Since then, diffusion models have been success-
fully applied to various domains, such as image generation,
restoration, and super-resolution [12].
More central to the work presented here, a few meth-
ods have attempted to apply diffusion models to seman-
tic segmentation. Baranchuk et al. [3] first train diffu-
sion models to generate images, then use multilayer per-
ceptrons (MLP) on its features to predict the class label.
Other works focus on binary segmentation with conditional
diffusion models [1, 48]. These methods generate single-
channel continuous samples conditioned on the input image
and obtain binary segmentation masks by thresholding the
result. Directly applying continuous diffusion is also done
in [49, 50]. Chen et al. [9] generate discrete data with con-
tinuous diffusion models by encoding categorical data into
bits and modeling these bits as real numbers.
Hoogeboom et al. [21] propose multinomial diffusion, a
variation of diffusion models designed for categorical data.
Subsequently, multinomial diffusion has been applied to
discrete use cases, such as for tabular data [30], the latentspace of vector-quantized variational auto-encoders [11, 22]
or text [21]. They can also generate segmentation maps in
the unconditional setting at a very small resolution ( 32×
64) [21]. Instead, we focus on the unexplored conditional
case and demonstrate results at significantly higher resolu-
tions (up to 256×512).
3. Method
We now introduce our approach by first framing the
problem setting and defining the necessary notation. We
then describe categorical diffusion models and the condi-
tioning procedure to produce stochastic semantic segmen-
tation via diffusion.
3.1. Background and notation
A denoising diffusion probabilistic model (DDPM) is a
latent variable model pθ(x0) =R
pθ(x0:T)dx1:Tdescrib-
ing the distribution of an observable variable x0∈RDus-
ing a collection of Tlatent variables {xt}T
t=1with the same
dimensionality as x0. The joint distribution is modeled as
a Markov chain pθ(x0:T) = p(xT)QT
t=1pθ(xt−1|xt),
which is commonly known as the reverse process . The ini-
tialp(xT)is set to a known, tractable distribution such as
the Gaussian distribution, while the transition distribution
pθ, parameterized by θ, is the trainable component of the
model. Training a DDPM aims to approximate pθ(x0)to an
empirical distribution q(x0)defined by a collection of sam-
ples ( e.g., images from the real world). To that end, training
minimizes the cross-entropy between both distributions,
min
θEx0∼q(x0)[−logpθ(x0)], (1)
which is intractable as it requires marginalizing over the
latent variables. Instead, a tractable distribution q(x1:T|
x0)is introduced and used as an approximation to the in-
tractable true posterior p(x1:T|x0)to define the evidence
lower bound (ELBO),
logpθ(x0)≥Ex1:T∼q(x1:T|x0)
logpθ(x0:T)
q(x1:T|x0)
,(2)
where the expectation is approximated by Monte Carlo
sampling. The lower bound is tight when the approximate
posterior qequals the real posterior. Maximizing the ELBO
over samples from q(x0)minimizes the cross-entropy loss
of Eq. (1).
The key difference between DDPMs and other latent
variable models is that the approximate posterior q(x1:T|
x0)is fixed and not learnable. DDPMs model this distri-
bution as a Markov chain q(x1:T|x0) =QT
t=1q(xt|
xt−1), known as the forward process . The transition dis-
tribution q(xt|xt−1)is chosen to be a tractable distri-
bution that allows efficient sampling from q(xt|x0)foranyt. The only constraint in the design of a DDPM is that
q(xT|x0)≈p(xT).
The original DDPM [19] modeled the transition distribu-
tions of the forward and the reverse processes as Gaussian
with diagonal covariance matrices, and p(xT)as a standard
multivariate normal. However, these assumptions are inade-
quate when the elements of x0belong to discrete, unordered
sets, as in the task of image segmentation.
3.2. Categorical diffusion model
We now consider the denoising diffusion formulation to
learn complex distributions of discrete image labelings. The
observable variable x0∈ LDis categorical, where Dis the
number of pixels of the image and L={1, . . . , L }is the
set of discrete labels that can be assigned to each pixel. Fol-
lowing [21], we consider that all latent variables in x1:Tare
also categorical and that the transition distributions for the
forward and reverse processes are modeled as categorical
distributions. For the forward process, the transition dis-
tribution acts element-wise over the previous state xt−1to
produce the parameters of the distribution for xtas,
q(xt|xt−1) =DY
d=1q(xt[d]|xt−1[d]), (3)
where xt[d]indicates the label at time tand pixel d. In the
following discussion, we will use xt∈ L to refer to the
label of a single pixel d, and we will drop the index dfor
clarity. The pixel-wise transition distribution q(xt|xt−1)
gives the element-wise probability of the next label given
the previous label as,
q(xt|xt−1) =C
xt;βt
L1+ (1−βt)ext−1
,(4)
where 1= (1, . . . , 1)T,eℓis the one-hot encoding vector
with 1 in position ℓand0elsewhere, and the hyperparame-
terαt= 1−βt∈(0,1)indicates the probability of keep-
ing the label unchanged. C(x;p)denotes the categorical
distribution with parameter vector p∈[0,1]L. From the
properties of categorical distributions, C(x|p) =p[x]andP
xp[x] = 1 .
The transition distribution of the forward process can be
composed as,
q(xt|x0) =C
xt;1−¯αt
L1+ ¯αtex0
(5)
with ¯αt=Qt
τ=1ατ, which enables efficient sampling of
elements from the Markov chain at any location t. Finally,
the posterior of the transition distribution can be computed
with the previous formulas by applying Bayes rule,
q(xt−1|xt, x0) =C(xt−1;π(xt, x0)), (6)next iterationConditional Categorical Diffusion
Reverse Process
𝐼
𝒙𝑇(1)
𝒙𝑇(𝑁)𝒙0(𝑁)𝒙0(1)𝐼
𝒙𝑡(𝑖)𝒙𝑡−1(𝑖)𝑝𝜃(𝒙𝑡−1|𝒙𝑡,𝐼)
......Figure 2: Illustration of the reverse process of our method.
The conditional categorical diffusion model (CCDM) re-
ceives as input an image Iand a categorical label map x(i)
T
sampled from the categorical uniform noise. The reverse
process of the CCDM generates a label map x(i)
0, which is
a sample from the learned distribution p(x0|I). When
repeated for Nsamples, we obtain an empirical approxi-
mation to the multimodal label distribution for the image I,
learned from the annotations of multiple expert raters.
with,
π(xt, x0) =1
˜πβt
L1+αtext
⊙1−¯αt−1
L1+ ¯αt−1ex0
(7)
and˜π=1−¯αt
L+ ¯αt·δx0xt, where δis the Kronecker delta.
The transition distribution of the reverse process is also
an element-wise categorical distribution,
pθ(xt−1|xt) =DY
d=1C(xt−1;ˆpt−1), (8)
where xt−1=xt−1[d]andˆpt−1are the label and the es-
timated parameter vector, respectively, at pixel d. Unlike
the forward process, the parameter vector for the pixel d
is not computed considering only the element dofxt. In-
stead, it is modeled as a function f:LD→[0,1]D×L
that incorporates context by considering the entire label
mapxtto produce a collection of Dprobability distribu-
tions for xt−1, which we refer to as ˆPt−1∈[0,1]D×Lwith
ˆpt−1=ˆPt−1[d].
While it is possible to use a neural network to estimate
ˆPt−1, Ho et al. [19] suggested that a consistent output space
for the network led to enhanced performance. Following
this idea, we train a network fθ, parameterized by θ, to
compute ˆP0=fθ(xt, t)∈[0,1]D×Lby receiving a la-
bel map xtand the step t. We then transform the parameter
vector for each pixel, ˆp0=ˆP0[d]to the parameter vector
ˆpt−1for the same pixel of xt−1as,
C(xt−1;ˆpt−1) = (9)
=X
x0q(xt−1|xt, x0)· C(x0;ˆp0) (10)
=X
x0C(xt−1;π(xt, x0))· C(x0;ˆp0), (11)from which,
ˆpt−1=X
x0∈Lπ(xt, x0)·ˆp0[x0], (12)
where we have omitted the pixel indices dfor clarity. This
transformation is not necessary when t= 1, as then ˆpt−1=
ˆp0computed by fθ. It is also possible to perform this
computation in parallel for every pixel to efficiently obtain
ˆPt−1. Note that the result of Eq. (12) differs from the pa-
rameter vector computed in [21], where the ill-defined ex-
pression ˆpt−1=π(xt,ˆx0)is employed.
3.3. Conditional categorical diffusion
In stochastic segmentation, the label map x0for an im-
ageIis modeled by a distribution q(x0|I). This distri-
bution is often too complex to be properly approximated as
a product of pixel-wise categorical distributions. We use a
conditional categorical diffusion model p(x0|I)(CCDM)
to model the potentially complex interactions between la-
bels and pixels.
When conditioning the categorical diffusion model on
an image, the forward process remains unchanged, q(x1:T|
x0, I) =q(x1:T|x0), as any latent variable is condition-
ally independent of the image given any previous variable.
On the other hand, the reverse process needs to incorporate
the dependency on the image in its transition distribution,
pθ(x0:T|I) =p(xT|I)QT
t=1pθ(xt−1|xt, I). In prac-
tice, this dependency is enforced by an additional input to
the neural network fθ(xt, t, I).
3.4. Training
Training is performed by maximizing the ELBO of
Eq. (2). Reorganizing terms and distributing expectations
for variance reduction, we express the ELBO as a sum of
three terms:
logpθ(x0|I)≥
Ex1∼q(x1|x0)[logpθ(x0|x1, I)] (13)
−TX
t=2Ext∼q(xt|x0)[KL(q(xt−1|xt,x0)∥pθ(xt−1|xt, I))]
(14)
−KL(q(xT|x0)∥p(xT|I)). (15)
The first two terms can be optimized by standard gra-
dient ascent. We approximate the expectations with Monte
Carlo sampling with a single sample. The sum over the time
variable tis also approximated by a single uniform sample
over{1, . . . , T }. The KL divergence of the second term is
the sum of pixel-wise KL divergences,
KL(q∥p) =DX
d=1KL(q(xt−1|xt, x0)∥pθ(xt−1|xt, I)),
(16)Algorithm 1 Training a CCDM with Tsteps
Require: Training data expressed as the empirical distribu-
tionq(x0, I) =q(x0|I)q(I).
repeat
t∼Uniform ({1, ..., T})
I∼q(I)
x0∼q(x0|I)
xt∼q(xt|x0)
ˆP0←fθ(xt, I, t) ▷shape D×L
ift >1then
▷Pixel-wise application of Eq. (12)
ˆpt−1←P
x0∈Lπ(xt, x0)·ˆp0[x0]▷shape L
▷Compute KL with Eq. (8) and (16)
ℓ←KL(q(xt−1|xt,x0)∥pθ(xt−1|xt, I))
else
ℓ← −P
dlogC(x0|ˆP0[d])
end if
θ←θ− ∇ θℓ ▷Gradient descent
until converged
where the parameter vectors of distributions qandpare
computed with Eqs. (7) and (12), respectively. Alg. 1 shows
the complete training procedure.
The third term of Eq. (15) does not depend on the learn-
able parameters θand is ignored during training. It is op-
timized by the design of the categorical diffusion model.
Since the forward process converges as
lim
t→∞q(xt|x0) =C
x;1
L
, (17)
we fix p(xT|I)to the element-wise uniform distribution,
p(xT|I) =p(xT) =C
xT;1
L
. (18)
This ensures that p(xT|I)≈q(xT|x0), making the third
term of the ELBO close to zero.
At inference, the CCDM samples from p(x0|I)to gen-
erate label maps for a given image I, which is achieved
by traversing the Markov chain of the reverse process as
outlined in Alg. 2 and illustrated in Fig. 2. To minimize
the noise of the generated label maps, the CCDM selects
the label with maximum probability instead of sampling
fromC(x0|ˆp0)in the final step.
3.5. Architecture of fθ
As described above, the neural network fθreceives a
label map xt, a time step t, and an image Ito estimate
the probability parameters for x0. Its base design is a U-
Net-like architecture [13] with self-attention modules at the
three innermost layers of the encoder and the decoder [13].
The network processes the input label map represented asAlgorithm 2 Inference from a CCDM with Tsteps
Require: Input image I,fθa network trained with Alg. 1
xT∼ CD 
xT;1
L
xprev←xT ▷Stores interm. and final prediction
fort=T, ..., 1do
ˆP0←fθ(xprev, I, t)
ift >1then
▷Pixel-wise application of Eq. (12)
ˆpt−1←P
x0∈Lπ(xt, x0)·ˆp0[x0]
xprev∼Q
dC(xt−1|ˆpt−1)
else
▷Final prediction
xprev←arg maxx0∈LˆP0[:, x0]
end if
end for
a binary tensor with Lchannels encoding the label of each
pixel as a one-hot vector. Parameters of the network are
shared for all values of t. The step variable tis encoded
with the standard transformer sinusoidal position embed-
ding [19] and concatenated as additional channels to the in-
put tensor and to the feature maps of intermediate layers.
Similarly, information from the input image Iis presented
to the network as raw pixel values concatenated to the input
tensor as additional channels. In some experiments we used
a pre-trained transformer architecture Dino-ViT [5] to ex-
tract informative visual features from the image I. In those
cases, the extracted features were concatenated to the fea-
ture map of the third level of the U-Net encoder, which cor-
responds to a spatial shape equal to1
8the shape of the input
image.
4. Experiments
In all our experiments, we set T= 250 and the collection
ofβtare set following the cosine schedule proposed in [36].
We evaluate our method on two tasks described below.
4.1. Segmentation with multiple annotations
Dataset The Lung Image Database Consortium
(LIDC) [2] binary segmentation dataset consists of
1’018 three dimensional chest CT scans of patients with
lung cancer. Lung nodules of each volume are annotated
by four expert raters from a pool of 12, yielding large
differences in annotations in some cases. We extract
nodule-centered slices from the CT volumes and treat each
slice as an independent image.
While LIDC is the standard benchmark of stochastic seg-
mentation methods to date ( e.g. [4, 15, 23, 25, 28, 29, 35,
43, 53, 54]), experimental configurations (pre-processing,
training/validation/test splits, metrics) vastly differ across
the literature. We conduct our experiments on the two most
prominent LIDC splits and report results on both separately.LIDCv1 LIDCv2
Method GED 16 GED 32 GED 50 GED 100 HM-IoU 16 HM-IoU 32 GED 16 GED 50 GED 100 HM-IoU 16
Prob. Unet [28] 0.310 ±0.01−0.303 ±0.01+ - 0.252 ±0.004†0.552 ±0.00− 0.548 ±0.00+0.320 ±0.030‡ - 0.252 ±‡ 0.500 ±0.030‡
HProb. Unet [29] 0.270 ±0.01− - - - 0.530 ±0.01− - 0.270 ±0.010‡ - - 0.530 ±0.01
PhiSeg [4] 0.262 ±0.00−0.247 ±0.00+ - 0.224 ±0.004†0.586 ±0.00− 0.595 ±0.00+ - - - -
SSN [35] 0.259 ±0.00−0.243 ±0.01+ - 0.225 ±0.002 0.558 ±0.00− 0.555 ±0.01+ - - - -
cFlow [43] - 0.225 ±0.01+ - - - 0.584 ±0.00+ - - - -
CAR [25] - - - 0.228 ±0.009 - - 0.264 ±0.002 0.248 ±0.004 0.243 ±0.004 0.592 ±0.005
JProb. Unet [53] - 0.206 ±0.00 - - - 0.647 ±0.01 0.262 ±0.00 - - 0.585 ±0.00
PixelSeg [52] 0.243 ±0.01 - - - 0.614 ±0.00 - 0.260 ±0.00 - - 0.587 ±0.01
MoSE [15] 0.218 ±0.003 - 0.195 ±0.002 0.189 ±0.002 0.624 ±0.004 - - - - -
AB [9] 0.213 ±0.001 0.196 ±0.002 0.193 ±0.002 - 0.614 ±0.001 0.619 ±0.001 - - - -
CIMD [38] 0.234 ±0.005 0.218 ±0.005 0.210 ±0.005 - 0.587 ±0.001 0.592 ±0.002 - - - -
CCDM (ours) 0.212 ±0.002 0.194 ±0.001 0.187 ±0.002 0.183 ±0.002 0.623 ±0.002 0.631 ±0.002 0.239 ±0.003 0.216 ±0.003 0.210 ±0.003 0.598 ±0.001
Table 1: Quantitative results on LIDCv1 and LIDCv2, with the methods ordered by year. Bold and underlined indicate best
and second best per column, respectively. Our results are over 3 seeds. For GED, lower is better; for HM-IoU, higher is
better. No method, including ours, uses pre-trained weights. Results for CIMD [38] and AB [9] are ours. All other scores are
taken from their original papers, except (+) from [53], (−) from [53], (†) from [35], ‡from [25].
The first, referred to as LIDCv1, is used in [4, 15, 35, 53].
LIDCv1 comprises 15’096 slices, divided into training, val-
idation, and testing sets with the ratio 60 : 20 : 20 . The
second, LIDCv2, is used in [25, 28] and contains 12’816
images with the ratio 70 : 15 : 15 .
Metrics We measure the performances with the Gener-
alised Energy Distance (GED) and the Hungarian-Matched
Intersection over Union (HM-IoU) [15, 25, 29]. Both met-
rics measure the difference between the distributions of gen-
erated and ground-truth label maps. We denote the metrics
computed with nsamples using a subscript, i.e., GED nand
HM-IoU n, and we set nto common values found in the
literature. Note that higher number of samples yield more
precise estimates.
Baselines We compare our approach to eleven re-
cent stochastic segmentation methods: probabilistic U-
Net (Prob. Unet) [28], hierarchical probabilistic U-Net
(HProb. Unet) [29], PhiSeg [4], stochastic segmenta-
tion network (SSN) [35], conditional normalizing flow
(cFlow) [43], calibrated adversarial refinement (CAR) [25],
joint probabilistic U-Net (JProb. Unet) [53], PixelSeg [52],
mixture of stochastic experts (MoSE) [15], analog bits
(AB) [9], and collectively intelligent medical diffusion
(CIMD) [38].
Following standard practice, we use random horizontal
and vertical flipping and random rotations of 0◦,90◦,180◦
and270◦for data augmentation. The resolution of the input
images is 128×128. We trained our method with the Adam
optimizer [26] until convergence of the GED metric on the
validation set, a polynomial learning rate scheduling start-
ing from 1e−4and ending with 1e−6, and batch size of 64.
We applied Polyak averaging with α= 0.99995 .4.2. Segmentation with a single annotation
We also evaluate our method with Cityscapes, a classical
multi-class segmentation dataset where each image is an-
notated with a single label map. It comprises 2’975 RGB
images of urban scenes for training and 500 images for val-
idation, with each image labeled using 19 possible classes.
We compare our approach to several established base-
lines using the validation set: DeepLabv3 [7], HRNet [47],
and UPerNet [51], with both ResNet [18] and Swin [32]
backbones.
Besides our standard method, which performs image
conditioning by concatenating the raw pixel values as chan-
nels of the input tensor, we also included in our comparison
a variant CCDM-Dino which leverages pre-trained Dino-
ViT features [5] as additional conditioning concatenated to
intermediate feature maps of our model’s encoder.
Experiments are conducted separately for two different
image resolutions: 128×256and256×512. For all re-
ported methods, we first resize the images to a fixed reso-
lution and then apply color jittering, random flipping, and
standard ImageNet intensity normalization as data augmen-
tation. All baselines are trained for 500epochs with a batch
size of 32, with optimizers, learning rate schedules, and
weight decay settings as reported in their respective pub-
lications (reported in detail in the supplementary material).
Our method was trained for 800epochs with a batch size
of32at128×256and of 16at256×512, using the Adam
optimizer [26] with a learning rate of 1e−4linearly decayed
to1e−6. We applied Polyak averaging with α= 0.999.
Performance is measured with the mean intersection-
over-union (mIoU). Unlike GED and HM-IoU, the metric
mIoU is incompatible with multiple label maps per image.
During inference, CCDM generates multiple label maps per
image that are subsequently fused into a single label map forperformance assessment. We found that fusing by averag-
ing the predicted probabilities resulted in superior perfor-
mances compared to fusing by majority vote.
5. Results
5.1. LIDC
We report performances on LIDCv1 and LIDCv2 in
Tab. 1 and qualitative results in Fig. 3. Due to the lack of
consistent evaluation protocols, we use a total of 10 metrics,
thereby covering all the baselines and allowing for direct
comparisons.
Our CCDM reaches the best performance for eight out of
the ten metrics, despite its relatively small size, with 9M pa-
rameters compared to, e.g., the 42M parameters of MoSE.
CCDM also outperforms recent continuous diffusion mod-
els for segmentation, including AB [9] (9M parameters) and
CIMD [38] (24M parameters). On HM-IoU 16, the CCDM
has a lower mean performance than MoSE by 0.001, but
with only half the standard deviation. The JProb. Unet
reaches a higher HM-IoU 32than all other methods, despite
being considerably worse for GED 32than our CCDM. Fur-
thermore, on LIDCv2, the JProb. Unet achieves only the
third-best score on GED 16, and fourth-best on HM-IoU 16.
This result indicates how comparing results obtained on dif-
ferent LIDC versions with each other can be misleading.
Fig. 3 presents qualitative results from our method. In
columns (g)-(l), we see that our CCDM generates a distri-
bution of samples that captures the annotation variability
created by the four expert raters. Further, as seen in the
bottom example, the CCDM also generates empty samples
according to the annotations (b)-(e).
Reduced number of time steps for sampling: During
inference, traversing the Tsteps of the reverse process
makes sampling from DDPMs slow. A straightforward so-
lution [36] involves traversing only a subset of nodes of the
reverse process, {xkτ:τ∈ {0, . . . , T/k }}, reducing the
number of steps by a factor k. This technique accelerates
inference at the expense of reduced performance. To illus-
trate the trade-offs between performance and speed, Fig. 5
presents the evolution of GED 16and HM-IoU 16as the num-
ber of inference steps is reduced. As expected, CCDMs per-
form best when the number of training and inference steps
are equal, but a reasonable increase in speed without a large
sacrifice in performance is possible.
5.2. Cityscapes
Experimental comparisons on Cityscapes are presented
in Tab. 2, and qualitative examples are provided in Fig. 4.
Experiments at 128×256demonstrate that CCDM-Dino
outperforms all other methods, even when only a single
sample is used. CCDM-raw also remains competitive, be-
ing outperformed only by one baseline (UPerNet+Swin-Method mIoU final (best)
Architecture Backbone #params 128×256 256 ×512
DeepLabv 3[7] ResNet50 ( ✓) 39m 43.4 (44.1) 58.6 (59.2)
DeepLabv 3[7] ResNet101 ( ✓) 58m 43.8 (45.5) 59.2 (59.8)
UPerNet [51] ResNet101 ( ✓) 83m 45.5 (47.1) 60.7 (61.2)
HRNet [47] w48v2 ( ✓) 70m 48.2 (49.5) 63.3 (64.2)
UPerNet [32] Swin-Tiny ( ✓) 58m 54.2 (55.9) 65.5 (66.0)
CCDM (ours) -
samples=1 30m 53.2 60.3
samples=5 30m 55.4 62.0
samples=10 30m 56.2 62.4
CCDM (ours) Dino ViT-S ( †)
samples=1 30m + 20M 55.5 64.0
samples=5 30m + 20M 56.9 65.4
samples=10 30m + 20M 57.3 65.8
Table 2: Results on Cityscapes-val for resolutions 128×256
and256×512.Bold and underlined indicate best and sec-
ond best per column, respectively. ( ✓) and ( †) indicate su-
pervised and self-supervised pretraining of the backbone,
respectively. Gray indicates pretrained, non-finetuned pa-
rameters. We report final performance for our method and
baselines. For the latter we also provide best achieved
performance during training (in parenthesis). For CCDM
methods, the field samples indicates the number of gener-
ated samples for label map fusion, as explained in Sect 4.2.
CCDM Capacity mIoU ( 128×256)
#params UNet Levels samples=1 samples=5 samples=10
5.4M 4 37.8 39.7 40.6
7.5M 5 44.7 48.3 48.5
22M 4 51.6 54.0 53.6
30M 5 53.2 55.4 56.2
Table 3: Effect of increasing CCDM capacity (without fea-
ture conditioning).
Tiny), despite using only between 36% and51% of the pa-
rameters of other models. Similarly, at 256×512, CCDM-
Dino outperforms four of the baselines with a single sample,
lags behind UPerNet+Swin-Tiny only by 0.1percent points
with5samples, and outperforms all baselines with 10sam-
ples. As expected, averaging across more samples improves
performance for both CCDM-raw and CCDM-Dino, albeit
with diminishing gains. Furthermore, the addition of Dino
features boosts single-sample performance by 2.3percent
points at 128×256, and 3.7percent points at 256×512,
hinting the greater value of adding feature conditioning for
generating segmentation at a higher resolution.
CCDM Capacity : Tab. 3(b) demonstrates the effect of in-
creasing the capacity of CCDM. Using more U-Net feature
levels, and increasing the number of parameters by doubling
the number of channels per level, increases the performance
regardless of the number of samples used for inference.a) b) h) c) g) e) d) f) i) j) k) l)Figure 3: Qualitative results on four LIDC images with our method. (a) shows the image, (b)-(e) its four labels, (f) the mean
prediction of our CCDM over six predictions, and (g)-(l) six individual predictions.
Figure 4: Qualitative comparisons on Cityscapes. All methods are trained and tested at a resolution of 256×512. Our method
produces structures with greater visual realism than other baselines. This is especially noticeable inside the marked regions.
0 50 100 150 200 250
Sampling Steps0.200.250.300.350.400.450.500.55GED16GED
HM-IoU
0.390.430.460.500.540.580.610.65
HM-IoU16
Figure 5: LIDC GED and HM-IoU versus the number of
sampling steps on LIDC. Evaluated on 500 random test im-
ages using 16 samples each, over 3 seeds.6. Conclusion
We introduced conditional categorical diffusion models
(CCDMs) that are capable of effectively modeling pixel-
level semantic distributions. Notably, and contrary to stan-
dard deterministic segmentation approaches, our model can
produce diverse samples given an input image, thereby cap-
turing the aleatoric uncertainty. Our method learns a multi-
modal label distribution of segmentations, induced by an-
notations from multiple expert raters, for which it achieves
state-of-the-art results on a challenging medical imaging
dataset, LIDC. Additionally, we demonstrate that it can
achieve competitive performance on a standard multi-class
semantic segmentation benchmark, Cityscapes, by outper-
forming several established, heavily engineered baselinesdespite using significantly fewer parameters.
One limitation of our method is the requirement of sev-
eral iterations for producing a sample, which is a com-
mon shortcoming of diffusion models. Accelerating sam-
pling constitutes a crucial research direction, orthogonal
to the present work. Finally, resolution scaling remains
notoriously difficult for diffusion models, with successful
examples relying on massive computational resources to
train cascades of models that gradually increase resolu-
tion [20, 42] or operate on the latent space of existing em-
bedding methods for continuous data ( e.g. images) [39] that
are not available for categorical data.
Acknowledgements
This work was partially funded by the University of
Bern, Swiss National Science Foundation Grants #320030-
188591, #200021-192285, and #200021-191983.
References
[1] Tomer Amit, Eliya Nachmani, Tal Shaharbany, and Lior
Wolf. Segdiff: Image segmentation with diffusion proba-
bilistic models. arXiv preprint arXiv:2112.00390 , 2021. 2
[2] Samuel G Armato III, Geoffrey McLennan, Luc Bidaut,
Michael F McNitt-Gray, Charles R Meyer, Anthony P
Reeves, Binsheng Zhao, Denise R Aberle, Claudia I Hen-
schke, Eric A Hoffman, et al. The lung image database con-
sortium (lidc) and image database resource initiative (idri):
a completed reference database of lung nodules on ct scans.
Medical physics , 38(2):915–931, 2011. 5
[3] Dmitry Baranchuk, Ivan Rubachev, Andrey V oynov,
Valentin Khrulkov, and Artem Babenko. Label-efficient se-
mantic segmentation with diffusion models. arXiv preprint
arXiv:2112.03126 , 2021. 2
[4] Christian F Baumgartner, Kerem C Tezcan, Krishna Chai-
tanya, Andreas M H ¨otker, Urs J Muehlematter, Khoschy
Schawkat, Anton S Becker, Olivio Donati, and Ender
Konukoglu. Phiseg: Capturing uncertainty in medical im-
age segmentation. In Medical Image Computing and Com-
puter Assisted Intervention–MICCAI 2019: 22nd Interna-
tional Conference, Shenzhen, China, October 13–17, 2019,
Proceedings, Part II 22 , pages 119–127. Springer, 2019. 2,
5, 6
[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv ´e J´egou,
Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-
ing properties in self-supervised vision transformers. In Pro-
ceedings of the International Conference on Computer Vi-
sion (ICCV) , 2021. 5, 6
[6] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos,
Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image
segmentation with deep convolutional nets, atrous convolu-
tion, and fully connected crfs. IEEE transactions on pattern
analysis and machine intelligence , 40(4):834–848, 2017. 2
[7] Liang-Chieh Chen, George Papandreou, Florian Schroff, and
Hartwig Adam. Rethinking atrous convolution for seman-tic image segmentation. arXiv preprint arXiv:1706.05587 ,
2017. 6, 7, 12
[8] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian
Schroff, and Hartwig Adam. Encoder-decoder with atrous
separable convolution for semantic image segmentation. In
Proceedings of the European conference on computer vision
(ECCV) , pages 801–818, 2018. 2
[9] Ting Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog
bits: Generating discrete data using diffusion models with
self-conditioning. arXiv preprint arXiv:2208.04202 , 2022.
2, 6, 7
[10] Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haib-
ing Ren, Xiaolin Wei, Huaxia Xia, and Chunhua Shen.
Twins: Revisiting the design of spatial attention in vision
transformers. Advances in Neural Information Processing
Systems , 34:9355–9366, 2021. 2
[11] Max Cohen, Guillaume Quispe, Sylvain Le Corff, Charles
Ollion, and Eric Moulines. Diffusion bridges vec-
tor quantized variational autoencoders. arXiv preprint
arXiv:2202.04895 , 2022. 3
[12] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu,
and Mubarak Shah. Diffusion models in vision: A survey.
arXiv preprint arXiv:2209.04747 , 2022. 2
[13] Prafulla Dhariwal and Alex Nichol. Diffusion models beat
gans on image synthesis. CoRR , abs/2105.05233, 2021. 1,
5, 12
[14] Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei
Fang, and Hanqing Lu. Dual attention network for scene seg-
mentation. In Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition , pages 3146–3154,
2019. 2
[15] Zhitong Gao, Yucong Chen, Chuyu Zhang, and Xuming
He. Modeling multimodal aleatoric uncertainty in segmen-
tation with mixture of stochastic expert. arXiv preprint
arXiv:2212.07328 , 2022. 2, 5, 6, 12
[16] Jiaqi Gu, Hyoukjun Kwon, Dilin Wang, Wei Ye, Meng Li,
Yu-Hsin Chen, Liangzhen Lai, Vikas Chandra, and David Z
Pan. Multi-scale high-resolution vision transformer for se-
mantic segmentation. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
12094–12103, 2022. 2
[17] Adam W Harley, Konstantinos G Derpanis, and Iasonas
Kokkinos. Segmentation-aware convolutional networks us-
ing local attention masks. In Proceedings of the IEEE Inter-
national Conference on Computer Vision , pages 5038–5047,
2017. 2
[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) , June 2016. 6
[19] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu-
sion probabilistic models. Advances in Neural Information
Processing Systems , 33:6840–6851, 2020. 2, 3, 4, 5
[20] Jonathan Ho, Chitwan Saharia, William Chan, David J. Fleet,
Mohammad Norouzi, and Tim Salimans. Cascaded diffu-
sion models for high fidelity image generation. Journal of
Machine Learning Research , 23(47):1–33, 2022. 9[21] Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick
Forr´e, and Max Welling. Argmax flows and multinomial dif-
fusion: Learning categorical distributions. Advances in Neu-
ral Information Processing Systems , 34:12454–12465, 2021.
2, 3, 4
[22] Minghui Hu, Yujie Wang, Tat-Jen Cham, Jianfei Yang, and
Ponnuthurai N Suganthan. Global context with discrete dif-
fusion in vector quantised modelling for image generation.
InProceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 11502–11511, 2022.
3
[23] Shi Hu, Daniel Worrall, Stefan Knegt, Bas Veeling, Henkjan
Huisman, and Max Welling. Supervised uncertainty quantifi-
cation for segmentation with multiple annotations. In Med-
ical Image Computing and Computer Assisted Intervention–
MICCAI 2019: 22nd International Conference, Shenzhen,
China, October 13–17, 2019, Proceedings, Part II 22 , pages
137–145. Springer, 2019. 2, 5
[24] Guillaume Jeanneret, Lo ¨ıc Simon, and Fr ´ed´eric Jurie. Diffu-
sion models for counterfactual explanations. arXiv preprint
arXiv:2203.15636 , 2022. 1
[25] Elias Kassapis, Georgi Dikov, Deepak K Gupta, and Cedric
Nugteren. Calibrated adversarial refinement for stochastic
semantic segmentation. In Proceedings of the IEEE/CVF
International Conference on Computer Vision , pages 7057–
7067, 2021. 2, 5, 6
[26] Diederik P Kingma and Jimmy Ba. Adam: A method for
stochastic optimization. International Conference for Learn-
ing Representations , 2015. 6
[27] Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr
Doll´ar. Panoptic feature pyramid networks. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 6399–6408, 2019. 2
[28] Simon Kohl, Bernardino Romera-Paredes, Clemens Meyer,
Jeffrey De Fauw, Joseph R Ledsam, Klaus Maier-Hein, SM
Eslami, Danilo Jimenez Rezende, and Olaf Ronneberger.
A probabilistic u-net for segmentation of ambiguous im-
ages. Advances in neural information processing systems ,
31, 2018. 2, 5, 6
[29] Simon AA Kohl, Bernardino Romera-Paredes, Klaus H
Maier-Hein, Danilo Jimenez Rezende, SM Eslami, Pushmeet
Kohli, Andrew Zisserman, and Olaf Ronneberger. A hierar-
chical probabilistic u-net for modeling multi-scale ambigui-
ties. arXiv preprint arXiv:1905.13077 , 2019. 2, 5, 6
[30] Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and
Artem Babenko. Tabddpm: Modelling tabular data with dif-
fusion models. arXiv preprint arXiv:2209.15421 , 2022. 2
[31] Liulei Li, Tianfei Zhou, Wenguan Wang, Jianwu Li, and Yi
Yang. Deep hierarchical semantic segmentation. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 1246–1257, 2022. 2
[32] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng
Zhang, Stephen Lin, and Baining Guo. Swin transformer:
Hierarchical vision transformer using shifted windows. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV) , 2021. 6, 7, 12
[33] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-ceedings of the IEEE conference on computer vision and pat-
tern recognition , pages 3431–3440, 2015. 2
[34] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher
Yu, Radu Timofte, and Luc Van Gool. Repaint: Inpainting
using denoising diffusion probabilistic models. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 11461–11471, 2022. 1
[35] Miguel Monteiro, Lo ¨ıc Le Folgoc, Daniel Coelho de Castro,
Nick Pawlowski, Bernardo Marques, Konstantinos Kamnit-
sas, Mark van der Wilk, and Ben Glocker. Stochastic seg-
mentation networks: Modelling spatially correlated aleatoric
uncertainty. Advances in Neural Information Processing Sys-
tems, 33:12756–12767, 2020. 2, 5, 6
[36] Alexander Quinn Nichol and Prafulla Dhariwal. Improved
denoising diffusion probabilistic models. In International
Conference on Machine Learning , pages 8162–8171. PMLR,
2021. 5, 7
[37] Di Qiu and Lok Ming Lui. Modal uncertainty estima-
tion via discrete latent representation. arXiv preprint
arXiv:2007.12858 , 2020. 2
[38] Aimon Rahman, Jeya Maria Jose Valanarasu, Ilker Haci-
haliloglu, and Vishal M Patel. Ambiguous medical image
segmentation using diffusion models. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 11536–11546, 2023. 6, 7
[39] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj ¨orn Ommer. High-resolution image
synthesis with latent diffusion models. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 10684–10695, June 2022. 9
[40] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-
net: Convolutional networks for biomedical image segmen-
tation. In International Conference on Medical image com-
puting and computer-assisted intervention , pages 234–241.
Springer, 2015. 2
[41] Chitwan Saharia, William Chan, Saurabh Saxena, Lala
Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed
Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi,
Rapha Gontijo Lopes, et al. Photorealistic text-to-image
diffusion models with deep language understanding. arXiv
preprint arXiv:2205.11487 , 2022. 1
[42] Chitwan Saharia, William Chan, Saurabh Saxena, Lala
Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed
Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan,
Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad
Norouzi. Photorealistic text-to-image diffusion models with
deep language understanding. In Alice H. Oh, Alekh Agar-
wal, Danielle Belgrave, and Kyunghyun Cho, editors, Ad-
vances in Neural Information Processing Systems , 2022. 9
[43] Raghavendra Selvan, Frederik Faye, Jon Middleton, and Ak-
shay Pai. Uncertainty quantification in medical image seg-
mentation with normalizing flows. In Machine Learning
in Medical Imaging: 11th International Workshop, MLMI
2020, Held in Conjunction with MICCAI 2020, Lima, Peru,
October 4, 2020, Proceedings 11 , pages 80–90. Springer,
2020. 2, 5, 6
[44] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,
and Surya Ganguli. Deep unsupervised learning usingnonequilibrium thermodynamics. In International Confer-
ence on Machine Learning , pages 2256–2265. PMLR, 2015.
2
[45] Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning
structured output representation using deep conditional gen-
erative models. Advances in neural information processing
systems , 28, 2015. 2
[46] MM Amaan Valiuddin, Christiaan GA Viviers, Ruud JG
van Sloun, Peter HN de With, and Fons van der Som-
men. Improving aleatoric uncertainty quantification in
multi-annotated medical image segmentation with normal-
izing flows. In Uncertainty for Safe Utilization of Ma-
chine Learning in Medical Imaging, and Perinatal Imaging,
Placental and Preterm Image Analysis: 3rd International
Workshop, UNSURE 2021, and 6th International Workshop,
PIPPI 2021, Held in Conjunction with MICCAI 2021, Stras-
bourg, France, October 1, 2021, Proceedings 3 , pages 75–
88. Springer, 2021. 2
[47] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang,
Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui
Tan, Xinggang Wang, Wenyu Liu, and Bin Xiao. Deep
high-resolution representation learning for visual recogni-
tion. TPAMI , 2019. 6, 7, 12
[48] Julia Wolleb, Robin Sandk ¨uhler, Florentin Bieder, Philippe
Valmaggia, and Philippe C Cattin. Diffusion models for
implicit image segmentation ensembles. arXiv preprint
arXiv:2112.03145 , 2021. 2
[49] Junde Wu, Huihui Fang, Yu Zhang, Yehui Yang, and Yanwu
Xu. Medsegdiff: Medical image segmentation with diffusion
probabilistic model. arXiv preprint arXiv:2211.00611 , 2022.
2
[50] Junde Wu, Rao Fu, Huihui Fang, Yu Zhang, and Yanwu
Xu. Medsegdiff-v2: Diffusion based medical image segmen-
tation with transformer. arXiv preprint arXiv:2301.11798 ,
2023. 2
[51] Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and
Jian Sun. Unified perceptual parsing for scene understand-
ing. In Proceedings of the European Conference on Com-
puter Vision (ECCV) , pages 418–434, 2018. 6, 7, 12
[52] Wei Zhang, Xiaohong Zhang, Sheng Huang, Yuting Lu, and
Kun Wang. Pixelseg: Pixel-by-pixel stochastic semantic seg-
mentation for ambiguous medical images. In Proceedings
of the 30th ACM International Conference on Multimedia ,
pages 4742–4750, 2022. 2, 6
[53] Wei Zhang, Xiaohong Zhang, Sheng Huang, Yuting Lu, and
Kun Wang. A probabilistic model for controlling diversity
and accuracy of ambiguous medical image segmentation. In
Proceedings of the 30th ACM International Conference on
Multimedia , pages 4751–4759, 2022. 2, 5, 6
[54] Yifan Zhang, Bo Pang, and Cewu Lu. Semantic segmenta-
tion by early region proxy. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 1258–1268, 2022. 2, 5
[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
Wang, and Jiaya Jia. Pyramid scene parsing network. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 2881–2890, 2017. 2[56] Roland S Zimmermann, Lukas Schott, Yang Song, Ben-
jamin A Dunn, and David A Klindt. Score-based generative
classifiers. arXiv preprint arXiv:2110.00473 , 2021. 17. Supplementary material
7.1. Metrics details
The GED and HM-IoU metrics used in our work are
computed as follows:
GED: Letpmbe the distribution over samples generated
by a model and pgtthe distribution over possible ground-
truth labels; the GED is computed as
GED(pm, pgt) =2Es∼pm,ˆs∼pgt[d(s,ˆs)]−Es,ˆs∼pgt[d(s,ˆs)]
−Es,ˆs∼pm[d(s,ˆs)], (19)
where the distance function d(·,·) = 1−IoU(·,·).
HM-IoU: Finds the optimal matching between ground
truth and generated samples. Specifically, for ngener-
ated samples, the ground-truth samples are duplicated to n.
Then, the HM-IoU is defined as the maximum IoU possible,
given that every generated sample is matched with a unique
ground-truth label, found by minimizing
HM-IoU = min
XX
iX
jd(i, j)Xi,j, (20)
where Xis a boolean matrix that assigns every row to a
unique column using d(·,·) = 1−IoU(·,·).
7.2. Sample diversity
Sample diversity is the expected distance between gen-
erated samples, i.e.,Es,ˆs∼pm[d(s,ˆs)], which corresponds to
the last term of GED in Eq. (19). We report the sample di-
versity for 16, 32, 50, and 100 samples for both LIDC splits
in Tab. 4 and Tab. 5.
LIDCv1
Method Div16 Div32 Div50 Div100
CCDM 0.491 ±0.001 0.509 ±0.001 0.515 ±0.002 0.519 ±0.002
Table 4: Sample diversity for our method on LIDCv1.
LIDCv2
Method Div16 Div32 Div50 Div100
CCDM 0.487 ±0.003 0.503 ±0.003 0.509 ±0.003 0.515 ±0.002
Table 5: Sample diversity for our method on LIDCv2.
7.3. Model size
While our 9M CCDM as reported in Tab. 1 is of compa-
rable size to most other baselines, we show in Tab. 6 that by
increasing the size of our CCDM from 9M to 41M, we getan increase in performance across all six metrics computed
on LIDCv1. Additionally, the CCDM seems to benefit more
from the increase in size than MoSE [15]. While we already
outperform the other baselines with our 9M model, this re-
sult suggests that we can improve the performance even fur-
ther by using larger models.
LIDCv1
Method #params GED 16 GED 32 GED 50 GED 100 HM-IoU 16 HM-IoU 32
MoSE [15] 9m 0.219 - 0.195 0.190 0.620 -
MoSE [15] 42m 0.218 - 0.195 0.189 0.624 -
CCDM 9m 0.212 0.194 0.187 0.183 0.623 0.631
CCDM 41m 0.207 0.189 0.182 0.177 0.629 0.636
Table 6: Performance of CCDM and MoSE on LIDCv1
with different model sizes.
7.4. Training settings of baselines on Cityscapes
On Cityscapes, all baselines were trained for 500epochs
using the optimizer, learning rate schedule, and weight de-
cay (denoted by wd) reported in their original publications.
Tab. 7 details these settings for each case. All models are
trained using a cross-entropy loss.
Method Settings
Arch. Backbone Lr Decay wd Batch Size Optim
HRNet [47] w 48v2 10−2polynomial 5×10−532 sgd
DeepLabv 3[7] ResNet 50/101 10−2polynomial 5×10−532 sgd
UPerNet [51] ResNet 101 10−2polynomial 5×10−532 sgd
UPerNet [32] Swin-T 10−4warmup+linear 10−232 AdamW
Table 7: Training settings of baselines on Cityscapes.
7.5. Additional comparisons on Cityscapes
Method mIoU
Architecture Backbone #params 128×256 256 ×512
UNet (CE) [13] - 30m 48.7 61.0
CCDM (ours) -
samples=1 30m 53.2 60.3
samples=5 30m 55.4 62.0
samples=10 30m 56.2 62.4
UNet (CE) [13] Dino ViT-S ( †) 30m + 20M 53.4 63.2
CCDM (ours) Dino ViT-S ( †)
samples=1 30m + 20M 55.5 64.0
samples=5 30m + 20M 56.9 65.4
samples=10 30m + 20M 57.3 65.8
Table 8: Comparison of our method to UNet and UNet-
Dino, trained with standard Cross-Entropy (CE) loss, on
Cityscapes-val. Bold and underlined indicate best and
second best per column, respectively. ( †) indicates self-
supervised pretraining of the backbone. Gray indicates pre-
trained, non-finetuned parameters.Figure 6: Qualitative comparisons of our method to competitive baselines on Cityscapes validation set.
Figure 7: Visualization of the forward diffusion process at different time steps.
We evaluate the gains of CCDMs with respect to their
backbone architectures when used as standalone segmenta-
tion models. To this end, we compare the performance of
our CCDM trained as defined in Alg. 1 and the UNet trained
with a standard cross-entropy loss, both on the Cityscapes
dataset. Similarly, we compare CCDM-Dino to its stan-
dalone backbone architecture DinoViT-S. In all cases, we
adopt the same training settings as our method, namely,
800epochs, linearly decayed learning rate, batch size of 32
at128×256and16at256×512. As shown in Tab. 8,
CCDM and CCDM-Dino outperform their respective stan-
dalone architectures.
We also provide additional qualitative comparisons of
our method to competitive baselines in Fig. 6. Finally,
Fig. 7 shows an example of the evolution of a Cityscapes
label map under the forward diffusion process described by
Eq. (4)."
Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient,http://arxiv.org/abs/2308.05681,"Recently, methods for skeleton-based human activity recognition have been
shown to be vulnerable to adversarial attacks. However, these attack methods
require either the full knowledge of the victim (i.e. white-box attacks),
access to training data (i.e. transfer-based attacks) or frequent model queries
(i.e. black-box attacks). All their requirements are highly restrictive,
raising the question of how detrimental the vulnerability is. In this paper, we
show that the vulnerability indeed exists. To this end, we consider a new
attack task: the attacker has no access to the victim model or the training
data or labels, where we coin the term hard no-box attack. Specifically, we
first learn a motion manifold where we define an adversarial loss to compute a
new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our
gradient contains information of the motion dynamics, which is different from
existing gradient-based attack methods that compute the loss gradient assuming
each dimension in the data is independent. The SMI gradient can augment many
gradient-based attack methods, leading to a new family of no-box attack
methods. Extensive evaluation and comparison show that our method imposes a
real threat to existing classifiers. They also show that the SMI gradient
improves the transferability and imperceptibility of adversarial samples in
both no-box and transfer-based black-box settings.","Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition
with Skeleton-Motion-Informed Gradient
Zhengzhi Lu1,2†He Wang3Ziyi Chang1Guoan Yang2Hubert P. H. Shum1‡
1Durham University, UK2Xi’an Jiaotong University, China3University College London, UK
lu947867114@stu.xjtu.edu.cn he wang@ucl.ac.uk ziyi.chang@durham.ac.uk
gayang@mail.xjtu.edu.cn hubert.shum@durham.ac.uk
Abstract
Recently, methods for skeleton-based human activity
recognition have been shown to be vulnerable to adversar-
ial attacks. However, these attack methods require either
the full knowledge of the victim (i.e. white-box attacks), ac-
cess to training data (i.e. transfer-based attacks) or fre-
quent model queries (i.e. black-box attacks). All their re-
quirements are highly restrictive, raising the question of
how detrimental the vulnerability is. In this paper, we show
that the vulnerability indeed exists. To this end, we consider
a new attack task: the attacker has no access to the vic-
tim model or the training data or labels, where we coin the
term hard no-box attack. Specifically, we first learn a mo-
tion manifold where we define an adversarial loss to com-
pute a new gradient for the attack, named skeleton-motion-
informed (SMI) gradient. Our gradient contains informa-
tion of the motion dynamics, which is different from existing
gradient-based attack methods that compute the loss gra-
dient assuming each dimension in the data is independent.
The SMI gradient can augment many gradient-based attack
methods, leading to a new family of no-box attack meth-
ods. Extensive evaluation and comparison show that our
method imposes a real threat to existing classifiers. They
also show that the SMI gradient improves the transferability
and imperceptibility of adversarial samples in both no-box
and transfer-based black-box settings.
1. Introduction
Deep learning models are vulnerable to adversarial at-
tacks, which compute data perturbations strategically to
fool trained networks. Since its discovery [31], a wide vari-
ety of models in different tasks have been attacked [1], rais-
ing severe concerns as these perturbations are impercepti-
ble to humans. Recently, the adversarial attack in skeleton-
based human activity recognition (S-HAR) has attracted at-
†This work was conducted during the visit to the Durham University.
‡Corresponding AuthorInformation
AccessibleWhite-
BoxQueried
Black-BoxTransferred
Black-BoxNo-
BoxHard
No-Box
Model Parameters ✓ × × × ×
Queries of Victims ✓ ✓ × × ×
Training Samples × × ✓ × ×
Labels ✓ ✓ ✓ ✓ ×
Table 1. Comparisons on different settings of adversarial attacks.
✓and×indicate if a method needs to access the corresponding
information.
tention as skeletal data have been widely used in security-
critical applications such as sports analysis, bio-mechanics,
surveillance, and human-computer interactions [24].
Existing attacks in S-HAR are categorized into white-
box and black-box approaches. White-box approaches
require prior knowledge of the full details of a victim
model [18, 36] while black-box approaches require a large
number of queries to the victim model [7] or the access to
training data and labels [36]. On the one hand, the victim
model details and the training data and labels are unlikely
to be available to the attacker in real-world scenarios. On
the other hand, making frequent and numerous queries (e.g.
tens of thousands) to the victim model is time-consuming
and raises suspicion. In other words, the settings of existing
S-HAR attacks are overly restrictive. A key to a success-
ful attack is to reduce the required information of the victim
model, training data and labels.
In this paper, we introduce a new threat model that re-
quires no access to the victim model, training data or labels.
We name the new threat model the hard no-box attack , dif-
ferentiating from the recent no-box attack on images [16]
that does not require access to the victim model but still
needs access to the labels (i.e. soft no-box attack). Table
1 demonstrates the comparison on different settings of ad-
versarial attacks. Among all attack settings, our hard no-
box attack requires the least amount of knowledge, as it can
only access the testing data without labels. Designing such
an attack is nontrivial and challenging. Without access to
the victim model, the attack method cannot rely on the gra-
dient of a classification loss [12], data manipulation duringarXiv:2308.05681v2  [cs.CV]  18 Aug 2023training [25], and the feedback of a classifier [2]. The chal-
lenge is further exacerbated by the requirement of no label
and training sample access, where no surrogate model can
be trained to attack or estimate the data distribution.
To tackle the challenges, we propose a contrastive learn-
ing (CL) [34] solution with a manifold-based no-box ad-
versarial loss. First, we introduce a new application of CL
to learn a latent data manifold where similar samples are
naturally aggregated while dissimilar samples are dispersed
without the need of class labels. It provides a good descrip-
tion of sample similarity that facilitates generating skele-
tal adversarial samples. CL is suitable for hard no-box at-
tack settings due to its ability to capture the discriminative
high-level features under our restricted attack conditions.
Second, we compute the perturbation to drag a data sample
away from its similar neighbors in the latent space, bounded
by a pre-defined budget. In particular, we design a new no-
box adversarial loss to maximize each adversary’s dissimi-
larity with positive samples while minimizing its similarity
with negative samples. The loss serves as guidance for the
adversary search in our gradient-based attack scheme.
While gradient-based attack methods like I-FGSM [14]
are shown to be effective on S-HAR attacks [36, 18], the
gradient is computed based on the victim model and the la-
bels, making it unsuitable for hard no-box attacks. Since
adversarial samples are likely to lie in or near the motion
manifold [7], ideally, we want to explore along the mani-
fold. That is, the computation of adversarial loss gradient
should consider the local motion manifold.
To this end, we propose to explicitly model motion dy-
namics for describing the local manifold around a given
motion. Specifically, we introduce the skeleton-motion-
informed (SMI) gradient that employs dynamics models
(e.g. Markovian and autoregressive) to represent motion
dynamics for the loss gradient computation. As a result,
while existing methods generally assume each dimension
in a data sample to be independent when computing the loss
gradient, SMI gradient explicitly considers the dependency
between frames in time. Furthermore, the SMI gradient is
compatible with existing gradient-based methods including
I-FGSM and MI-FGSM [8], allowing us to effectively con-
struct a new family of no-box attack methods.
Extensive experiments show that our method gener-
ates effective adversarial samples that successfully at-
tack various victim models across datasets (HDM05,
NTU60 and NTU120). Our SMI-gradient based attacks
improve the attack transferability in both no-box and
transferred black-box settings, with better imperceptibil-
ity. Codes are available in https://github.com/
luyg45/HardNoBoxAttack and our contributions are:
• We confirm the S-HAR threat by introducing a new hard
no-box attack and proposing the first method to generate
adversarial samples without access to the victim modelor training data or labels, to the best of our knowledge.
• We propose a new skeleton-motion-informed gradient
that guides the adversary search along the motion man-
ifold, explicitly considering the spatial-temporal nature
of skeletal motions.
• We present a family of novel gradient-based attack strate-
gies facilitated by the new gradient, improving the trans-
ferability and imperceptibility of adversarial samples in
no-box and transferred black-box attacks.
2. Related Works
Skeleton-Based Human Action Recognition S-HAR
has attracted considerable attention in many applications
[24] where deep learning-based approaches have achieved
state-of-the-art performance [30, 13]. Recurrent neural net-
works are employed to model the temporal domain of hu-
man motions [9, 29]. Furthermore, unlike images and
videos, the skeleton has a graph structure, so graph convolu-
tional networks have shown to be effective in modelling the
spatial or spatial-temporal features [28, 41]. The effective-
ness is generally achieved by considering the skeleton as a
topological graph where the joints and bones correspond to
nodes and edges [21]. Improved graph designs and network
architectures are subsequently proposed [20, 44, 45, 43].
Adversarial Attacks on Skeletons Adversarial attacks
were initially introduced in [31], which showcases the vul-
nerability of deep neural networks and has been extended
to other data types. Generally, adversarial attack is a spe-
cial technique of data augmentation that aims to reveal the
vulnerability of a system by finding new samples, while
other data augmentation techniques may have diverse pur-
poses, e.g. training efficiency and inference performance
[27]. Recently, the attack on S-HAR has received increas-
ing attention. Wang et al. [36] analyzed the perceptibility
of adversarial skeletal samples and proposed a new percep-
tual loss. Liu et al. [18] focused on GCN-based models
and utilized generative adversarial networks to synthesize
adversarial examples. Tanaka et al. [32] proposed a new
lower-dimensional attack, in which only the length of bones
could be perturbed. These methods all require the complete
knowledge of victim models, a setting known as the white-
box attack. In contrast, Diao et.al [7] introduced the first
black-box S-HAR attack method, which searches motion
manifolds for adversaries. Still, black-box attacks need to
frequently query the victim models, which can be infeasi-
ble in real-world systems. In contrast, we consider a more
practical threat setting named the hard no-box attack, where
an attacker only has access to unlabeled skeletal data.
Gradient-Based Attack Strategies The core compo-
nent of adversarial attacks is to generate adversarial samples
[1]. Gradient-based attack methods have been widely used
to introduce perturbations to a sample following the direc-
tion of the loss gradient. Goodfellow et al. [12] proposedFigure 1. The training (left) and attack (right) processes for the
hard no-box attack. The trained query encoder in the training pro-
cess is used for attacks in the attack process.
the fast gradient sign method (FGSM) that perturbs a sam-
ple by a single step along the loss gradient. Kurakin et al.
[14] proposed I-FGSM by extending FGSM to an iterative
process. Dong et al. [8] presented MI-FGSM by adding mo-
mentum to the gradient, which boosted the transferability of
adversarial samples. Xie et al. [40] applied diversified aug-
mentations to the inputs before each iteration to craft more
transferable samples. While these gradient-based strategies
are successful in static data and have been adapted to skele-
tal motions, they neglect the dependency between frames
for gradient computation, which is crucial in time series.
This motivates us to propose our skeleton-motion-informed
attack strategies, which explicitly model the motion dynam-
ics in the temporal domain [39, 35].
3. Hard No-Box Attack for Skeletal Data
Figure 1 shows the overview of our method. The left part
is the training process where we adopt contrastive learning
to obtain a latent data manifold to distinguish data samples.
The attack process is shown on the right-hand side. We first
design a new no-box adversarial loss in the trained latent
space to guide the adversary search using samples that are
dissimilar to the attacked sample. Then we propose a novel
skeleton-motion-informed gradient and a new family of at-
tack methods for generating adversarial samples.
3.1. Contrastive Learning for Motion Manifold
While the fundamental idea of adversarial attacks is to
perturb a data sample to cross class boundaries, such bound-
aries cannot be estimated for hard no-box attacks due to the
lack of labels. To estimate such boundaries without labels,
we present a new application of contrastive learning (CL)
[34] to aggregate similar data samples as soft class bound-
aries in latent space. Such boundaries enable us to adver-
sarially perturb a sample to cross boundaries. We also trainan encoder to extract discriminative high-level features for
the motion manifold in latent space. Overall, our CL con-
structs boundaries in latent space without labels via aggre-
gating similar samples and segregating dissimilar samples.
Our attack is guided by the dissimilarity of high-level fea-
tures between samples for generating adversarial samples,
instead of using class boundaries to lead the attack [2].
To incorporate both spatial and temporal information, we
train an encoder (Fig. 1 left) based on adaptive graph convo-
lutional network (AGCN) [28]. To force encoders to focus
on high-level features, we apply skeleton-specific data aug-
mentations to an input sequence Sand obtain two different
views SqandSk. Augmentations include spatial operations
(e.g. pose transformations, joint jittering, etc.) and temporal
operations (e.g. temporal crop and resize) [34] (detailed in
supplementary material). Then, we feed SqandSkinto the
query encoder fqand the key encoder fkrespectively for
the info-noise-contrastive estimation (InfoNCE) [23]:
Lcontrast = (1)
−logexp (fq(Sq)·fk(Sk)/τ)
exp (fq(Sq)·fk(Sk)/τ) +P
Fn∼Nexp (fq(Sq)·Fn/τ),
where τis the temperature parameter, Nis the dynamic
queue storing the features of negative samples Fnobtained
in the training process. After training, we use the query
encoder fq, which encodes the motion manifold, for attack.
3.2. Adversarial Loss for Unlabeled Skeletal Data
The adversarial loss of hard no-box attack is significantly
different from most existing methods that heavily depend
on labels and class boundaries. Since class labels and class
boundaries are unavailable in hard no-box attacks, we uti-
lize data samples that are dissimilar to a given sample (i.e.
negative samples ) for defining the adversarial loss. Cor-
respondingly, samples that are similar to the given sample
are considered as positive samples . We argue when a given
sample is perturbed towards its negative samples and away
from its positive samples, it tends to become an adversary.
This is because the negative samples generally indicate the
high-density areas of other classes in the latent space.
The hard no-box adversarial loss is designed as:
Ladv=−logexp [Sim(fq(s), fq(˜s))]P
jexp [Sim(fq(s), fq(˜sj))],(2)
where Sim is the cosine similarity, sis the adversarial sam-
ple to be computed, esis the clean sample regarded as the
positive sample, and esjare the negative samples. Maximiz-
ingLadvmoves saway from esand towards esjin the latent
manifold. With Ladv, gradient-based attacks are employed.
To maximize Eq. 2, the selection of negative samples esj
is crucial and we design a method tailored for no-box at-
tacks. Existing work [10] utilizes cluster-fit [42] to generatepseudo labels for selecting negative samples during adver-
sarial training, which is less suitable for the no-box attack
as it requires another pretrained off-line encoder to obtain
pseudo labels. Instead, we adapt K-means, an unsupervised
method, to select negatives, removing the need of any pre-
training. We discard Qclusters whose cluster centers are the
closest to the input sample, mitigating the risk of mislead-
ing attacks. The remaining cluster centers are considered as
the negative samples ˜sj.
4. Skeleton-Motion-Informed Gradient
Existing gradient-based attack methods treat each di-
mension of the data as an independent variable, i.e. raw
gradient. Attacks based on raw gradients tend to drag a sam-
ple away from the data manifold [11]. With the guidance of
class boundaries and a limit on the perturbation budget, the
raw gradient can still find deceiving adversaries. However,
this setting is infeasible in hard no-box attacks. Without
class boundaries, raw gradients that point to the negative
samples can drag the adversary far away from the manifold.
This is because while the perturbations are towards negative
samples, they are not necessarily in a direction orthogonal
to the class boundary. Consequently, larger perturbations
are needed to cross the boundary, leading to adversaries be-
ing far off the manifold. This creates the need to constrain
the perturbation within or near the manifold, at least locally.
Since the motion manifold is constrained by the motion dy-
namics [38], we argue that the gradient needs to explicitly
capture the dynamics. Therefore, we propose a new gradi-
ent named skeleton-motion-informed (SMI) gradient, cap-
turing the manifold information that has been largely ig-
nored by existing methods in loss gradient computation.
4.1. Dynamics in the Gradient Structure
Given a skeletal sequence S= [S1, S2,···, St]and the
adversarial loss J(S), a straightforward but effective strat-
egy to craft adversarial perturbations is the gradient-based
attack [1]. It utilizes backpropagation of the loss function
∇J(S)to iteratively change input samples S:
ˆS=S+α·sign (∇J(S)), (3)
where αis the attack step size and ˆSis the adversarial sam-
ples. In skeletal motions, this attack gradient ∇J(S)con-
sists of a set of partial derivatives over all frames:
∇J(S) =∂J(S)
∂S1,∂J(S)
∂S2,···,∂J(S)
∂St
. (4)
The partial derivative∂J(S)
∂Stassumes each frame is indepen-
dent, and this is the raw gradient employed in existing meth-
ods [36]. However, human motions contain rich dynamics
so that the system can be described as St=f(S<t). Sofar, various dynamics models have been attempted to model
human motions, such as Markovian models [33, 37], au-
toregressive models [39], and many-to-many mapping [38],
all of which can capture the dynamics at different scales in
time. We explore these models to reveal the missing dy-
namics in the structure of the raw gradient and propose our
SMI-gradients that consider motion dynamics.
Markovian Model We assume the motion dynamics can
be captured by a Markovian model, i.e. St=fd1(St−1).
This allows us to derive the 1st-order SMI-gradient:
∂J(S)
∂St−1
d1=∂J(S)
∂St−1+∂J(S)
∂St·dSt
dSt−1, (5)
wheredSt
dSt−1is the temporal relationship between two con-
secutive frames that will be instantiated. Eq. 5 shows that
the attack gradient along the motion manifold needs to con-
sider the first-order information in the motion, e.g. velocity.
Autoregressive Model Besides the first-order dynamics,
we also model the second-order dynamics by assuming
St=fd2(St−1, St−2), as2nd-order dynamics (i.e. joint ac-
celeration) capture the smooth temporal dynamics of skele-
tal motion [36]. We extend Eq. 5 as:
∂J(S)
∂St−2
d2=∂J(S)
∂St−2+∂J(S)
∂St−1·∂St−1
∂St−2
+∂J(S)
∂St·(∂St
∂St−2+∂St
∂St−1·∂St−1
∂St−2).(6)
While higher-order models can also be considered,
there is an empirical evidence that the first three or-
ders are the most important in skeletal motion adversar-
ial attack [36]. Therefore, we express the SMI gradi-
ents of the whole skeletal sequence as (∇J(S))d1=h
(∂J(S)
∂S1)d1,(∂J(S)
∂S2)d1,···,(∂J(S)
∂St)d1i
and(∇J(S))d2=h
(∂J(S)
∂S1)d2,(∂J(S)
∂S2)d2,···,(∂J(S)
∂St)d2i
.
4.2. Time-Varying Autoregressive Models for Dy-
namics
We employ explicit models [39] to compute the
dynamics-related derivatives in SMI gradients. While im-
plicit models [33] may also be considered, they would
require another network to be trained, making them less
preferable in hard no-box attacks. To realize fd1andfd2,
we use time-varying autoregressive models (TV-AR) [3],
which effectively estimates the dynamics of skeleton se-
quence [39] due to its ability of modelling the temporal
non-stationary signals:
fd1:St=At·St−1+Bt+γt, (7)fd2:St=Ct·St−1+Dt·St−2+Et+γt,(8)
where Eq. 7 and Eq. 8 are denoted as TV-AR(1) and TV-
AR(2) respectively. The model parameters β1
t= [At, Bt]
andβ2
t= [Ct, Dt, Et]are all time-varying parameters and
determined by data-fitting. γtis a time-dependent white
noise representing the dynamics of stochasticity.
Using Eq. 7 to compute∂St
∂St−1, Eq. 5 becomes:
∂J(S)
∂St−1
d1=∂J(S)
∂St−1+∂J(S)
∂St·At. (9)
Similarly, using Eq. 8, we can compute Ct=∂St
∂St−1and
Dt=∂St
∂St−2. For∂St−1
∂St−2, we use St−1=Ct−1·St−2+
Dt−1·St−3+Et−1+γtto compute it: Ct−1=∂St−1
∂St−2.
Then, Eq. 6 becomes:
∂J(S)
∂St−2
d2=∂J(S)
∂St−2+∂J(S)
∂St−1·Ct−1+∂J(S)
∂St·(Dt+Ct·Ct−1).
(10)
5. Skeleton-Motion-Informed Attack
We construct new gradient-based attack methods based
on our novel SMI gradient. Due to its compatibility, our
proposed gradient can be integrated with most existing
gradient-based methods. We select I-FGSM and MI-FGSM,
which have been proven for their efficiency on S-HAR at-
tacks [36, 18]. We augment them with first and second-
order SMI-gradients, leading to four new attack methods.
Fast Gradient Sign Methods (FGSM) FGSM [12] is
a single-step attack method that generates the adversarial
samples ˆS=S+rby maximizing the adversarial loss
function J(S), where rdenotes an adversarial perturbation
that is constrained within a budget ∥r∥p< ϵ, where ∥·∥p
denotes the lp-norm. One variant of FGSM is the Iterative
Fast Gradient Sign Method (I-FGSM) [14], which extends
FGSM to an iterative process:
ˆSi+1=ˆSi+α·sign (∇sJ(S)), (11)
where αis the attack step size and imeans iteration. An-
other variant is MI-FGSM [8], which considers the momen-
tum of the attack to avoid local maxima:
gi+1=µ·gi+∇sJ(S)
∥∇sJ(S)∥1(12)
ˆSi+1=ˆSi+α·sign 
gi+1
, (13)
where µis the momentum decay factor and giis the gradient
in iteration i.
SMI-gradient Based Attacks We replace the original
gradient ∇J(S)in I-FGSM and MI-FGSM with our SMI
gradient (∇J(S))d1or(∇J(S))d2. This creates four newAlgorithm 1 S1I-FGSM and S2I-FGSM
Input: An encoder kwith a loss function J; a skeletal sequence sample
S; the size of attack step α; iterations I; the budget of perturbation ϵ.
Output: An adversarial example ˆSwith∥ˆS−S∥p< ϵ.
1: Initialization: ˆS0=S;
2: Fitting Swith TV-AR model to obtain the time-varying parameters
βt;
3:fori= 0 toI−1do
4: Input ˆSitok;
5: Obtain the raw gradient ∇J(ˆSi)onJ;
6: Calculate the SMI gradient (∇J(ˆSi))d1with Eq. 9, or
(∇J(ˆSi))d2with Eq. 10, using βtand∇J(ˆSi);
7: Update ˆSi+1by applying the sign gradient as:
ˆSi+1=ˆSi+α·sign
∇J(ˆSi))d1
, or
ˆSi+1=ˆSi+α·sign
∇J(ˆSi))d2
.(14)
8:end for
9:return ˆS=ˆSI
dynamic attack strategies: first-order SMI I-FGSM ( S1I-
FGSM), second-order SMI I-FGSM ( S2I-FGSM), first-
order SMI MI-FGSM ( S1MI-FGSM), and second-order
SMI MI-FGSM ( S2MI-FGSM). The processes of SI-FGSM
are shown in Algorithm 1. The algorithm of SMI-FGSM
can be found in the supplementary material.
6. Experiments
We refer the readers to the supplementary material for
extra experimental results.
Datasets We select three widely used skeletal datasets:
HDM05 [22] (2,337 sequences of 130 classes performed by
5 actors), NTU60 [26] (56,880 sequences of 60 classes),
and NTU120 [19] (114,480 sequences of 120 classes, an
extended version of NTU60, one of the largest datasets in
the field). We pre-process HDM05 following [9] and both
NTU datasets following [28]. The different skeletons are
mapped to a standard 25-joint structure as in [38]. For our
hard no-box attack, we only use the testing data and do not
use the training data, the training labels and the testing la-
bels during attacks.
Target Models We choose multiple state-of-the-art mod-
els as victims: ST-GCN [41], 2s-AGCN [28], AS-GCN
[15], SGN [44] and MS-G3D [20]. They are trained us-
ing the official implementations and following the training
protocols. For 2s-AGCN, we attack both the single joint
stream model (js-AGCN) and the two-stream model.
Implementation Details We pre-train the CL encoder fq
following [34]. The unsupervised network is trained with a
temperature value τ= 0.07and SGD optimizer for 450
epochs. The learning rate is set to 0.01 with a weight decay
of 0.0001. Due to the limitation of hard no-box settings,
the attacker cannot access the training samples during the
whole process. Therefore, the encoder is trained on the test-Victim
modelsSelf-sup
AttackerAGCN
AttackerNo-box
I-FGSMNo-box
S1I-FGSMNo-box
S2I-FGSMNo-box
MI-FGSMNo-box
S1MI-FGSMNo-box
S2MI-FGSMϵ= 0.01js-AGCN 11.21% —— 26.05% 28.09% 30.87% 30.68% 34.75% 36.58 %
2s-AGCN 5.36% —— 13.94% 15.04% 16.45% 16.47% 18.23% 19.31 %
ST-GCN 3.57% 12.93% 9.55% 9.86% 9.96% 11.11% 11.36% 11.56 %
MS-G3D 8.39% 35.23% 10.57% 11.14% 11.69% 11.76% 12.85% 14.11 %
SGN 21.25% 26.03% 34.09% 34.46% 35.23% 38.49% 38.75% 38.81 %
ASGCN 5.69% 20.87% 13.92% 14.85% 14.67% 15.95% 16.82% 17.75 %ϵ= 0.008js-AGCN 10.12% —— 22.84% 24.36% 26.46% 25.70% 29.64% 30.88 %
2s-AGCN 5.04% —— 11.36% 12.19% 13.03% 12.30% 13.85% 15.56 %
ST-GCN 3.26% 10.33% 7.87% 7.99% 8.04% 8.84% 9.07% 9.19%
MS-G3D 5.19% 31.28% 9.18% 9.51% 9.99% 10.01% 10.26% 12.98 %
SGN 20.95% 23.30% 29.61% 30.20% 30.74% 33.32% 33.63% 34.54 %
ASGCN 5.54% 18.77% 11.42% 12.05% 12.29% 12.77% 13.69% 14.37 %ϵ= 0.006js-AGCN 7.19% —— 19.70% 20.32% 21.23% 20.04% 22.76% 24.33 %
2s-AGCN 3.70% —— 7.93% 9.80% 10.56% 9.80% 11.26% 12.66 %
ST-GCN 2.46% 7.88% 5.65% 5.85% 5.97% 6.25% 6.54% 6.66%
MS-G3D 4.46% 23.15% 7.30% 7.84% 7.61% 7.94% 8.05% 8.39%
SGN 16.76% 19.93% 23.92% 24.57% 25.75% 26.74% 27.04% 27.64 %
ASGCN 3.94% 14.30% 8.79% 9.23% 9.07% 9.71% 10.29% 10.90 %
Table 2. The fooling rate of different methods on the target models in NTU60, where ϵis the perturbation budget.
Victim
modelsSelf-sup
AttackerAGCN
AttackerNo-box
I-FGSMNo-box
S1I-FGSMNo-box
S2I-FGSMNo-box
MI-FGSMNo-box
S1MI-FGSMNo-box
S2MI-FGSMϵ= 0.01js-AGCN 9.97% —— 23.92% 24.64% 25.79% 27.26% 27.93% 29.07 %
2s-AGCN 6.38% —— 20.09% 21.11% 22.06% 23.51% 24.63% 24.96 %
ST-GCN 12.18% 23.84% 23.53% 24.73% 25.77% 26.95% 27.31% 28.76 %
MS-G3D 10.63% 24.63% 19.07% 20.11% 20.20% 21.57% 21.95% 22.73 %
SGN 19.65% 37.90% 31.43% 32.64% 33.75% 38.47% 37.96% 38.85 %
ASGCN 7.29% 24.15% 18.03% 19.29% 20.37% 19.88% 20.22% 21.60 %ϵ= 0.008js-AGCN 9.04% —— 21.58% 21.77% 22.47% 24.28% 24.62% 25.74 %
2s-AGCN 5.79% —— 15.71% 15.23% 15.94% 18.68% 18.76% 19.57 %
ST-GCN 11.23% 21.35% 20.74% 21.51% 22.22% 23.52% 24.65% 24.87 %
MS-G3D 9.98% 21.73% 17.06% 17.74% 17.92% 19.53% 19.29% 20.33 %
SGN 17.59% 35.88% 27.38% 28.17% 28.65% 32.43% 33.06 % 32.55%
ASGCN 6.87% 21.87% 15.73% 16.93% 17.62% 17.41% 17.75% 18.70 %ϵ= 0.006js-AGCN 8.23% —— 18.51% 18.88% 18.79% 20.74% 21.88% 22.06 %
2s-AGCN 5.09% —— 7.93% 9.80% 10.56% 9.80% 11.26% 12.66 %
ST-GCN 9.54% 17.51% 17.60% 17.97% 18.67% 18.90% 19.91% 20.34 %
MS-G3D 9.42% 18.07% 15.06% 15.09% 15.20% 16.86% 17.25% 17.56 %
SGN 16.82% 34.10% 22.39% 22.65% 22.76% 25.43% 25.79% 25.92 %
ASGCN 5.39% 19.02% 12.90% 13.45% 14.97% 14.08% 15.26% 16.33 %
Table 3. The fooling rate of different methods on the target models in NTU120, where ϵis the perturbation budget.
ing set. We adopt the l∞norm for the perturbation budget
ϵ. For clusters of negative samples, the number of clusters
is 120, and the number of deleted centers Qis 10.
Evaluation Metrics We employ the fooling rate as a
major metric. It is defined as the percentage of data sam-
ples whose predicted labels changed after adversarial at-
tacks [18]. Besides, inspired by [36], we define a percep-
tual deviation indicator to evaluate the imperceptibility of
adversarial skeletal samples:
∆p=1
MTMX
n=0S−ˆS
2+1
MTMX
n=0B−ˆB
2
+1
MTLMX
n=0¨S−¨ˆS
2(15)
where Mis the number of adversarial samples, Tis the total
number of frames, and Lis the number of joints in the skele-
ton. The three terms evaluate the deviations of joint posi-
tion, bone-length, and acceleration, respectively. A smaller
perceptual deviation indicates better imperceptibility.6.1. Hard No-Box Attack
Baselines We establish two baselines using transfer-based
attacks based on a self-supervised and a supervised classi-
fier. This is because our method is the first hard no-box
attack and there is no other similar method. The transfer-
based attack is the closest setting to ours as they do not re-
quire access to the victim model. The first baseline (Self-
sup Attacker) is a self-supervised surrogate model with a
linear layer appended to our CL encoder. We freeze our CL
encoder after the manifold training and then train the linear
layer supervisedly [17]. In this way, the need to access la-
bels is only for training the linear layer, not the CL encoder,
which is not strictly hard no-box but closer than existing
methods. The second baseline is a standard transfer-based
attack where we use js-AGCN as the surrogate model and
SMART [36] as the white-box attacker (AGCN Attacker).
Unlike our method, both baselines still require access to the
training data and the training labels during attacks.
For hard no-box attack, different attack strategies are
compared including I-FGSM, MI-FGSM, S1I-FGSM, S2I-
FGSM, S1MI-FGSM, and S2MI-FGSM. We run all the
attackers for 400 iterations and report the attack perfor-Victim
modelsSelf-sup
AttackerAGCN
AttackerNo-box
I-FGSMNo-box
S1I-FGSMNo-box
S2I-FGSMNo-box
MI-FGSMNo-box
S1MI-FGSMNo-box
S2MI-FGSMϵ= 0.01js-AGCN 10.12% —— 10.61% 10.98% 11.55% 13.45% 14.20 % 14.20 %
2s-AGCN 1.89% —— 5.30% 5.68% 5.68% 6.44% 6.44% 6.82%
ST-GCN 6.44% 24.26% 9.47% 9.85% 9.47% 8.90% 11.17% 11.74 %
MS-G3D 4.17% 86.95% 41.67% 44.51% 43.94% 53.03% 56.06 % 53.41%
SGN 1.89% 3.98% 2.46% 2.84% 3.03% 3.03% 3.40% 3.59%
ASGCN 1.89% 27.57% 3.22% 4.36% 3.22% 4.36% 5.68% 5.68%ϵ= 0.008js-AGCN 9.46% —— 8.14% 9.09% 9.09% 10.61% 10.98% 11.55 %
2s-AGCN 1.70% —— 4.36% 4.92% 4.73% 4.55% 5.30% 5.87%
ST-GCN 3.79% 21.69% 8.33% 8.52% 8.52% 8.33% 8.90% 8.33%
MS-G3D 3.60% 82.17% 25.76% 30.68% 29.17% 36.36% 39.39 % 39.02%
SGN 1.51% 3.60% 0.57% 1.51% 2.08% 2.27% 2.27% 2.46%
ASGCN 1.70% 22.43% 2.46% 2.84% 2.84% 2.27% 2.84% 3.03%ϵ= 0.006js-AGCN 7.19% —— 5.11% 7.01% 6.44% 6.06% 6.63% 7.77%
2s-AGCN 1.33% —— 2.08% 2.08% 2.27% 3.79% 3.98% 4.17%
ST-GCN 3.40% 19.85% 6.44% 7.01% 6.63% 7.58% 8.33% 7.77%
MS-G3D 2.84% 72.43% 11.55% 12.31% 11.92% 15.34% 18.94 % 17.99%
SGN 0.57% 3.40% 0.13% 0.94% 0.57% 1.13% 1.32% 1.51%
ASGCN 1.52% 17.82% 0.38% 0.76% 1.89% 0.57% 2.27% 2.27%
Table 4. The fooling rate of different methods on the target models in HDM05, where ϵis the perturbation budget.
Figure 2. Visual comparisons between attack strategies in no-box attacks ( ϵ=0.006) with key visual differences highlighted.
mance under different perturbation budgets ϵin Table 2 for
NTU60, Table 3 for NTU120, and Table 4 for HDM05. We
omit the results on js-AGCN and 2s-AGCN under AGCN
Attacker because AGCN is the surrogate model.
Table 2-4 show that the hard no-box attack poses real
threats to a range of S-HAR classifiers. In general, the fool-
ing rate of hard no-box attacks is higher than Self-sup At-
tackers. This is surprising as the Attacker utilizes training
data and training labels while our method does not. Look-
ing further, AGCN Attacker is much better than Self-sup
Attacker and the major difference is their feature extraction
(i.e. one is a CL encoder and one is a graph network). This
shows transfer-based attack heavily relies on the feature ex-
traction ability of the surrogate model that cannot bypass
access to the training data and the training labels. Further-
more, when compared with AGCN Attacker, our method
achieves similar fooling rates, varying across different vic-
tims and datasets. Given that AGCN Attacker requires ac-
cess to training data, training labels and testing labels, we
argue hard no-box attacker achieves superior results and
provides a more realistic setting.
In addition, among various no-box attack strategies,
S2MI-FGSM performs the best and often by big margins.
All the SMI gradient-based methods generate stronger ad-
versaries compared with baselines I-FGSM and MI-FGSM.
The 2nd-order SMI attack method usually outperforms the
corresponding 1st-order version. Last, we notice a variance
in fooling rate across different victims and datasets. For in-stance, the multi-stream model (2s-AGCN) significantly en-
hances the robustness compared to the single-stream model
(js-AGCN); the fooling rate of all methods drops by nearly
half. This may be because the multi-stream model can en-
semble features from different modalities, which improves
the robustness. In general, it is still an open question why
fooling rate can vary across victims and datasets and we
leave the theoretical analysis for future work.
Surrogate
ModelVictims I-FGSMMI-
FGSMS2I-FGSM
(Ours)S2MI-FGSM
(Ours)
2s-AGCNSTGCN 2.10% 2.10% 3.00% 3.01%
MS-G3D 2.58% 2.59% 2.90% 2.97%
ST-GCN2sAGCN 2.20% 2.34% 2.44% 2.64%
MS-G3D 2.00% 2.10% 2.63% 2.92%
MS-G3DSTGCN 1.71% 1.69% 2.65% 2.67%
2sAGCN 1.76% 1.79% 2.03% 2.07%
Table 5. The fooling rate of different attack strategies in transferred
SMART attacks, where attack budgets ϵ= 0.01.
6.2. Transfer-Based Black-Box Attack
SMI gradient not only improves the transferability in
hard no-box attacks, but also enhances other gradient-based
skeletal attacks. Here, we employ SMART [36], a white-
box attacker, as a baseline to compare different attack strate-
gies. In the original SMART settings, I-FGSM is adopted
to generate adversarial samples. We replace it with S2I-
FGSM, MI-FGSM, and S2MI-FGSM to make a compari-
son. As all strategies achieve similar fooling rates in white-
box attacks, we mainly focus on their transferability usingdifferent surrogate models. We utilize SMART to attack 2s-
AGCN, ST-GCN, and MS-G3D on NTU60 and transfer the
obtained samples to other victim networks.
The performance of the transferred black-box attack is
shown in Table 5. S2MI-FGSM gives the best performance
in transfer-based black-box attacks. S2I-FGSM also im-
proves the transferability of adversarial samples compared
with baselines. In contrast, MI-FGSM, which succeeds in
the image transfer-based attack, struggles in skeletal data.
Its performance declines to 1.69% when it attacks STGCN
via MS-G3D. Overall, the success rate is low in Table 5
because SMART is sensitive to the chosen surrogate [36].
Transfer-based attacks are proven to suffer from lower fool-
ing rates in S-HAR attack [36] and improving the transfer-
ability is still an open problem. Table 5 aims to show our
SMI gradient can improve it by incorporating motion dy-
namics into the attack gradient, compared with other alter-
native gradients. We will include in future work how to
further explore this dynamics for better attack transfer.
6.3. Perceptual Analysis
A key feature of SMI gradient-based attacks is the im-
provement in the perceptual quality of the adversarial sam-
ples due to the consideration of the motion manifold. To
verify this, we employ quantitative comparison and qualita-
tive visual analysis on the no-box adversarial samples under
various strategies. We compare the perceptual quality ∆p
on NTU60 in Table 6. We find that S2I-FGSM achieves the
best imperceptibility and obtains a massive improvement
compared with I-FGSM. In contrast, MI-FGSM’s deviation
is twice that of S2I-FGSM. Although S2MI-FGSM does not
achieve the best visual performance, it is still slightly better
than I-FGSM and achieves a better trade-off between fool-
ing rate and perceptual quality. This is understandable be-
cause our method considers dynamics that help to generate
more on-manifold adversarial samples. Moreover, the 1st-
order SMI attacks outperform baselines but cannot compete
with 2nd-order SMI attacks. This demonstrates the impor-
tance of considering acceleration in the skeletal attack.
We show the visual comparison of poses under vari-
ous attack strategies in no-box attacks in Figure 2. The
spinal joints demonstrate the most obvious differences. S2I-
FGSM outperforms the other attack methods and gets the
most natural poses, whereas I-FGSM has slight but notice-
able joint displacements in the neck and head. S2MI-FGSM
performs better than its baseline, MI-FGSM, which shows
zig-zag bending in the frame t0+ 2. The samples produced
by MI-FGSM have the worst imperceptibility, where we can
easily find the unnatural jittery movements.
We also evaluate perceptual quality ∆pon SMART ad-
versarial samples obtained with different gradients. Results
conducted on the NTU60 dataset are shown in Table 7. S2I-
FGSM reaches the best perceptual performance comparedwith all attack strategies. MI-FGSM slightly declines the
imperceptibility. S2MI-FGSM performs slightly worse in
MS-G3D and ST-GCN. The reason is mainly that S2MI-
FGSM takes more iterations in the white-box attack, lead-
ing to late stopping and slightly worse visual performance.
Strategies ϵ= 0.01 ϵ= 0.008 ϵ= 0.006
I-FGSM 95.87 68.56 43.13
MI-FGSM 131.77 90.44 54.61
S1I-FGSM 84.63 60.77 38.15
S1MI-FGSM 114.51 78.06 47.04
S2I-FGSM 65.60 45.67 27.67
S2MI-FGSM 90.93 62.04 37.46
Table 6. The perceptual deviation of different attack strategies in
no-box attacks with different budgets ϵ.
Victims I-FGSM MI-FGSMS2I-FGSM
(Ours)S2MI-FGSM
(Ours)
2s-AGCN 1.52 1.62 1.25 1.49
MS-G3D 2.39 2.46 1.69 3.02
ST-GCN 1.13 1.18 1.10 1.47
Table 7. The perceptual deviation of different attack strategies in
SMART for different victim models.
7. Conclusions and Discussions
In this paper, we have verified potential threats to S-HAR
solutions. A new setting is proposed: the hard no-box attack
on skeletal motions without access to the victim model, the
training samples or the labels. We validate our setting by
proposing the first pipeline for hard no-box attacks. More-
over, as far as we know, we are the first to explore motion
dynamics in the adversarial gradient computation, leading
to a new SMI gradient compatible with existing gradient-
based attacks. By extensive evaluation and comparison, our
method has been proven to be threatening and impercepti-
ble, relying on the least prior knowledge.
The SMI gradient also improves the transferability of
transferred black-box attacks. Nonetheless, boosting the
transferability is still an open problem [36] and we will ex-
plore this further with our SMI gradient in the future. We
will explore other models (e.g., diffusion models [5]) and
other time-series data (e.g. stock price, videos) for the pro-
posed attack. Also, our SMI gradient describes dynamics
and may be beneficial for motion synthesis [4].
We call for attention to intensify the S-HAR robustness
by considering defences against our hard no-box attack. We
validate randomized smoothing [6] as a potential defence
method in supplementary materials. Due to the least prior
knowledge requirement, security risks posed by our attack
can be reduced with such defenses. Otherwise, our attacks
become a significantly threat to S-HAR.
Acknowledegments
This research is supported in part by National Natural
Science Foundation of China (ref: 61673314, Yang), EP-
SRC (ref: EP/X031012/1, NortHFutures, Shum) and EU
Horizon 2020 (ref: 899739, CrowdDNA, Wang).References
[1] Naveed Akhtar, Ajmal Mian, Navid Kardan, and Mubarak
Shah. Advances in adversarial attacks and defenses in com-
puter vision: A survey. IEEE Access , 9:155161–155196,
2021.
[2] Wieland Brendel, Jonas Rauber, and Matthias Bethge.
Decision-based adversarial attacks: Reliable attacks against
black-box machine learning models. In International Con-
ference on Learning Representations , 2018.
[3] Laura F Bringmann, Ellen L Hamaker, Daniel E Vigo,
Andr ´e Aubert, Denny Borsboom, and Francis Tuerlinckx.
Changing dynamics: Time-varying autoregressive models
using generalized additive modeling. Psychological meth-
ods, 22(3):409, 2017.
[4] Ziyi Chang, Edmund JC Findlay, Haozheng Zhang, and Hu-
bert PH Shum. Unifying human motion synthesis and style
transfer with denoising diffusion probabilistic models. arXiv
preprint arXiv:2212.08526 , 2022.
[5] Ziyi Chang, George A Koulieris, and Hubert PH Shum.
On the design fundamentals of diffusion models: A survey.
arXiv preprint arXiv:2306.04542 , 2023.
[6] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified
adversarial robustness via randomized smoothing. In inter-
national conference on machine learning , pages 1310–1320.
PMLR, 2019.
[7] Yunfeng Diao, Tianjia Shao, Yong-Liang Yang, Kun Zhou,
and He Wang. Basar: Black-box attack on skeletal action
recognition. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 7597–
7607, 2021.
[8] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun
Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial at-
tacks with momentum. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition , pages
9185–9193, 2018.
[9] Yong Du, Wei Wang, and Liang Wang. Hierarchical recur-
rent neural network for skeleton based action recognition. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 1110–1118, 2015.
[10] Lijie Fan, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang,
and Chuang Gan. When does contrastive learning pre-
serve adversarial robustness from pretraining to finetun-
ing? Advances in Neural Information Processing Systems ,
34:21480–21492, 2021.
[11] Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and An-
drew B Gardner. Detecting adversarial samples from arti-
facts. arXiv preprint arXiv:1703.00410 , 2017.
[12] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
Explaining and harnessing adversarial examples. arXiv
preprint arXiv:1412.6572 , 2014.
[13] Qiuhong Ke, Mohammed Bennamoun, Senjian An, Ferdous
Sohel, and Farid Boussaid. A new representation of skele-
ton sequences for 3d action recognition. In Proceedings of
the IEEE conference on computer vision and pattern recog-
nition , pages 3288–3297, 2017.[14] Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adver-
sarial examples in the physical world , pages 99–112. Chap-
man and Hall/CRC, 2018.
[15] Maosen Li, Siheng Chen, Xu Chen, Ya Zhang, Yanfeng
Wang, and Qi Tian. Actional-structural graph convolutional
networks for skeleton-based action recognition. In Proceed-
ings of the IEEE/CVF conference on computer vision and
pattern recognition , pages 3595–3603, 2019.
[16] Qizhang Li, Yiwen Guo, and Hao Chen. Practical no-box
adversarial attacks against dnns. Advances in Neural Infor-
mation Processing Systems , 33:12849–12860, 2020.
[17] Lilang Lin, Sijie Song, Wenhan Yang, and Jiaying Liu. Ms2l:
Multi-task self-supervised learning for skeleton based action
recognition. In Proceedings of the 28th ACM International
Conference on Multimedia , pages 2490–2498, 2019.
[18] Jian Liu, Naveed Akhtar, and Ajmal Mian. Adversarial
attack on skeleton-based human action recognition. IEEE
Transactions on Neural Networks and Learning Systems ,
2020.
[19] Jun Liu, Amir Shahroudy, Mauricio Perez, Gang Wang,
Ling-Yu Duan, and Alex C Kot. Ntu rgb+ d 120: A large-
scale benchmark for 3d human activity understanding. IEEE
transactions on pattern analysis and machine intelligence ,
42(10):2684–2701, 2019.
[20] Ziyu Liu, Hongwen Zhang, Zhenghao Chen, Zhiyong Wang,
and Wanli Ouyang. Disentangling and unifying graph convo-
lutions for skeleton-based action recognition. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 143–152, 2020.
[21] Qianhui Men, Edmond S. L. Ho, Hubert P. H. Shum, and
Howard Leung. A quadruple diffusion convolutional recur-
rent network for human motion prediction. IEEE Trans-
actions on Circuits and Systems for Video Technology ,
31(9):3417–3432, 2021.
[22] Meinard M ¨uller, Tido R ¨oder, Michael Clausen, Bernhard
Eberhardt, Bj ¨orn Kr ¨uger, and Andreas Weber. Mocap
database hdm05. Institut f ¨ur Informatik II, Universit ¨at Bonn ,
2(7), 2007.
[23] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Repre-
sentation learning with contrastive predictive coding. arXiv
preprint arXiv:1807.03748 , 2018.
[24] Bin Ren, Mengyuan Liu, Runwei Ding, and Hong Liu. A
survey on 3d skeleton-based action recognition using learn-
ing method. arXiv preprint arXiv:2002.05907 , 2020.
[25] Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pir-
siavash. Hidden trigger backdoor attacks. In Proceedings of
the AAAI conference on artificial intelligence , pages 11957–
11965, 2020.
[26] Amir Shahroudy, Jun Liu, Tian-Tsong Ng, and Gang Wang.
Ntu rgb+ d: A large scale dataset for 3d human activity anal-
ysis. In Proceedings of the IEEE conference on computer
vision and pattern recognition , pages 1010–1019, 2016.
[27] Divya Shanmugam, Davis Blalock, Guha Balakrishnan, and
John Guttag. Better aggregation in test-time augmenta-
tion. In Proceedings of the IEEE/CVF International Confer-
ence on Computer Vision (ICCV) , pages 1214–1223, October
2021.[28] Lei Shi, Yifan Zhang, Jian Cheng, and Hanqing Lu. Two-
stream adaptive graph convolutional networks for skeleton-
based action recognition. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition ,
pages 12026–12035, 2019.
[29] Sijie Song, Cuiling Lan, Junliang Xing, Wenjun Zeng, and
Jiaying Liu. An end-to-end spatio-temporal attention model
for human action recognition from skeleton data. In Pro-
ceedings of the AAAI conference on artificial intelligence ,
volume 31, 2017.
[30] Tae Soo Kim and Austin Reiter. Interpretable 3d human ac-
tion analysis with temporal convolutional networks. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition workshops , pages 20–28, 2017.
[31] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.
Intriguing properties of neural networks. arXiv preprint
arXiv:1312.6199 , 2013.
[32] Nariki Tanaka, Hiroshi Kera, and Kazuhiko Kawamoto. Ad-
versarial bone length attack on action recognition. arXiv
preprint arXiv:2109.05830 , 2021.
[33] Xiangjun Tang, He Wang, Bo Hu, Xu Gong, Ruifan Yi, Qi-
long Kou, and Xiaogang Jin. Real-time controllable mo-
tion transition for characters. ACM Trans. Graph. , 41(4),
jul 2022.
[34] Fida Mohammad Thoker, Hazel Doughty, and Cees GM
Snoek. Skeleton-contrastive 3d action representation learn-
ing. In Proceedings of the 29th ACM International Confer-
ence on Multimedia , pages 1655–1663, 2021.
[35] He Wang, Yunfeng Diao, Zichang Tan, and Guodong Guo.
Defending black-box skeleton-based human activity classi-
fiers. arXiv preprint arxiv.2203.04713 , 2022.
[36] He Wang, Feixiang He, Zhexi Peng, Tianjia Shao, Yong-
Liang Yang, Kun Zhou, and David Hogg. Understanding the
robustness of skeleton-based action recognition under adver-
sarial attack. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 14656–
14665, 2021.
[37] He Wang, Edmond SL Ho, and Taku Komura. An energy-
driven motion planning method for two distant postures.
IEEE transactions on visualization and computer graphics ,
21(1):18–30, 2015.
[38] He Wang, Edmond SL Ho, Hubert PH Shum, and Zhanxing
Zhu. Spatio-temporal manifold learning for human motions
via long-horizon modeling. IEEE transactions on visualiza-
tion and computer graphics , 27(1):216–227, 2019.
[39] Shihong Xia, Congyi Wang, Jinxiang Chai, and Jessica Hod-
gins. Realtime style transfer for unlabeled heterogeneous
human motion. ACM Transactions on Graphics (TOG) ,
34(4):1–10, 2015.
[40] Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu
Wang, Zhou Ren, and Alan L Yuille. Improving transferabil-
ity of adversarial examples with input diversity. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 2730–2739, 2019.
[41] Sijie Yan, Yuanjun Xiong, and Dahua Lin. Spatial tempo-
ral graph convolutional networks for skeleton-based actionrecognition. In Thirty-second AAAI conference on artificial
intelligence , 2018.
[42] Xueting Yan, Ishan Misra, Abhinav Gupta, Deepti Ghadi-
yaram, and Dhruv Mahajan. Clusterfit: Improving gen-
eralization of visual representations. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 6509–6518, 2020.
[43] Jiahang Zhang, Lilang Lin, and Jiaying Liu. Hierarchi-
cal consistent contrastive learning for skeleton-based action
recognition with growing augmentations. arXiv preprint
arXiv:2211.13466 , 2022.
[44] Pengfei Zhang, Cuiling Lan, Wenjun Zeng, Junliang Xing,
Jianru Xue, and Nanning Zheng. Semantics-guided neural
networks for efficient skeleton-based human action recog-
nition. In proceedings of the IEEE/CVF conference on
computer vision and pattern recognition , pages 1112–1121,
2020.
[45] Yujie Zhou, Haodong Duan, Anyi Rao, Bing Su, and Jiaqi
Wang. Self-supervised action representation learning from
partial spatio-temporal skeleton sequences. arXiv preprint
arXiv:2302.09018 , 2023.Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition
with Skeleton-Motion-Informed Gradient – Supplementary Material
Zhengzhi Lu1,2†He Wang3Ziyi Chang1Guoan Yang2Hubert P. H. Shum1‡
1Durham University, UK2Xi’an Jiaotong University, China3University College London, UK
lu947867114@stu.xjtu.edu.cn he wang@ucl.ac.uk ziyi.chang@durham.ac.uk
gayang@mail.xjtu.edu.cn hubert.shum@durham.ac.uk
In this document, we first show extra experimental re-
sults for hard no-box attacks and the data fitting of time-
varying autoregressive models. Then, we give the details of
SMI-FGSM and the transfer-based black-box attack. Fur-
thermore, we describe the data augmentation approaches
used in contrastive learning. Finally, we show the attack
results of hard no-box attacks against a defense method.
1. Visual Comparisons
We demonstrate more static poses of adversarial samples
under different attack strategies in no-box attacks. These
samples are conducted on the NTU60 datasets and the per-
turbation budget ϵis 0.006. The visual comparisons are
shown in Figure 1. It is obvious that SMI gradient-based at-
tack methods improve the imperceptibility compared with
their baselines. We provide more examples in the supple-
mentary video.
2. The Number of Cluster Centers for Negative
Samples
The selection of negative samples is crucial in our hard
no-box attacks. Hence, we utilize the K-means clustering
method to obtain proper negative samples. In this part, we
study how the no-box fooling rate varies with different num-
bers of cluster centers in the K-means. The number of clus-
ter centers in K-means is set as 120, 100, 80, and 60, re-
spectively. I-FGSM [2] is adopted to generate hard no-box
adversarial samples on the NTU60. The fooling rates under
different numbers of cluster centers are reported in Table
1. All samples in the test dataset are used for clustering.
The attack with 120 cluster centers achieves the best results
when attacking MS-G3D and AS-GCN. The fooling rate of
60 cluster centers is similar to 120 and even outperforms in
js-AGCN. We speculate this might be because the NTU60
dataset is divided into 60 classes.
†This work was conducted during the visit to the Durham University.
‡Corresponding AuthorVictims 120 100 80 60
js-AGCN 27.84% 27.62% 26.89% 28.02%
MS-G3D 11.13 % 10.43% 10.70% 11.03%
AS-GCN 14.08 % 13.65% 13.90% 14.02%
Table 1. The fooling rate of the different numbers of cluster centers
in no-box attacks with ϵ= 0.01.
3. Trading-Off Sample Size and Fooling Rate
in Cluster
We utilize all the samples in the test dataset for K-means
clustering in hard no-box attacks. However, it is possible to
trade-off between the number of samples used in clustering
and the fooling rate. To reduce the calculation burden, not
all the samples are necessary for clustering. We conduct the
no-box attack results on the NTU60 with different numbers
of cluster samples, i.e. 100%, 75%, 50%, and 25% of the
dataset. We employ I-FGSM to produce no-box adversarial
samples and show the fooling rates in Table 2. The number
of cluster centers is set as 120. Using fewer samples for
clustering slightly reduces the fooling rate but gives a better
trade-off.
Victims 100% 75% 50% 25%
js-AGCN 27.84 % 27.22% 27.05% 26.51%
MS-G3D 11.13 % 10.83% 10.85% 10.80%
AS-GCN 14.08 % 13.45% 13.92% 13.43%
Table 2. The no-box fooling rate of different numbers of samples
used in clustering, ϵ= 0.01.
4. Other Comparisons
4.1. Selecting Negative Samples
Positive samples indicate boundary of same class while
negative ones indicate high-density areas of other classes.
As shown in Table 3, our ablation study shows selecting
negative ones avoids misleading perturbations.Figure 1. Visual comparisons between attack strategies in no-box attacks ( ϵ=0.006) with key visual differences highlighted.Victims w/o w
js-AGCN 31.5% 36.6%
MS-G3D 11.1% 14.1%
Table 3. The fooling rate of S 2MI-FGSM against js-AGCN and
MS-G3D without or with selection of nagative samples in no-box
attacks on NTU60 with ϵ= 0.01.
4.2. Adaptating Previous Methods to Motions
Our hard no-box setting is the strictest when compared
with no-box, black-box and white-box settings. Particu-
larly, previous no-box methods uses different, looser set-
tings where labels are usually required. On the contrary, our
hard no-box setting is stricter and does not require labels.
Moreover, our proposed method explicitly considers motion
dynamics while previous no-box methods are usually pro-
posed for images without any dynamics-related considera-
tion. Nonetheless, we still adapt a no-box method [3] to the
motion data to validate our dynamics consideration. Table
4 shows simple adaptation of previous methods to motion
data leads to worse fooling rates even if more knowledge
is used in their methods. [3] struggles to capture skeleton
dynamics but our method with SMI gradient is effective.
Victims [3] Method Our Method
js-AGCN 11.64% 26.05 %
MS-G3D 4.92% 9.55%
Table 4. The fooling rate of adapting [3] to motions and our
method against js-AGCN and MS-G3D on NTU60 with ϵ= 0.01.
4.3. Training with Training Samples Other Than
Testing Ones
Our proposed method does not necessarily require test-
ing samples that are used for attacking, and allows to be
trained on other samples. Table 5 shows the fooling rates
when our method is trained on test or other samples (sam-
ples in the training set).
Victims Testing Samples Other Samples
js-AGCN 30.87% 35.30 %
MS-G3D 11.69% 12.98 %
Table 5. The fooling rate of S 2MI-FGSM being trained on test-
ing samples or other samples against js-AGCN and MS-G3D on
NTU60 with ϵ= 0.01.
4.4. Training with Half Dataset
Our method does not rely on full dataset for both training
and attacking. We report results in Table 6. The distribution
shift in non-overlap samples for training and attacking may
lead to this slight difference.Victims Full Set Half Set
js-AGCN 9.96% 8.78%
MS-G3D 11.69 % 9.30%
Table 6. The fooling rate of S 2MI-FGSM being trained on full or
half training dataset against js-AGCN and MS-G3D on NTU60
withϵ= 0.01.
5. Data Fitting Performance of Time-varying
Autoregressive
In order to estimate SMI gradient, we employ time-
varying autoregressive (TV-AR) to model the dynamic re-
lationship in skeletal sequences. This section demonstrates
the skeletal data fitting results of TV-AR(1) and TV-AR(2)
models. Our TV-AR models constrain the mapping of the
dynamics to a specific situation, i.e. they assume that each
degree of freedom (DOF) of skeletal data is independent of
the others. The fitting curves are shown in Figure 2. Both
the TV-AR(1) and TV-AR(2) successfully model the skele-
tal sequences, and TV-AR(1) gets better fitting results.
6. The Detailed Algorithm of SMI-FGSM
In this section, we provide the algorithm of SMI-FGSM.
It is obtained by integrating the momentum term of gradi-
ents into each iteration of SI-FGSM. The whole process is
shown in the Algorithm 1.
Algorithm 1 S1MI-FGSM and S2MI-FGSM
Input: An encoder kwith loss function J; a skeletal sequence samples
S; the size of attack step α; the number of iterations I; the budget of
perturbation ϵ; the weight decay factor µ.
Output: An adversarial example ˆSwith∥ˆS−S∥p< ϵ.
1: Initialization: ˆS0=S,(g0)d1= 0,(g0)d2= 0;
2: Fitting Swith TV-AR model to obtain the time-varying parameters
βt;
3:fori= 0 toI−1do
4: Inputting ˆSitok;
5: Using loss function Jto obtain the raw gradient ∇J(ˆSi);
6: Calculating the SMI gradient (∇J(ˆSi))d1with Eq.9, or
(∇J(ˆSi))d2with Eq.10 using βtand∇J(ˆSi);
7: Updating (gi+1)d1or(gi+1)d2by accumulating the velocity
vector in the gradient direction as
(gi+1)d1=µ·(gi)d1+(∇J(ˆSi))d1/vextenddouble/vextenddouble/vextenddouble(∇J(ˆSi))d1/vextenddouble/vextenddouble/vextenddouble
1, or
(gi+1)d2=µ·(gi)d2+(∇J(ˆSi))d2/vextenddouble/vextenddouble/vextenddouble(∇J(ˆSi))d2/vextenddouble/vextenddouble/vextenddouble
1;(1)
8: Updating ˆSi+1by applying the sign gradient as
ˆSi+1=ˆSi+α·sign/parenleftbig
(gi+1)d1/parenrightbig
, or
ˆSi+1=ˆSi+α·sign/parenleftbig
(gi+1)d2/parenrightbig
;(2)
9:end for
10:return ˆS=ˆSIFigure 2. Skeletal data fitting of TV-AR model. Upper is TV-AR(2) model, and lower is TV-AR(1) model.
7. The Details of Transfer-Based Black-Box At-
tacks
We employ SMART [6] as the baseline for the transfer-
based black-box attack. SMART is a white-box attacker
which utilizes classification loss and perceptual loss to gen-
erate adversarial samples. In our experimental settings, the
attack step size αof SMART is set as 0.005, and the max-
imum iteration number is 400. In the transfer-based black-
box attack, due to SMART having the full knowledge of the
surrogate models, we adopt an early stop strategy following
its original settings. This means SMART ends the iterative
attack when it succeeds in the white-box attack to ensure
the best imperceptibility. Therefore, not all the samples are
iterated for the 400 epochs. This is a crucial distinction be-
tween the no-box attack and the transfer-based black-box
attack.
8. Skeleton Augmentations for Contrastive
Learning
In this section, we detail the skeleton augmentation
methods used in training the latent manifold for the hard
no-box attack through contrastive learning (CL). These aug-
mentations can be divided into temporal augmentations and
spatial augmentations. We combine these two methods to
create positive samples for CL. The spatial augmentations
contain pose transformation and joint jittering. The tempo-
ral augmentations are temporal crop and resize. We assume
thatSis the input skeletal sequence consisting of body
joints LinTframes.Pose Transformation We utilize pose transformation to
obtain the augmented samples that retain the same pose as
the input but vary in viewpoint and distance to the camera.
The 3D shearing is adopted to the skeletal sequence Sat
each frame for pose transformation:
Dpose(S) =S·
1r01r02
r10 1r12
r20r21 1
, (3)
where ris randomly selected from a uniform distribution
[−1,1]. We show some samples of pose transformation in
Figure 3.
Figure 3. Pose transformation augmented samples.
Joint Jittering To enhance the performance of the no-box
attack, we aim to train a data manifold that is robust to thenoise and random changes. Hence, we employ joint jittering
where the selected joints are randomly moved into irregular
positions. The augmentations can be defined as:
Djoint(S) =S[:, l]·
r00r01r02
r10r11r12
r20r21r22
, (4)
where ris randomly selected from a uniform distribution
[−1,1]andlis a subset of joints randomly chosen for each
motion. The same transformation matrix is applied to each
frame in one motion. Examples are shown in Figure 4.
Figure 4. Joint jittering augmented samples.
Temporal crop and resize Temporal relationship is crit-
ical to skeletal-related downstream tasks. Therefore, we
change the speed, and starting and ending points in the orig-
inal samples to create positive pairs. The temporal crop and
resize can be expressed as:
DTemporal (S) = Interpolate (S[Rstart:Rend]),(5)
where RstartandRendare the randomly selected starting
and ending points. We first create a new sub-sequence
(S[Rstart:Rend]), and then re-sample it to a fixed length.
The interpolation helps to get the samples varying in speeds.
Figure 5 shows the examples of temporal crop and resize,
We combine the above spatial and temporal augmenta-
tions to obtain positive samples for CL. We first apply the
temporal crop and resize to the inputs S. Then we randomly
choose the spatial augmentation from the pose transforma-
tion and the joint jittering and adopt it to the temporal aug-
mented samples.
9. Attack Results Against Defense Method
We employ randomized smoothing [1] for defense to
test our post-defense performance. The robustness of ran-
domized smoothing largely depends on a defense budget σ,
which is the magnitude of the noise added during robust
Figure 5. Temporal crop and resize.
Figure 6. Fooling rates of attack methods under different noise
intensities.
training. We test different σvalues to improve its robust-
ness. Here, we choose MS-G3D [4] as the victim model as
it is one of the latest classifiers and HDM05 as the dataset
[5]. After training, we launch our hard no-box attacks us-
ing different attack strategies. Fooling rates of these strate-
gies under different noise magnitudes are shown in Figure
6. With the improvement of the robustness of the victim
model, naturally the fooling rate of all the attack methods
has decreased, but we notice that SMI gradient still boosts
the performance compared with the raw gradient. Admit-tedly, hard-no box attacks are not as effective as other at-
tack methods, especially post-defense, but it is only because
our method has extremely limited knowledge about the data
and the victim model, compared with the settings of exist-
ing methods. We argue that the hard no-box attack is the
least restrictive attack setting so far, which itself is a contri-
bution.
References
[1] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified
adversarial robustness via randomized smoothing. In inter-
national conference on machine learning , pages 1310–1320.
PMLR, 2019.
[2] Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adver-
sarial examples in the physical world , pages 99–112. Chap-
man and Hall/CRC, 2018.
[3] Qizhang Li, Yiwen Guo, and Hao Chen. Practical no-box
adversarial attacks against dnns, 2020.
[4] Ziyu Liu, Hongwen Zhang, Zhenghao Chen, Zhiyong Wang,
and Wanli Ouyang. Disentangling and unifying graph convo-
lutions for skeleton-based action recognition. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 143–152, 2020.
[5] Meinard M ¨uller, Tido R ¨oder, Michael Clausen, Bernhard
Eberhardt, Bj ¨orn Kr ¨uger, and Andreas Weber. Mocap
database hdm05. Institut f ¨ur Informatik II, Universit ¨at Bonn ,
2(7), 2007.
[6] He Wang, Feixiang He, Zhexi Peng, Tianjia Shao, Yong-Liang
Yang, Kun Zhou, and David Hogg. Understanding the robust-
ness of skeleton-based action recognition under adversarial at-
tack. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition , pages 14656–14665,
2021."
GameFormer: Game-theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving,http://arxiv.org/abs/2303.05760,"Autonomous vehicles operating in complex real-world environments require
accurate predictions of interactive behaviors between traffic participants.
This paper tackles the interaction prediction problem by formulating it with
hierarchical game theory and proposing the GameFormer model for its
implementation. The model incorporates a Transformer encoder, which effectively
models the relationships between scene elements, alongside a novel hierarchical
Transformer decoder structure. At each decoding level, the decoder utilizes the
prediction outcomes from the previous level, in addition to the shared
environmental context, to iteratively refine the interaction process. Moreover,
we propose a learning process that regulates an agent's behavior at the current
level to respond to other agents' behaviors from the preceding level. Through
comprehensive experiments on large-scale real-world driving datasets, we
demonstrate the state-of-the-art accuracy of our model on the Waymo interaction
prediction task. Additionally, we validate the model's capacity to jointly
reason about the motion plan of the ego agent and the behaviors of multiple
agents in both open-loop and closed-loop planning tests, outperforming various
baseline methods. Furthermore, we evaluate the efficacy of our model on the
nuPlan planning benchmark, where it achieves leading performance.","GameFormer: Game-theoretic Modeling and Learning of Transformer-based
Interactive Prediction and Planning for Autonomous Driving
Zhiyu Huang†, Haochen Liu†, Chen Lv∗
Nanyang Technological University, Singapore
†Equal contribution {zhiyu001,haochen002 }@e.ntu.edu.sg
∗Corresponding author lyuchen@ntu.edu.sg
Abstract
Autonomous vehicles operating in complex real-world
environments require accurate predictions of interactive be-
haviors between traffic participants. This paper tackles
the interaction prediction problem by formulating it with
hierarchical game theory and proposing the GameFormer
model for its implementation. The model incorporates a
Transformer encoder, which effectively models the relation-
ships between scene elements, alongside a novel hierarchi-
cal Transformer decoder structure. At each decoding level,
the decoder utilizes the prediction outcomes from the previ-
ous level, in addition to the shared environmental context,
to iteratively refine the interaction process. Moreover, we
propose a learning process that regulates an agent’s be-
havior at the current level to respond to other agents’ be-
haviors from the preceding level. Through comprehensive
experiments on large-scale real-world driving datasets, we
demonstrate the state-of-the-art accuracy of our model on
the Waymo interaction prediction task. Additionally, we val-
idate the model’s capacity to jointly reason about the mo-
tion plan of the ego agent and the behaviors of multiple
agents in both open-loop and closed-loop planning tests,
outperforming various baseline methods. Furthermore, we
evaluate the efficacy of our model on the nuPlan planning
benchmark, where it achieves leading performance. Project
website: https://mczhi.github.io/GameFormer/
1. Introduction
Accurately predicting the future behaviors of surround-
ing traffic participants and making safe and socially-
compatible decisions are crucial for modern autonomous
driving systems. However, this task is highly challenging
due to the complexities arising from road structures, traffic
norms, and interactions among road users [14, 23, 24]. In
recent years, deep neural network-based approaches have
shown remarkable advancements in prediction accuracy and
scalability [7, 11, 15, 22, 40]. In particular, Transformers
have gained prominence in motion prediction [25,31,32,35,
Level -0
Level -1
Level -KInitial Modality Query
Plan
TrajectoryPredicted
TrajectoryLevel -k
Vectorized Scene
Agent History + MapAVNeighboring 
Agents
Future trajectories
Common 
backgroundFigure 1. Hierarchical game theoretic modeling of agent interac-
tions. The historical states of agents and maps are encoded as
background information; a level- 0agent’s future is predicted in-
dependently based on the initial modality query; a level- kagent
responds to all other level- (k−1)agents.
45, 47] because of their flexibility and effectiveness in pro-
cessing heterogeneous information from the driving scene,
as well as their ability to capture interrelationships among
the scene elements.
Despite the success of existing prediction models in
encoding the driving scene and representing interactions
through agents’ past trajectories, they often fail to explic-
itly model agents’ future interactions and their interaction
with the autonomous vehicle (A V). This limitation results
in a passive reaction from the A V’s planning module to the
prediction results. However, in critical situations such as
merge, lane change, and unprotected left turn, the A V needs
to proactively coordinate with other agents. Therefore, joint
prediction and planning are necessary for achieving more
interactive and human-like decision-making. To address
this, a typical approach is the recently-proposed conditional
prediction model [17,34,36,37,39], which utilizes the A V’s
internal plans to forecast other agents’ responses to the A V .
Although the conditional prediction model mitigates the in-
teraction issue, such a one-way interaction still neglects the
dynamic mutual influences between the A V and other road
users. From a game theory perspective, the current pre-
diction/planning models can be regarded as leader-follower
games with limited levels of interaction among agents.arXiv:2303.05760v2  [cs.RO]  11 Aug 2023In this study, we utilize a hierarchical game-theoretic
framework (level- kgame theory) [5, 42] to model the in-
teractions among various agents [27, 28, 41] and introduce
a novel Transformer-based prediction model named Game-
Former . Stemming from insights in cognitive science, level-
kgame theory offers a structured approach to modeling in-
teractions among agents. At its core, the theory introduces a
hierarchy of reasoning depths denoted by k. A level- 0agent
acts independently without considering the possible actions
of other agents. As we move up the hierarchy, a level- 1
agent considers interactions by assuming that other agents
are level- 0and predicts their actions accordingly. This pro-
cess continues iteratively, where a level- kagent predicts
others’ actions assuming they are level- (k−1)and responds
based on these predictions. Our model aligns with the spirit
of level- kgame theory by considering agents’ reasoning
levels and explicit interactions.
As illustrated in Fig. 1, we initially encode the driving
scene into background information, encompassing vector-
ized maps and observed agent states, using Transformer en-
coders. In the future decoding stage, we follow the level- k
game theory to design the structure. Concretely, we set up
a series of Transformer decoders to implement level- krea-
soning. The level- 0decoder employs only the initial modal-
ity query and encoded scene context as key and value to
predict the agent’s multi-modal future trajectories. Then, at
each iteration k, the level- kdecoder takes as input the pre-
dicted trajectories from the level- (k−1)decoder, along with
the background information, to predict the agent’s trajec-
tories at the current level. Moreover, we design a learning
process that regulates the agents’ trajectories to respond to
the trajectories of other agents from the previous level while
also staying close to human driving data. The main contri-
butions of this paper are summarized as follows:
1. We propose GameFormer , a Transformer-based inter-
active prediction and planning framework. The model
employs a hierarchical decoding structure to capture
agent interactions, iteratively refine predictions, and is
trained based on the level- kgame formalism.
2. We demonstrate the state-of-the-art prediction perfor-
mance of our GameFormer model on the Waymo in-
teraction prediction benchmark.
3. We validate the planning performance of the Game-
Former framework in open-loop driving scenes and
closed-loop simulations using the Waymo open motion
dataset and the nuPlan planning benchmark.
2. Related Work
2.1. Motion Prediction for Autonomous Driving
Neural network models have demonstrated remarkable
effectiveness in motion prediction by encoding contextual
scene information. Early studies utilize long short-termmemory (LSTM) networks [1] to encode the agent’s past
states and convolutional neural networks (CNNs) to pro-
cess the rasterized image of the scene [7, 12, 21, 34]. To
model the interaction between agents, graph neural net-
works (GNNs) [4, 13, 20, 30] are widely used for represent-
ing agent interactions via scene or interaction graphs. More
recently, the unified Transformer encoder-decoder structure
for motion prediction has gained popularity, e.g., Scene-
Transformer [32] and WayFormer [31], due to their com-
pact model description and superior performance. However,
most Transformer-based prediction models focus on the en-
coding part, with less emphasis on the decoding part. Mo-
tion Transformer [35] addresses this limitation by proposing
a well-designed decoding stage that leverages iterative local
motion refinement to enhance prediction accuracy. Inspired
by iterative refinement and hierarchical game theory, our
approach introduces a novel Transformer-based decoder for
interaction prediction, providing an explicit way to model
the interactions between agents.
Regarding the utilization of prediction models for plan-
ning tasks, numerous works focus on multi-agent joint mo-
tion prediction frameworks [14, 24, 30, 38] that enable effi-
cient and consistent prediction of multi-modal multi-agent
trajectories. An inherent issue in existing motion prediction
models is that they often ignore the influence of the A V’s ac-
tions, rendering them unsuitable for downstream planning
tasks. To tackle this problem, several conditional multi-
agent motion prediction models [8, 17, 36] have been pro-
posed by integrating A V planning information into the pre-
diction process. However, these models still exhibit one-
way interactions, neglecting the mutual influence among
agents. In contrast, our approach aims to jointly predict the
future trajectories of surrounding agents and facilitate A V
planning through iterative mutual interaction modeling.
2.2. Learning for Decision-making
The primary objective of the motion prediction module
is to enable the planning module to make safe and intelli-
gent decisions. This can be achieved through the use of of-
fline learning methods that can learn decision-making poli-
cies from large-scale driving datasets. Imitation learning
stands as the most prevalent approach, which aims to learn
a driving policy that can replicate expert behaviors [19,44].
Offline reinforcement learning [26] has also gained interest
as it combines the benefits of reinforcement learning and
large collected datasets. However, direct policy learning
lacks interpretability and safety assurance, and often suf-
fers from distributional shifts. In contrast, planning with a
learned motion prediction model is believed to be more in-
terpretable and robust [3, 6, 18, 46], making it a more desir-
able way for autonomous driving. Our proposed approach
aims to enhance the capability of prediction models that can
improve interactive decision-making performance.
2Transformer Encoder
Level -0 Decoder
Scene context encoding
Modality embedding 
queryAgent history 
query Query 
content
K&V×K
Agent State 
Encoder
Map Polyline 
Encoder
Self-attention
Cross -attentionK&V
GMM PredictionQuery 
content
Scores TrajectoriesLevel -k 
Decoder
...... ...
... ...Map encoding Agent encodingConcatenate
Trajectories Scores
Level -(k-1) 
future query
Level -(k-1) agent  future encodingFigure 2. Overview of our proposed GameFormer framework. The scene context encoding is obtained via a Transformer-based encoder;
the level- 0decoder takes the modality embedding and agent history encodings as query and outputs level- 0future trajectories and scores;
the level- kdecoder uses a self-attention module to model the level- (k−1) future interaction and append it to the scene context encoding.
3. GameFormer
We introduce our interactive prediction and planning
framework, called GameFormer , which adopts the Trans-
former encoder-decoder architecture (see Fig. 2). In the fol-
lowing sections, we first define the problem and discuss the
level- kgame theory that guides the design of the model and
learning process in Sec. 3.1. We then describe the encoder
component of the model, which encodes the scene context,
in Sec. 3.2, and the decoder component, which incorporates
a novel interaction modeling concept, in Sec. 3.3. Finally,
we present the learning process that accounts for interac-
tions among different reasoning levels in Sec. 3.4.
3.1. Game-theoretic Formulation
We consider a driving scene with Nagents, where
the A V is denoted as A0and its neighboring agents as
A1,···, AN−1at the current time t= 0. Given the his-
torical states of all agents (including the A V) over an ob-
servation horizon Th,S={s−Th:0
i}, as well as the map
information Mincluding traffic lights and road waypoints,
the goal is to jointly predict the future trajectories of neigh-
boring agents Y1:Tf
1:N−1over the future horizon Tf, as well
as a planned trajectory for the A V Y1:Tf
0. In order to cap-
ture the uncertainty, the results are multi-modal future tra-
jectories for the A V and neighboring agents, denoted by
Y1:Tf
i={y1:Tf
j, pj|j=1 : M}, where y1:Tf
jis a sequenceof predicted states, pjthe probability of the trajectory, and
Mthe number of modalities.
We leverage level- kgame theory to model agent interac-
tions in an iterative manner. Instead of simply predicting a
single set of trajectories, we predict a hierarchy of trajecto-
ries to model the cognitive interaction process. At each rea-
soning level, with the exception of level- 0, the decoder takes
as input the prediction results from the previous level, which
effectively makes them a part of the scene, and estimates the
responses of agents in the current level to other agents in the
previous level. We denote the predicted multi-modal trajec-
tories (essentially a Gaussian mixture model) of agent iat
reasoning level kasπ(k)
i, which can be regarded as a policy
for that agent. The policy π(k)
iis conditioned on the poli-
cies of all other agents except the i-th agent at level- (k−1),
denoted by π(k−1)
¬i. For instance, the A V’s policy at level- 2
π(2)
0would take into account all neighboring agents’ poli-
cies at level- 1π(1)
1:N−1. Formally, the i-th agent’s level- k
policy is set to optimize the following objective:
min
πiLk
i
π(k)
i|π(k−1)
¬i
, (1)
where L(·)is the loss (or cost) function. It is important to
note that policy πhere represents the multi-modal predicted
trajectories (GMM) of an agent and that the loss function is
calculated on the trajectory level.
3For the level- 0policies, they do not take into account
probable actions or reactions of other agents and instead
behave independently. Based on the level- kgame theory
framework, we design the future decoder, which we elabo-
rate upon in Section 3.3.
3.2. Scene Encoding
Input representation . The input data comprises histor-
ical state information of agents, Sp∈RN×Th×ds, where ds
represents the number of state attributes, and local vector-
ized map polylines M∈RN×Nm×Np×dp. For each agent,
we find Nmnearby map elements such as routes and cross-
walks, each containing Npwaypoints with dpattributes.
The inputs are normalized according to the state of the ego
agent, and any missing positions in the tensors are padded
with zeros.
Agent History Encoding . We use LSTM networks to
encode the historical state sequence Spfor each agent, re-
sulting in a tensor Ap∈RN×D, which contains the past
features of all agents. Here, Ddenotes the hidden feature
dimension.
Vectorized Map Encoding . To encode the local map
polylines of all agents, we use the multi-layer percep-
tron (MLP) network, which generates a map feature tensor
Mp∈RN×Nm×Np×Dwith a feature dimension of D. We
then group the waypoints from the same map element and
use max-pooling to aggregate their features, reducing the
number of map tokens. The resulting map feature tensor is
reshaped into Mr∈RN×Nmr×D, where Nmrrepresents
the number of aggregated map elements.
Relation Encoding . We concatenate the agent fea-
tures and their corresponding local map features to cre-
ate an agent-wise scene context tensor Ci= [Ap, Mi
p]∈
R(N+Nmr)×Dfor each agent. We use a Transformer en-
coder with Elayers to capture the relationships among all
the scene elements in each agent’s context tensor Ci. The
Transformer encoder is applied to all agents, generating a fi-
nal scene context encoding Cs∈RN×(N+Nmr)×D, which
represents the common environment background inputs for
the subsequent decoder network.
3.3. Future Decoding with Level- kReasoning
Modality embedding . To account for future uncertain-
ties, we need to initialize the modality embedding for each
possible future, which serves as the query to the level- 0de-
coder. This can be achieved through either a heuristics-
based method, learnable initial queries [31], or through a
data-driven method [35]. Specifically, a learnable initial
modality embedding tensor I∈RN×M×Dis generated,
where Mrepresents the number of future modalities.
Level- 0Decoding . In the level- 0decoding layer, a
multi-head cross-attention Transformer module is utilized,
which takes as input the combination of the initial modalityembedding Iand the agent’s historical encoding in the final
scene context Cs,Ap(by inflating a modality axis), result-
ing in (Cs,Ap+I)∈RN×M×Das the query and the scene
context encoding Csas the key and value. The attention is
applied to the modality axis for each agent, and the query
content features can be obtained after the attention layer as
ZL0∈RN×M×D. Two MLPs are appended to the query
content features ZL0to decode the GMM components of
predicted futures GL0∈RN×M×Tf×4(corresponding to
(µx, µy,logσx,logσy)at every timestep) and the scores of
these components PL0∈RN×M×1.
Level -(k-1) 
Scores
𝑷𝑳𝒌−𝟏 [N, M, 1 ]
Level -(k-1) 
Trajectories
𝑺𝒇𝑳𝒌−𝟏 [N, M, Tf , 2]
MLP +
Max-Pooling
Future Encoding
𝑨𝒇𝑳𝒌−𝟏 [N, D]
Self-attention Transformer
 Cross -attention Transformer
Scene Context 
Encoding
𝑪𝒔𝒊 [N+Nm , D]
MLP
Updated Scene 
Context Encoding
𝑪𝑳𝒌𝒊 [N+N+Nm, D]
MLP
Multi -future
Encoding
𝑨𝒎𝒇𝑳𝒌−𝟏 [N, M, D ]
Future Interaction
𝑨𝒇𝒊𝑳𝒌−𝟏 [N, D]
Q K V
Level -(k-1) Agent 
Query content
𝒁𝑳𝒌−𝟏 𝒊[M, D ]
Level -(k) Agent 
Scores
𝑷𝑳𝒌𝒊 [M, 1]
Level -(k) Agent 
Gaussians
𝑮𝑳𝒌𝒊 [M, Tf , 4]
Weighted
SumConcatenate
Agent Multi -future
𝑨𝒎𝒇𝒊,𝑳𝒌−𝟏 [M, D ]
Agent 
Future
MaskQ K V
Agent Query 
Content  𝒁𝑳𝒌𝒊 [M, D ]
Figure 3. The detailed structure of a level- kinteraction decoder.
Interaction Decoding . The interaction decoding stage
contains Kdecoding layers corresponding to Kreason-
ing levels. In the level- klayer ( k≥1), it receives all
agents’ trajectories from the level-( k−1) layer SLk−1
f∈
RN×M×Tf×2(the mean values of the GMM GLk−1) and
use an MLP with max-pooling on the time axis to encode
the trajectories, resulting in a tensor of agent multi-modal
future trajectory encoding ALk−1
mf∈RN×M×D. Then, we
apply weighted-average-pooling on the modality axis with
the predicted scores from the level-( k−1) layer PLk−1to
obtain the agent future features ALk−1
f∈RN×D. We use
a multi-head self-attention Transformer module to model
the interactions between agent future trajectories ALk−1
fiand
concatenate the resulting interaction features with the scene
context encoding from the encoder part. This yields an up-
4dated scene context encoding for agent i, denoted by Ci
Lk=
[ALk−1
fi, Ci
s]∈R(N+Nm+N)×D. We adopt a multi-head
cross-attention Transformer module with the query content
features from the level-( k−1) layer Zi
Lk−1and agent future
features ALk−1
mf,(Zi
Lk−1+Ai,Lk−1
mf)∈RM×Das query and
the updated scene context encoding Ci
Lkas key and value.
We use a masking strategy to prevent an agent from access-
ing its own future information from the last layer. For ex-
ample, agent A0can only get access to the future interaction
features of other agents {A1,···, AN−1}. Finally, the re-
sulting query content tensor from the cross-attention mod-
uleZi
Lkis passed through two MLPs to decode the agent’s
GMM components and scores, respectively. Fig. 3 illus-
trates the detailed structure of a level- kinteraction decoder.
Note that we share the level- kdecoder for all agents to gen-
erate multi-agent trajectories at that level. At the final level
of interaction decoding, we can obtain multi-modal trajec-
tories for the A V and neighboring agents GLK, as well as
their scores PLK.
3.4. Learning Process
We present a learning process to train our model using
the level- kgame theory formalism. First, we employ imi-
tation loss as the primary loss to regularize the agent’s be-
haviors, which can be regarded as a surrogate for factors
such as traffic regulations and driving styles. The future be-
havior of an agent is modeled as a Gaussian mixture model
(GMM), where each mode mat time step tis described by
a Gaussian distribution over the (x, y)coordinates, charac-
terized by mean µt
mand covariance σt
m. The imitation loss
is computed using the negative log-likelihood loss from the
best-predicted component m∗(closest to the ground truth)
at each timestep, as formulated:
LIL=TfX
t=1LNLL(µt
m∗, σt
m∗, pm∗,st). (2)
The negative log-likelihood loss function LNLL is de-
fined as follows:
LNLL = log σx+log σy+1
2 dx
σx2
+dx
σx2!
−log(pm∗),
(3)
where dx=sx−µxanddy=sy−µy,(sx,sy)is ground-
truth position; pm∗is the probability of the selected compo-
nent, and we use the cross-entropy loss in practice.
For a level- kagent A(k)
i, we design an auxiliary loss
function inspired by prior works [4, 16, 29] that considers
the agent’s interactions with others. The safety of agent
interactions is crucial, and we use an interaction loss (ap-
plicable only to decoding levels k≥1) to encourage the
agent to avoid collisions with the possible future trajecto-
ries of other level- (k−1)agents. Specifically, we use arepulsive potential field in the interaction loss to discourage
the agent’s future trajectories from getting too close to any
possible trajectory of any other level- (k−1)agent A(k−1)
¬i.
The interaction loss is defined as follows:
LInter =MX
m=1TfX
t=1max
∀j̸=i
∀n∈1:M1
d
ˆ s(i,k)
m,t,ˆ s(j,k−1)
n,t
+ 1,(4)
where d(·,·)is the L2distance between the future states
((x, y)positions), mis the mode of the agent i,nis the
mode of the level- (k−1)agent j. To ensure activation of
the repulsive force solely within close proximity, a safety
margin is introduced, meaning the loss is only applied to
interaction pairs with distances smaller than a threshold.
The total loss function for the level- kagent iis the
weighted sum of the imitation loss and interaction loss.
Lk
i(π(k)
i) =w1LIL(π(k)
i) +w2LInter(π(k)
i, π(k−1)
¬i),(5)
where w1andw2are the weighting factors to balance the
influence of the two loss terms.
4. Experiments
4.1. Experimental Setup
Dataset . We set up two different model variants for dif-
ferent evaluation purposes. The prediction-oriented model
is trained and evaluated using the Waymo open motion
dataset (WOMD) [9], specifically addressing the task of
predicting the joint trajectories of two interacting agents.
For the planning tasks, we train and test the models on both
WOMD with selected interactive scenarios and the nuPlan
dataset [2] with a comprehensive evaluation benchmark.
Prediction-oriented model . We adopt the setting of the
WOMD interaction prediction task, where the model pre-
dicts the joint future positions of two interacting agents 8
seconds into the future. The neighboring agents within the
scene will serve as the background information in the en-
coding stage, while only the two labeled interacting agents’
joint future trajectories are predicted. The model is trained
on the entire WOMD training dataset, and we employ the
official evaluation metrics, which include minimum aver-
age displacement error (minADE), minimum final displace-
ment error (minFDE), miss rate, and mean average preci-
sion (mAP). We investigate two different prediction model
settings. Firstly, we consider the joint prediction setting,
where only M= 6 joint trajectories of the two agents are
predicted [32]. Secondly, we examine the marginal predic-
tion setting and train our model to predict M= 64 marginal
trajectories for each agent in the interaction pair. During in-
ference, the EM method proposed in MultiPath++ [40] is
employed to generate a set of 6marginal trajectories for
each agent, from which the top 6joint predictions are se-
lected for these two agents.
5Planning-oriented model . We introduce another model
variant designed for planning tasks. Specifically, this vari-
ant takes into account multiple neighboring agents around
the A V and predicts their future trajectories. The model
is trained and tested across two datasets: WOMD and nu-
Plan. For WOMD, we randomly select 10,000 20-second
scenarios, where 9,000 of them are used for training and
the remaining 1,000 for validation. Then, we evaluate
the model’s joint prediction and planning performance on
400 9-second interactive and dynamic scenarios ( e.g., lane-
change, merge, and left-turn) in both open-loop and closed-
loop settings. To conduct closed-loop testing, we utilize
a log-replay simulator [18] to replay the original scenar-
ios involving other agents, with our planner taking control
of the A V . In open-loop testing, we employ distance-based
error metrics, which include planning ADE, collision rate,
miss rate, and prediction ADE. In closed-loop testing, we
focus on evaluating the planner’s performance in a realistic
driving context by measuring metrics including success rate
(no collision or off-route), progress along the route, longi-
tudinal acceleration and jerk, lateral acceleration, and po-
sition errors. For the nuPlan dataset, we design a compre-
hensive planning framework and adhere to the nuPlan chal-
lenge settings to evaluate the planning performance. Specif-
ically, we evaluate the planner’s performance in three tasks:
open-loop planning, closed-loop planning with non-reactive
agents, and closed-loop with reactive agents. These tasks
are evaluated using a comprehensive set of metrics pro-
vided by the nuPlan platform, and an overall score is derived
based on these tasks. More information about our models is
provided in the supplementary material.
4.2. Main Results
4.2.1 Interaction Prediction
Within the prediction-oriented model, we use a stack of
E= 6 Transformer encoder layers, and the hidden feature
dimension is set to D= 256 . We consider 20neighboring
agents around the two interacting agents as background in-
formation and employ K= 6 decoding layers. The model
only generates trajectories for the two labeled interacting
agents. Moreover, the local map elements for each agent
comprise possible lane polylines and crosswalk polylines.
Quantitative results . Table 1 summarizes the predic-
tion performance of our model in comparison with state-of-
the-art methods on the WOMD interaction prediction (joint
prediction of two interacting agents) benchmark. The met-
rics are averaged over different object types (vehicle, pedes-
trian, and cyclist) and evaluation times (3, 5, and 8 seconds).
Our joint prediction model (GameFormer (J, M=6)) outper-
forms existing methods in terms of position errors. This can
be attributed to its superior ability to capture future interac-
tions between agents through an iterative process and to pre-
dict future trajectories in a scene-consistent manner. How-ever, the scoring performance of the joint model is limited
without predicting an over-complete set of trajectories and
aggregation. To mitigate this issue, we employ the marginal
prediction model (GameFormer (M, M=64)) with EM ag-
gregation, which significantly improves the scoring perfor-
mance (better mAP metric). The overall performance of
our marginal model is comparable to that of the ensemble
and more complicated MTR model [35]. Nevertheless, it
is worth noting that marginal ensemble models may not be
practical for real-world applications due to their substan-
tial computational burden. Therefore, we utilize the joint
prediction model, which provides better prediction accuracy
and computational efficiency, for planning tests.
Table 1. Comparison with state-of-the-art models on the WOMD
interaction prediction benchmark
Model minADE ( ↓) minFDE ( ↓) Miss rate ( ↓) mAP ( ↑)
LSTM baseline [9] 1.9056 5.0278 0.7750 0.0524
Heat [30] 1.4197 3.2595 0.7224 0.0844
AIR2[43] 1.3165 2.7138 0.6230 0.0963
SceneTrans [32] 0.9774 2.1892 0.4942 0.1192
DenseTNT [15] 1.1417 2.4904 0.5350 0.1647
M2I [37] 1.3506 2.8325 0.5538 0.1239
MTR [35] 0.9181 2.0633 0.4411 0.2037
GameFormer (M, M=64) 0.9721 2.2146 0.4933 0.1923
GameFormer (J, M=6) 0.9161 1.9373 0.4531 0.1376
Qualitative results . Fig. 4 illustrates the interaction
prediction performance of our approach in several typical
scenarios. In the vehicle-vehicle interaction scenario, two
distinct situations are captured by our model: vehicle 2 ac-
celerates to take precedence at the intersection, and vehicle
2 yields to vehicle 1. In both cases, our model predicts that
vehicle 1 creeps forward to observe the actions of vehicle 2
before executing a left turn. In the vehicle-pedestrian sce-
nario, our model predicts that the vehicle will stop and wait
for the pedestrian to pass before starting to move. In the
vehicle-cyclist interaction scenario, where the vehicle in-
tends to merge into the right lane, our model predicts the
vehicle will decelerate and follow behind the cyclist in that
lane. Overall, the results manifest that our model can cap-
ture multiple interaction patterns of interacting agents and
accurately predict their possible joint futures.
4.2.2 Open-loop Planning
We first conduct the planning tests in selected WOMD sce-
narios with a prediction/planning horizon of 5 seconds. The
model uses a stack of E= 6 Transformer encoder layers,
and we consider 10neighboring agents closest to the ego
vehicle to predict M= 6joint future trajectories for them.
Determining the decoding levels . To determine the op-
timal reasoning levels for planning, we analyze the impact
of decoding layers on open-loop planning performance, and
the results are presented in Table 2. Although the planning
ADE and prediction ADE exhibit a slight decrease with ad-
6V1V2
VC
VP
t+0st+8s
lowhigh
Vehicle -Vehicle Vehicle -Pedestrian Vehicle -Cyclist Time ScoreFigure 4. Qualitative results of the proposed method in interaction prediction (multi-modal joint prediction of two interacting agents). The
red boxes are interacting agents to predict and the magenta boxes are background neighboring agents.
t+0s t+0st+5s t+5s
Roadside Parking Merge
 IntersectionTime 
egoTime 
other
Figure 5. Qualitative results of the proposed method in open-loop planning. The red box is the A V and the magenta boxes are its neighboring
agents; the red trajectory is the plan of the A V and the blue ones are the predictions of neighboring agents.
ditional decoding layers, the miss rate and collision rate are
at their lowest when the decoding level is 4. The intuition
behind this observation is that humans are capable of per-
forming only a limited depth of reasoning, and the optimal
iteration depth empirically appears to be 4in this test.
Table 2. Influence of decoding levels on open-loop planning
Level Planning ADE Collision Rate Miss Rate Prediction ADE
0 0.9458 0.0384 0.1154 1.0955
1 0.8846 0.0305 0.0994 0.9377
2 0.8529 0.0277 0.0897 0.8875
3 0.8423 0.0269 0.0816 0.8723
4 0.8329 0.0198 0.0753 0.8527
5 0.8171 0.0245 0.0777 0.8361
6 0.8208 0.0238 0.0826 0.8355
Quantitative results . Our joint prediction and planning
model employs 4decoding layers, and the results of the fi-
nal decoding layer (the most-likely future evaluated by the
trained scorer) are utilized as the plan for the A V and predic-
tions for other agents. We set up some imitation learning-
based planning methods as baselines, which are: 1) vanilla
imitation learning (IL), 2) deep imitative model (DIM) [33],
3) MultiPath++ [40] (which predicts multi-modal trajecto-
ries for the ego agent), 4) MTR-e2e (end-to-end variant withlearnable motion queries) [35], and 5) differentiable inte-
grated prediction and planning (DIPP) [18]. Table 3 reports
the open-loop planning performance of our model in com-
parison with the baseline methods. The results reveal that
our model performs significantly better than vanilla IL and
DIM, because they are just trained to output the ego’s trajec-
tory while not explicitly predicting other agents’ future be-
haviors. Compared to performant motion prediction models
(MultiPath++ and MTR-e2e), our model also shows better
planning metrics for the ego agent. Moreover, our model
outperforms DIPP (a joint prediction and planning method)
in both planning and prediction metrics, especially the col-
lision rate. These results emphasize the advantage of our
model, which explicitly considers all agents’ future behav-
iors and iteratively refines the interaction process.
Qualitative results . Fig. 5 displays qualitative results
of our model’s open-loop planning performance in complex
driving scenarios. For clarity, only the most-likely trajecto-
ries of the agents are displayed. These results demonstrate
that our model can generate a plausible future trajectory for
the A V and handle diverse interaction scenarios, and predic-
tions of the surrounding agents enhance the interpretability
of our planning model’s output.
7Table 3. Evaluation of open-loop planning performance in selected WOMD scenarios
Method Collision rate (%) Miss rate (%)Planning error (m) Prediction error (m)
@1s @3s @5s ADE FDE
Vanilla IL 4.25 15.61 0.216 1.273 3.175 – –
DIM 4.96 17.68 0.483 1.869 3.683 – –
MultiPath++ 2.86 8.61 0.146 0.948 2.719 – –
MTR-e2e 2.32 8.88 0.141 0.888 2.698 – –
DIPP 2.33 8.44 0.135 0.928 2.803 0.925 2.059
Ours 1.98 7.53 0.129 0.836 2.451 0.853 1.919
Table 4. Evaluation of closed-loop planning performance in selected WOMD scenarios
MethodSuccess rate Progress Acceleration Jerk Lateral acc. Position error to expert driver ( m)
(%) (m) (m/s2) ( m/s3) ( m/s2) @3s @5s @8s
Vanilla IL 0 6.23 1.588 16.24 0.661 9.355 20.52 46.33
RIP 19.5 12.85 1.445 14.97 0.355 7.035 17.13 38.25
CQL 10 8.28 3.158 25.31 0.152 10.86 21.18 40.17
DIPP 68.12±5.51 41.08 ±5.88 1.44±0.18 12.58 ±3.23 0.31 ±0.11 6.22±0.52 15.55 ±1.12 26.10 ±3.88
Ours 73.16±6.14 44.94 ±7.69 1.19±0.15 13.63 ±2.88 0.32 ±0.09 5.89±0.78 12.43 ±0.51 21.02 ±2.48
DIPP (w/ refinement) 92.16±0.62 51.85 ±0.14 0.58±0.03 1.54±0.19 0.11 ±0.01 2.26±0.10 5.55 ±0.24 12.53 ±0.48
Ours (w/ refinement) 94.50±0.66 52.67±0.33 0.53±0.02 1.56 ±0.23 0.10±0.01 2.11±0.21 4.87±0.18 11.13±0.33
4.2.3 Closed-loop Planning
We evaluate the closed-loop planning performance of our
model in selected WOMD scenarios. Within a simulated
environment [18], we execute the planned trajectory gener-
ated by the model and update the ego agent’s state at each
time step, while other agents follow their logged trajectories
from the dataset. Since other agents do not react to the ego
agent, the success rate is a lower bound for safety assess-
ment. For planning-based methods (DIPP and our proposed
method), we project the output trajectory onto a reference
path to ensure the ego vehicle’s adherence to the roadway.
Additionally, we employ a cost-based refinement planner
[18], which utilizes the initial output trajectory and the pre-
dicted trajectories of other agents to explicitly regulate the
ego agent’s actions. Our method is compared against four
baseline methods: 1) vanilla IL, 2) robust imitative planning
(RIP) [10], 3) conservative Q-learning (CQL) [26], and 4)
DIPP [18]. We report the means and standard deviations of
the planning-based methods over three training runs (mod-
els trained with different seeds). The quantitative results
of closed-loop testing are summarized in Table 4. The re-
sults show that the IL and offline RL methods exhibit subpar
performance in the closed-loop test, primarily due to distri-
butional shifts and casual confusion. In contrast, planning-
based methods perform significantly better across all met-
rics. Without the refinement step, our model outperforms
DIPP because it captures agent interactions more effectively
and thus the raw trajectory is closer to an expert driver.
With the refinement step, the planner becomes more robust
against training seeds, and our method surpasses DIPP be-
cause it can deliver better predictions of agent interactions
and provide a good initial plan to the refinement planner.4.2.4 nuPlan Benchmark Evaluation
To handle diverse driving scenarios in the nuPlan plat-
form [2], we develop a comprehensive planning framework
GameFormer Planner . It fulfills all important steps in the
planning pipeline, including feature processing, path plan-
ning, model query, and motion refinement. We increase the
prediction and planning horizon to 8 seconds to meet bench-
mark requirements. The evaluation is conducted over three
tasks: open-loop (OL) planning, closed-loop (CL) planning
with non-reactive agents, and closed-loop planning with re-
active agents. The score for each individual task is calcu-
lated using various metrics and scoring functions, and an
overall score is obtained by aggregating these task-specific
scores. It is important to note that we reduce the size of our
model (encoder and decoder layers) due to limited compu-
tational resources on the test server. The performance of our
model on the nuPlan test benchmark is presented in Table 5,
in comparison with other competitive learning-based meth-
ods and a rule-based approach (IDM Planner). The results
reveal the capability of our planning framework in achiev-
ing high-quality planning results across the evaluated tasks.
Moreover, the closed-loop visualization results illustrate the
ability of our model to facilitate the ego vehicle in making
interactive and human-like decisions.
Table 5. Results on the nuPlan planning test benchmark
Method Overall OL CL non-reactive CL reactive
Hoplan 0.8745 0.8523 0.8899 0.8813
Multi path 0.8477 0.8758 0.8165 0.8506
GameFormer 0.8288 0.8400 0.8087 0.8376
Urban Driver 0.7467 0.8629 0.6821 0.6952
IDM Planner 0.5912 0.2944 0.7243 0.7549
84.3. Ablation Study
Effects of agent future modeling . We investigate the
impact of different agent future modeling settings on open-
loop planning performance in WOMD scenarios. We com-
pare our base model to three ablated models: 1) No future :
agent future trajectories from the preceding level are not
incorporated in the decoding process at the current level,
2)No self-attention : agent future trajectories are incorpo-
rated but not processed through a self-attention module,
and 3) No interaction loss : the model is trained without
the proposed interaction loss. The results, as presented in
Table 6, demonstrate that our game-theoretic approach can
significantly improve planning and prediction accuracy. It
underscores the advantage of utilizing the future trajecto-
ries of agents from the previous level as contextual infor-
mation for the current level. Additionally, incorporating a
self-attention module to represent future interactions among
agents improves the accuracy of planning the prediction.
Using the proposed interaction loss during training can sig-
nificantly reduce the collision rate.
Table 6. Influence of future modeling on open-loop planning
Planning ADE Collision Rate Miss Rate Prediction ADE
No future 0.9210 0.0295 0.0963 0.9235
No self-attention 0.8666 0.0231 0.0860 0.8856
No interaction loss 0.8415 0.0417 0.0846 0.8486
Base 0.8329 0.0198 0.0753 0.8527
Influence of decoder structures . We investigate the in-
fluence of decoder structures on the open-loop planning task
in WOMD scenarios. Specifically, we examine two ablated
models. First, we assess the importance of incorporating
kindependent decoder layers, as opposed to training a sin-
gle shared interaction decoder and iteratively applying it k
times. Second, we explore the impact of simplifying the de-
coder into a multi-layer Transformer that does not generate
intermediate states. This translates into applying the loss
solely to the final decoding layer, rather than all intermedi-
ate layers. The results presented in Table 7 demonstrate bet-
ter open-loop planning performance for the base model (in-
dependent decoding layers with intermediate trajectories).
This design allows each layer to capture different levels of
relationships, thereby facilitating hierarchical modeling. In
addition, the omission of intermediate trajectory outputs can
degrade the model’s performance, highlighting the neces-
sity of regularizing the intermediate state outputs.
Table 7. Influence of decoder structures on open-loop planning
Planning ADE Collision Rate Miss Rate Prediction ADE
Base 0.8329 0.0198 0.0753 0.8547
Shared decoder 0.9196 0.0382 0.0860 0.9095
Multi-layer decoder 0.9584 0.0353 0.0988 0.9637
Ablation results on the interaction prediction task .
We investigate the influence of the decoder on the WOMDinteraction prediction task. Specifically, we vary the decod-
ing levels from 0 to 8 to determine the optimal decoding
level for this task. Moreover, we remove either the agent
future encoding part from the decoder or the self-attention
module (for modeling agent future interactions) to investi-
gate their influences on prediction performance. We train
the ablated models using the same training set and evalu-
ate their performance on the validation set. The results in
Table 8 reveal that the empirically optimal number of de-
coding layers is 6 for the interaction prediction task. It is
evident that fewer decoding layers fail to adequately cap-
ture the interaction dynamics, resulting in subpar predic-
tion performance. However, using more than 6 decoding
layers may introduce training instability and overfitting is-
sues, leading to worse testing performance. Similarly, we
find that incorporating predicted agent future information
is crucial for achieving good performance, and using self-
attention to model the interaction among agents’ futures can
also improve prediction accuracy.
Table 8. Decoder ablation results on interaction prediction
Decoding layers minADE minFDE Miss Rate mAP
K=0 1.0505 2.2905 0.5113 0.1226
K=1 1.0169 2.1876 0.5061 0.1281
K=3 0.9945 2.1143 0.5026 0.1265
K=6 0.9133 1.9251 0.4564 0.1339
K=8 0.9839 2.1515 0.5003 0.1255
K=6 w/o future 0.9862 2.0848 0.4979 0.1256
K=6 w/o self-attention 0.9263 1.9931 0.4599 0.1281
5. Conclusions
This paper introduces GameFormer , a Transformer-
based model that utilizes hierarchical game theory for in-
teractive prediction and planning. Our proposed approach
incorporates novel level- kinteraction decoders in the Trans-
former prediction model that iteratively refine the future
trajectories of interacting agents. We also implement a
learning process that regulates the predicted behaviors of
agents based on the prediction results from the previous
level. Experimental results on the Waymo open motion
dataset demonstrate that our model achieves state-of-the-art
accuracy in interaction prediction and outperforms baseline
methods in both open-loop and closed-loop planning tests.
Moreover, our proposed planning framework delivers lead-
ing performance on the nuPlan planning benchmark.
Acknowledgement
This work was supported in part by the A*STAR AME
Young Individual Research Grant (No. A2084c0156), the
MTC Individual Research Grants (No.M22K2c0079), the
ANR-NRF joint grant (No.NRF2021-NRF-ANR003 HM
Science), and the SUG-NAP Grant of Nanyang Technolog-
ical University, Singapore.
9References
[1] Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan,
Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese. So-
cial lstm: Human trajectory prediction in crowded spaces. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 961–971, 2016. 2
[2] Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye Kit
Fong, Eric Wolff, Alex Lang, Luke Fletcher, Oscar Beijbom,
and Sammy Omari. nuplan: A closed-loop ml-based plan-
ning benchmark for autonomous vehicles. In CVPR ADP3
workshop , 2021. 5, 8
[3] Sergio Casas, Abbas Sadat, and Raquel Urtasun. Mp3: A
unified model to map, perceive, predict and plan. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 14403–14412, 2021. 2
[4] Yuxiao Chen, Boris Ivanovic, and Marco Pavone. Scept:
Scene-consistent, policy-based trajectory predictions for
planning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pages 17103–
17112, 2022. 2, 5
[5] Miguel A Costa-Gomes, Vincent P Crawford, and Nagore
Iriberri. Comparing models of strategic thinking in van
huyck, battalio, and beil’s coordination games. Journal of
the European Economic Association , 7(2-3):365–376, 2009.
2
[6] Alexander Cui, Sergio Casas, Abbas Sadat, Renjie Liao,
and Raquel Urtasun. Lookout: Diverse multi-future predic-
tion and planning for self-driving. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 16107–16116, 2021. 2
[7] Henggang Cui, Vladan Radosavljevic, Fang-Chieh Chou,
Tsung-Han Lin, Thi Nguyen, Tzu-Kuo Huang, Jeff Schnei-
der, and Nemanja Djuric. Multimodal trajectory predictions
for autonomous driving using deep convolutional networks.
In2019 International Conference on Robotics and Automa-
tion (ICRA) , pages 2090–2096. IEEE, 2019. 1, 2
[8] Jose Luis Vazquez Espinoza, Alexander Liniger, Wilko
Schwarting, Daniela Rus, and Luc Van Gool. Deep inter-
active motion prediction and planning: Playing games with
motion prediction models. In Learning for Dynamics and
Control Conference , pages 1006–1019. PMLR, 2022. 2
[9] Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi
Liu, Hang Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp,
Charles R Qi, Yin Zhou, et al. Large scale interactive motion
forecasting for autonomous driving: The waymo open mo-
tion dataset. In Proceedings of the IEEE/CVF International
Conference on Computer Vision , pages 9710–9719, 2021. 5,
6
[10] Angelos Filos, Panagiotis Tigkas, Rowan McAllister,
Nicholas Rhinehart, Sergey Levine, and Yarin Gal. Can au-
tonomous vehicles identify, recover from, and adapt to dis-
tribution shifts? In International Conference on Machine
Learning , pages 3145–3153. PMLR, 2020. 8
[11] Jiyang Gao, Chen Sun, Hang Zhao, Yi Shen, Dragomir
Anguelov, Congcong Li, and Cordelia Schmid. Vectornet:
Encoding hd maps and agent dynamics from vectorized rep-
resentation. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition , pages 11525–
11533, 2020. 1
[12] Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan
Stanciulescu, and Fabien Moutarde. Home: Heatmap output
for future motion estimation. In 2021 IEEE International
Intelligent Transportation Systems Conference (ITSC) , pages
500–507. IEEE, 2021. 2
[13] Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bog-
dan Stanciulescu, and Fabien Moutarde. Gohome: Graph-
oriented heatmap output for future motion estimation. In
2022 International Conference on Robotics and Automation
(ICRA) , pages 9107–9114. IEEE, 2022. 2
[14] Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bog-
dan Stanciulescu, and Fabien Moutarde. Thomas: Trajectory
heatmap output with learned multi-agent sampling. In Inter-
national Conference on Learning Representations , 2022. 1,
2
[15] Junru Gu, Chen Sun, and Hang Zhao. Densetnt: End-to-end
trajectory prediction from dense goal sets. In Proceedings
of the IEEE/CVF International Conference on Computer Vi-
sion, pages 15303–15312, 2021. 1, 6
[16] Niklas Hanselmann, Katrin Renz, Kashyap Chitta, Apra-
tim Bhattacharyya, and Andreas Geiger. King: Generating
safety-critical driving scenarios for robust imitation via kine-
matics gradients. In European Conference on Computer Vi-
sion, pages 335–352. Springer, 2022. 5
[17] Zhiyu Huang, Haochen Liu, Jingda Wu, and Chen Lv. Con-
ditional predictive behavior planning with inverse reinforce-
ment learning for human-like autonomous driving. IEEE
Transactions on Intelligent Transportation Systems , 2023. 1,
2
[18] Zhiyu Huang, Haochen Liu, Jingda Wu, and Chen Lv. Dif-
ferentiable integrated motion prediction and planning with
learnable cost function for autonomous driving. IEEE trans-
actions on neural networks and learning systems , 2023. 2, 6,
7, 8
[19] Zhiyu Huang, Chen Lv, Yang Xing, and Jingda Wu. Multi-
modal sensor fusion-based deep neural network for end-to-
end autonomous driving with scene understanding. IEEE
Sensors Journal , 21(10):11781–11790, 2020. 2
[20] Zhiyu Huang, Xiaoyu Mo, and Chen Lv. Multi-modal mo-
tion prediction with transformer-based neural network for
autonomous driving. In 2022 International Conference on
Robotics and Automation (ICRA) , pages 2605–2611. IEEE,
2022. 2
[21] Zhiyu Huang, Xiaoyu Mo, and Chen Lv. Recoat: A deep
learning-based framework for multi-modal motion predic-
tion in autonomous driving application. In 2022 IEEE 25th
International Conference on Intelligent Transportation Sys-
tems (ITSC) , pages 988–993. IEEE, 2022. 2
[22] Xiaosong Jia, Li Chen, Penghao Wu, Jia Zeng, Junchi Yan,
Hongyang Li, and Yu Qiao. Towards capturing the tempo-
ral dynamics for trajectory prediction: a coarse-to-fine ap-
proach. In Conference on Robot Learning , pages 910–920.
PMLR, 2023. 1
[23] Xiaosong Jia, Liting Sun, Masayoshi Tomizuka, and Wei
Zhan. Ide-net: Interactive driving event and pattern extrac-
10tion from human data. IEEE Robotics and Automation Let-
ters, 6(2):3065–3072, 2021. 1
[24] Xiaosong Jia, Liting Sun, Hang Zhao, Masayoshi Tomizuka,
and Wei Zhan. Multi-agent trajectory prediction by combin-
ing egocentric and allocentric views. In Conference on Robot
Learning , pages 1434–1443. PMLR, 2022. 1, 2
[25] Xiaosong Jia, Penghao Wu, Li Chen, Yu Liu, Hongyang Li,
and Junchi Yan. Hdgt: Heterogeneous driving graph trans-
former for multi-agent trajectory prediction via scene encod-
ing. IEEE Transactions on Pattern Analysis and Machine
Intelligence (TPAMI) , 2023. 1
[26] Aviral Kumar, Aurick Zhou, George Tucker, and Sergey
Levine. Conservative q-learning for offline reinforcement
learning. Advances in Neural Information Processing Sys-
tems, 33:1179–1191, 2020. 2, 8
[27] Nan Li, Ilya Kolmanovsky, Anouck Girard, and Yildiray
Yildiz. Game theoretic modeling of vehicle interactions at
unsignalized intersections and application to autonomous ve-
hicle control. In 2018 Annual American Control Conference
(ACC) , pages 3215–3220, 2018. 2
[28] Nan Li, Dave W Oyler, Mengxuan Zhang, Yildiray Yildiz,
Ilya Kolmanovsky, and Anouck R Girard. Game theoretic
modeling of driver and vehicle interactions for verification
and validation of autonomous vehicle control systems. IEEE
Transactions on control systems technology , 26(5):1782–
1797, 2017. 2
[29] Jerry Liu, Wenyuan Zeng, Raquel Urtasun, and Ersin Yumer.
Deep structured reactive planning. In 2021 IEEE Inter-
national Conference on Robotics and Automation (ICRA) ,
pages 4897–4904. IEEE, 2021. 5
[30] Xiaoyu Mo, Zhiyu Huang, Yang Xing, and Chen Lv.
Multi-agent trajectory prediction with heterogeneous edge-
enhanced graph attention network. IEEE Transactions on
Intelligent Transportation Systems , 2022. 2, 6
[31] Nigamaa Nayakanti, Rami Al-Rfou, Aurick Zhou, Kratarth
Goel, Khaled S Refaat, and Benjamin Sapp. Wayformer:
Motion forecasting via simple & efficient attention networks.
arXiv preprint arXiv:2207.05844 , 2022. 1, 2, 4
[32] Jiquan Ngiam, Vijay Vasudevan, Benjamin Caine, Zheng-
dong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca
Roelofs, Alex Bewley, Chenxi Liu, Ashish Venugopal, et al.
Scene transformer: A unified architecture for predicting fu-
ture trajectories of multiple agents. In International Confer-
ence on Learning Representations , 2021. 1, 2, 5, 6
[33] Nicholas Rhinehart, Rowan McAllister, and Sergey Levine.
Deep imitative models for flexible inference, planning, and
control. In International Conference on Learning Represen-
tations , 2019. 7
[34] Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and
Marco Pavone. Trajectron++: Dynamically-feasible trajec-
tory forecasting with heterogeneous data. In European Con-
ference on Computer Vision , pages 683–700. Springer, 2020.
1, 2
[35] Shaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele.
Motion transformer with global intention localization and lo-
cal movement refinement. Advances in Neural Information
Processing Systems , 2022. 1, 2, 4, 6, 7[36] Haoran Song, Wenchao Ding, Yuxuan Chen, Shaojie Shen,
Michael Yu Wang, and Qifeng Chen. Pip: Planning-
informed trajectory prediction for autonomous driving. In
European Conference on Computer Vision , pages 598–614.
Springer, 2020. 1, 2
[37] Qiao Sun, Xin Huang, Junru Gu, Brian C Williams, and
Hang Zhao. M2i: From factored marginal trajectory pre-
diction to interactive prediction. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 6543–6552, 2022. 1, 6
[38] Qiao Sun, Xin Huang, Brian C Williams, and Hang Zhao.
Intersim: Interactive traffic simulation via explicit relation
modeling. In 2022 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS) , pages 11416–11423.
IEEE, 2022. 2
[39] Ekaterina Tolstaya, Reza Mahjourian, Carlton Downey,
Balakrishnan Vadarajan, Benjamin Sapp, and Dragomir
Anguelov. Identifying driver interactions via conditional be-
havior prediction. In 2021 IEEE International Conference on
Robotics and Automation (ICRA) , pages 3473–3479. IEEE,
2021. 1
[40] Balakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivas-
tava, Khaled S Refaat, Nigamaa Nayakanti, Andre Cornman,
Kan Chen, Bertrand Douillard, Chi Pang Lam, Dragomir
Anguelov, et al. Multipath++: Efficient information fu-
sion and trajectory aggregation for behavior prediction. In
2022 International Conference on Robotics and Automation
(ICRA) , pages 7814–7821. IEEE, 2022. 1, 5, 7
[41] Wenshuo Wang, Letian Wang, Chengyuan Zhang, Changliu
Liu, Lijun Sun, et al. Social interactions for autonomous
driving: A review and perspectives. Foundations and
Trends® in Robotics , 10(3-4):198–376, 2022. 2
[42] James R Wright and Kevin Leyton-Brown. Beyond equi-
librium: Predicting human behavior in normal-form games.
InTwenty-Fourth AAAI Conference on Artificial Intelligence ,
2010. 2
[43] David Wu and Yunnan Wu. Air2for interaction prediction.
arXiv preprint arXiv:2111.08184 , 2021. 6
[44] Danfei Xu, Yuxiao Chen, Boris Ivanovic, and Marco Pavone.
Bits: Bi-level imitation for traffic simulation. In 2023
IEEE International Conference on Robotics and Automation
(ICRA) , pages 2929–2936. IEEE, 2023. 2
[45] Ye Yuan, Xinshuo Weng, Yanglan Ou, and Kris M Kitani.
Agentformer: Agent-aware transformers for socio-temporal
multi-agent forecasting. In Proceedings of the IEEE/CVF
International Conference on Computer Vision , pages 9813–
9823, 2021. 1
[46] Wenyuan Zeng, Wenjie Luo, Simon Suo, Abbas Sadat, Bin
Yang, Sergio Casas, and Raquel Urtasun. End-to-end in-
terpretable neural motion planner. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 8660–8669, 2019. 2
[47] Zikang Zhou, Luyao Ye, Jianping Wang, Kui Wu, and Ke-
jie Lu. Hivt: Hierarchical vector transformer for multi-agent
motion prediction. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
8823–8833, 2022. 1
11GameFormer: Game-theoretic Modeling and Learning of Transformer-based
Interactive Prediction and Planning for Autonomous Driving
Supplementary Material
A. Experiment Details
A.1. Prediction-oriented Model
Model inputs . In each scene, one of the two interacting
agents is designated as the focal agent, with its current state
serving as the origin of the coordinate system. We consider
10 surrounding agents closest to a target agent as the back-
ground agents, and therefore, there are two target agents to
predict and up to 20 different background agents in a scene.
The current and historical states of each agent are retrieved
for the last one second at a sampling rate of 10Hz, result-
ing in a tensor with a shape of (22×11)for each agent.
The state at each timestep includes the agent’s position
(x, y), heading angle ( θ), velocity ( vx, vy), bounding box
size (L, W, H ), and one-hot category encoding of the agent
(totally three types). All historical states for each agent are
aggregated into a fixed-shape tensor of (22×11×11), with
missing agent states padded as zeros, to form the input ten-
sor of historical agent states.
For each target agent, up to 6 drivable lanes (each extend-
ing 100 meters) that the agent may take are identified using
depth-first search on the road graph, along with 4 nearby
crosswalks as the local map context, with each map vector
containing 100 waypoints. The features of a waypoint in a
drivable lane include the position and heading angles of the
centerline, left boundary, and right boundary, speed limit, as
well as discrete attributes such as the lane type, traffic light
state, and controlled by a stop sign. The features of a way-
point in the crosswalk polyline only encompass position and
heading angle. Therefore, the local map context for a tar-
get agent comprises two tensors: drivable lanes with shape
(6×100×15)and crosswalks with shape (4×100×3).
Encoder structure . In the encoder part, we utilize two
separate LSTMs to encode the historical states of the target
and background agents, respectively, resulting in a tensor
with shape (22×256) that encompasses all agents’ histor-
ical state sequences. The local map context encoder con-
sists of a lane encoder for processing the drivable lanes and
a crosswalk encoder for the crosswalk polylines. The lane
encoder employs MLPs to encode numeric features and em-
bedding layers to encode discrete features, outputting a ten-
sor of encoded lane vectors with shape (2×6×100×256) ,
while the crosswalk encoder uses an MLP to encode nu-
meric features, resulting in a tensor of crosswalk vectors
with shape (2×4×100×256) . Subsequently, we utilize a
max-pooling layer (with a step size of 10) to aggregate the
waypoints from a drivable lane in the encoded lane tensor,yielding a tensor with shape (2×6×10×256) that is re-
shaped to (2×60×256) . Similarly, the encoded crosswalk
tensor is processed using a max-pooling layer with a step
size of 20 to obtain a tensor with shape (2×20×256) .
These two tensors are concatenated to produce an encoded
local map context tensor with shape (2×80×256) . For
each target agent, we concatenate its local map context ten-
sor with the historical state tensor of all agents to obtain a
scene context tensor with dimensions of (102×256) , and
we use self-attention Transformer encoder layers to extract
the relationships among the elements in the scene. It is im-
portant to note that invalid positions in the scene context
tensor are masked from attention calculations.
Decoder structure . For the M= 6 joint prediction
model, we employ the learnable latent modality embedding
with a shape of ( 2×6×256). For each agent, the query
(6×256) in the level-0 decoder is obtained by summing
up the encoding of the target agent’s history and its corre-
sponding latent modality embedding; the value and key are
derived from the scene context by the encoder. The level-0
decoder generates the multi-modal future trajectories of the
target agent with xandycoordinates using an MLP from
the attention output. The scores of each trajectory are de-
coded by another MLP with a shape of (6×1). In a level-
kdecoder, we use a shared future encoder across different
layers, which includes an MLP and a max-pooling layer, to
encode the future trajectories from the previous level into
a tensor with a shape of (6×256) . Next, we employ the
trajectory scores to average-pool the encoded trajectories,
which results in the encoded future of the agent. The en-
coded futures of the two target agents are then fed into a
self-attention Transformer layer to model their future inter-
action. Finally, the output of the Transformer layer is ap-
pended to the scene context obtained from the encoder.
For the M= 64 marginal prediction model, we use a set
of 64 fixed intention points that are encoded with MLPs to
create the modality embedding with shape ( 2×64×256).
This modality embedding serves as the query input for the
level-0 decoder. The fixed intention points are obtained
through the K-means method from the training dataset. For
each scene, the intention points for the two target agents are
normalized based on the focal agent’s coordinate system.
The other components of the decoder are identical to those
used in the joint prediction model.
Training . In the training dataset, each scene contains
several agent tracks to predict, and we consider each track
sequentially as the focal agent, while the closest track to
12the focal agent is chosen as the interacting agent. The task
is to predict six possible joint future trajectories of these
two agents. We employ only imitation loss at each level to
improve the prediction accuracy and training efficiency.
In the joint prediction model, we aim to predict the joint
and scene-level future trajectories of the two agents. There-
fore, we backpropagate the loss through the joint future
trajectories of the two agents that most closely match the
ground truth (i.e., have the least sum of displacement er-
rors). In the marginal prediction model, we backpropagate
the imitation loss to the individual agent through the posi-
tive GMM component that corresponds to the closest inten-
tion point to the endpoint of the ground-truth trajectory.
Our models are trained for 30 epochs using the AdamW
optimizer with a weight decay of 0.01. The learning rate
starts with 1e-4 and decays by a factor of 0.5 every 3 epochs
after 15 epochs. We also clip the gradient norm of the net-
work parameters with the max norm of the gradients as 5.
We train the models using 4 NVIDIA Tesla V100 GPUs,
with a batch size of 64 per GPU.
Testing . The testing dataset has three types of agents:
vehicle, pedestrian, and cyclist. For the vehicle-vehicle in-
teraction, we randomly select one of the two vehicles as
the focal agent. For other types of interaction pairs ( e.g.,
cyclist-vehicle and pedestrian-vehicle), we consider the cy-
clist or pedestrian as the focal agent. For the marginal pre-
diction model, we employ the Expectation-Maximization
(EM) method to aggregate trajectories for each agent.
Specifically, we use the EM method to obtain 6 marginal
trajectories (along with their probabilities) from the 64 tra-
jectories predicted for each agent. Then, we consider the
top 6 joint predictions from the 36 possible combinations of
the two agents, where the confidence of each combination
is the product of the marginal probabilities.
A.2. Planning-oriented Model
Model inputs . In each scene, we consider the A V and 10
surrounding agents to perform planning for the A V and pre-
diction for other agents. The A V’s current state is the origin
of the local coordinate system. The historical states of all
agents in the past two seconds are extracted; for each agent,
we find its nearby 6 drivable lanes and 4 crosswalks. Addi-
tionally, we extract the A V’s traversed lane waypoints from
its ground truth future trajectory and use a cubic spline to
interpolate these waypoints to generate the A V’s reference
route. The reference route extends 100 meters ahead of the
A V and contains 1000 waypoints with 0.1 meters intervals.
It is represented as a tensor with shape (1000×5). The ref-
erence route tensor also contains information on the speed
limit and stop points in addition to positions and headings.
Model structure . For each agent, its scene context ten-
sor is created as a concatenation of all agents’ historical
states and encoded local map elements, resulting in a ten-sor of shape (91×256) . In the decoding stage, a learn-
able modality embedding of size (11×6×256) and the
agent’s historical encoding are used as input to the level-0
decoder, which outputs six possible trajectories along with
corresponding scores. In the level- kdecoder, the future en-
codings of all agents are obtained through a self-attention
module of size (11×256) , and are concatenated with the
scene context tensor from the encoder. This concatenation
generates an updated scene context tensor with a shape of
(102×256) . When decoding an agent’s future trajectory
at the current level, the future encoding of that agent in the
scene context tensor is masked to avoid using its previously
predicted future information.
Training . In data processing, we filter those scenes
where the A V’s moving distance is less than 5 meters ( e.g.,
when stopping at a red light). Similarly, we perform joint
future prediction and calculate the imitation loss through
the joint future that is closest to the ground truth. The
weights for the imitation loss and interaction loss are set
tow1= 1, w2= 0.1. Our model is trained for 20 epochs
using the AdamW optimizer with a weight decay of 0.01.
The learning rate is initialized to 1e-4 and decreases by a
factor of 0.5 every 2 epochs after the 10th epoch. We train
the model using an NVIDIA RTX 3080 GPU, with a batch
size of 32.
Testing . The testing scenarios are extracted from the
WOMD, wherein the ego agent shows dynamic driving be-
haviors1. In open-loop testing, we check collisions between
the A V’s planned trajectory and other agents’ ground-truth
future trajectories, and we count a miss if the distance be-
tween A V’s planned state at the final step and the ground-
truth state is larger than 4.5 meters. The planning errors and
prediction errors are calculated according to the most-likely
trajectories scored by the model. In closed-loop testing, the
A V plans a trajectory at every timestep with an interval of
0.1 seconds and executes the first step of the plan.
A.3. Baseline Methods
To compare model performance, we introduce the fol-
lowing learning-based planning baselines.
Vanilla Imitation Learning (IL) : A simplified version
of our model that directly outputs the planned trajectory of
the A V without explicitly reasoning other agents’ future tra-
jectories. The plan is only a single-modal trajectory. The
original encoder part of our model is utilized, but only one
decoder layer with the ego agent’s historical encoding as the
query is used to decode the A V’s plan.
Deep Imitative Model (DIM) : A probabilistic planning
method that aims to generate expert-like future trajectories
q(S1:T|ϕ) =QT
t=1q(St|S1:t−1, ϕ)given the A V’s obser-
1https://github.com/smarts-project/smarts-
project.offline-datasets/blob/master/waymo_
candid_list.csv
13vations ϕ. We follow the original open-source DIM imple-
mentation and use the rasterized scene image R200×200×3
and the A V’s historical states R11×5as the observation. We
use a CNN to encode the scene image and an RNN to en-
code the agent’s historical states. The A V’s future state is
decoded (as a multivariate Gaussian distribution) in an au-
toregressive manner. In testing, DIM requires a specific
goalGto direct the agent to the goal, and a gradient-based
planner maximizes the learned imitation prior logq(S|ϕ)
and the test-time goal likelihood logp(G|S, ϕ).
Robust Imitative Planning (RIP) : An epistemic
uncertainty-aware planning method that is developed upon
DIM and shows good performance in conducting robust
planning in out-of-distribution (OOD) scenarios. Specifi-
cally, we employ the original open-source implementation
and choose the worst-case model that has the worst likeli-
hood mindlogq(S1:T|ϕ)among d= 6 trained DIM mod-
els and improve it with a gradient-based planner.
Conservative Q-Learning (CQL) : A widely-used of-
fline reinforcement learning algorithm that learns to make
decisions from offline datasets. We implement the CQL
method with the d3rlpy offline RL library2. The RL agent
takes the same state inputs as the DIM method and outputs
the target pose of the next step (∆x,∆y,∆θ)relative to the
agent’s current position. The reward function is the distance
traveled per step plus an extra reward for reaching the goal,
i.e.,rt= ∆dt+10× 1(d(st, sgoal)<1). Since the dataset
only contains perfect driving data, no collision penalty is
included in the reward function.
Differentiable Integrated Prediction and Planning
(DIPP) : A joint prediction and planning method that uses a
differentiable motion planner to optimize the trajectory ac-
cording to the prediction result. We adopt the original open-
source implementation and the same state input setting. We
increase the historical horizon to 20 and the number of pre-
diction modalities from 3 to 6. In open-loop testing, we uti-
lize the results from the DIPP prediction network without
trajectory planning (refinement).
MultiPath++ : A high-performing motion prediction
model that is based on the context-aware fusion of hetero-
geneous scene elements and learnable latent anchor embed-
dings. We utilize the open-source implementation of Mul-
tiPath++3that achieved state-of-the-art prediction accuracy
on the WOMD motion prediction benchmark. We train the
model to predict 6 possible trajectories and corresponding
scores for the ego agent using the same dataset. In open-
loop testing, only the most-likely trajectory will be used as
the plan for the A V .
Motion Transformer (MTR)-e2e : A state-of-the-art
prediction model that occupies the first place on the WOMD
2https://github.com/takuseno/d3rlpy
3https://github.com/stepankonev/waymo-motion-
prediction-challenge-2022-multipath-plus-plusmotion prediction leaderboard. We follow the original
open-source implementation of the context encoder and
MTR decoder. However, we modified the decoder to use
an end-to-end variant of MTR that is better suited for the
open-loop planning task. Specifically, only 6 learnable mo-
tion query pairs are used to decode 6 possible trajectories
and scores. The same dataset is used to train the MTR-e2e
model, and the data is processed according to the MTR con-
text inputs.
A.4. Refinement Planner
Inverse dynamic model . To convert the initial planned
trajectory to control actions {at, δt}(i.e., acceleration and
yaw rate), we utilize the following inverse dynamic model.
Φ−1:vt=∆p
∆t=∥pt+1−pt∥
∆t,
θt= arctan∆py
∆px,
at=vt+1−vt
∆t,
δt=θt+1−θt
∆t,(S1)
where ptis a predicted coordinate in the trajectory, and ∆t
is the time interval.
Dynamic model . To derive the coordinate and heading
{pxt, pyt, θ}from control actions, we adopt the following
differentiable dynamic model.
Φ :vt+1=at∆t+vt,
θt+1=δt∆t+θt,
pxt+1=vtcosθt∆t+pxt,
pyt+1=vtsinθt∆t+pyt.(S2)
Motion planner . We use a differentiable motion plan-
ner proposed in DIPP to plan the trajectory for the A V . The
planner takes as input the initial control action sequence de-
rived from the planned trajectory given by our model. We
formulate each planning cost term cias a squared vector-
valued residual, and the motion planner aims to solve the
following nonlinear least squares problem:
u∗= arg min
u1
2X
i∥ωici(u)∥2, (S3)
where uis the sequence of control actions, and ωiis the
weight for cost ci.
We consider a variety of cost terms as proposed in DIPP,
including travel speed, control effort (acceleration and yaw
rate), ride comfort (jerk and change of yaw rate), distance
to the reference line, heading difference, as well as the cost
of violating traffic light. Most importantly, the safety cost
takes all other agents’ predicted states into consideration
and avoids collision with them, as illustrated in DIPP.
14We use the Gauss-Newton method to solve the optimiza-
tion problem. The maximum number of iterations is 30,
and the step size is 0.3. We use the best solution during the
iteration process as the final plan to execute.
Learning cost function weights . Since the motion plan-
ner is differentiable, we can learn the weights of the cost
terms by differentiating through the optimizer. We use the
imitation learning loss below (average displacement error
and final displacement error) to learn the cost weights, as
well as minimize the sum of cost values. We set the maxi-
mum number of iterations to 3 and the step size to 0.5 in the
motion planner. We use the Adam optimizer with a learning
rate of 5e-4 to train the cost function weights; the batch size
is 32 and the total number of training steps is 10,000.
L=λ1X
t||ˆst−st||2+λ2||ˆsT−sT||2+λ3X
i||ci||2,
(S4)
where λ1= 1, λ2= 0.5, λ3= 0.001are the weights.
A.5. GameFormer Planner
To validate our model’s performance on the nuPlan
benchmark4, we have developed a comprehensive planning
framework to handle the realistic driving scenarios in nu-
Plan. The planning process comprises the following steps:
1) feature processing: relevant data from the observation
buffer and map API undergoes preprocessing to extract in-
put features for the prediction model; 2) path planning: can-
didate route paths for the ego vehicle are computed, from
which the optimal path is selected as the reference path; 3)
model query: the prediction model is queried to generate
an initial plan for the ego vehicle and predict the trajecto-
ries of surrounding agents; and 4) trajectory refinement: a
nonlinear optimizer is employed to refine the ego vehicle’s
trajectory on the reference path and produce the final plan.
For computational efficiency, we use a compact version of
the GameFormer model, configuring it with 3 encoding lay-
ers and 3 decoding layers (1 initial decoding layer and 2
interaction decoding layers). Additionally, we introduce an
extra decoding layer after the last interaction decoding layer
to separately generate the ego vehicle’s plan. The ego plan
is then projected onto the reference path as an initialization
of the refinement planner. The output of the GameFormer
model consists of multimodal trajectories for the surround-
ing agents. For each neighboring agent, we select the trajec-
tory with the highest probability and project it onto the ref-
erence path using the Frenet transformation, subsequently
calculating spatiotemporal path occupancy. A comprehen-
sive description of the planning framework can be found in
this dedicated report5.
4https://eval.ai/web/challenges/challenge-
page/1856/overview
5https://opendrivelab.com/e2ead/AD23Challenge/
Track_4_AID.pdfB. Additional Quantitative Results
B.1. Interaction Prediction
Table S1 displays the per-category performance of our
models on the WOMD interaction prediction benchmark,
in comparison with the MTR model. The GameFormer
joint prediction model exhibits the lowest minFDE across
all object categories, indicating the advantages of our model
and joint training of interaction patterns. Our Game-
Former model surpasses MTR in the cyclist category and
achieves comparable performance to MTR in other cate-
gories, though with a much simpler structure than MTR.
Table S1. Per-class performance of interaction prediction on the
WOMD interaction prediction benchmark
Class Model minADE ( ↓) minFDE ( ↓) Miss rate ( ↓) mAP ( ↑)
VehicleMTR 0.9793 2.2157 0.3833 0.2977
GF (J) 0.9822 2.0745 0.3785 0.1856
GF (M) 1.0499 2.4044 0.4321 0.2469
PedestrianMTR 0.7098 1.5835 0.3973 0.2033
GF (J) 0.7279 1.4894 0.4272 0.1505
GF (M) 0.7978 1.8195 0.4713 0.1962
CyclistMTR 1.0652 2.3908 0.5428 0.1102
GF (J) 1.0383 2.2480 0.5536 0.0768
GF (M) 1.0686 2.4199 0.5765 0.1338
B.2. nuPlan Benchmark
Table S2 presents a performance comparison between
our planner and the DIPP planner. For the benchmark eval-
uation, we replace the prediction model in the proposed
planning framework with the DIPP model and other parts
of the framework remain the same. The results show that
the GameFormer model still outperforms the DIPP model,
as a result of better initial plans for the ego agent and pre-
diction results for other agents.
Table S2. Comparison with DIPP planner on the nuPlan testing
benchmark
Method Overall OL CL non-reactive CL reactivate
DIPP 0.7950 0.8141 0.7853 0.7857
Ours 0.8288 0.8400 0.8087 0.8376
B.3. Abalation Study
Effects of decoding levels on closed-loop planning .
We investigate the influence of decoding levels on closed-
loop planning performance in selected WOMD scenarios,
using the success rate (without collision) as the main metric.
We also report the inference time of the prediction network
(without the refine motion planner) in closed-loop planning,
which is executed on an NVIDIA RTX 3080 GPU. The re-
sults in Table S3 reveal that increasing the decoding lay-
ers could potentially lead to a higher success rate, and even
adding a single layer of interaction modeling can bring sig-
nificant improvement compared to level- 0. In closed-loop
15testing, the success rate reaches a plateau at a decoding
level of 2, while the computation time continues to increase.
Therefore, using two reasoning levels in our model may of-
fer a favorable balance between performance and efficiency
in practical applications.
Table S3. Effects of decoding levels on closed-loop planning
Level Success rate (%) Inference time (ms)
0 89.5 31.8
1 92.25 44.1
2 94 56.7
3 94.5 66.5
4 94.5 79.2
C. Additional Qualitative Results
C.1. Interaction Prediction
Fig. S1 presents additional qualitative results of our
GameFormer framework in the interaction prediction task,
showcasing the ability of our method to handle a variety of
interaction pairs and complex urban driving scenarios.
C.2. Level- kPrediction
Fig. S2 illustrates the most-likely joint trajectories of
the target agents at different interaction levels. The results
demonstrate that our proposed model is capable of refining
the prediction results in the iterated interaction process. At
level- 0, the predictions for target agents appear more inde-
pendent, potentially leading to trajectory collisions. How-
ever, through iterative refinement, our model can generate
consistent and human-like trajectories at a higher interac-
tion level.
C.3. Open-loop Planning
Fig. S3 provides additional qualitative results of our
model in the open-loop planning task, which show the abil-
ity of our model to jointly plan the trajectory of the A V and
predict the behaviors of neighboring agents.
C.4. Closed-loop Planning
We visualize the closed-loop planning performance of
our method through videos available on the project website,
including interactive urban driving scenarios from both the
WOMD and nuPlan datasets.
16t+0st+8s
lowhigh
Figure S1. Additional qualitative results of interaction prediction. The red boxes are interacting agents to predict, and the magenta boxes
are background neighboring agents. Six joint trajectories of the two interacting agents are predicted.
17t+0st+8s
Scene 1 Scene 2Level -0 Level -2 Level -4
Figure S2. Prediction results of the two interacting agents at different reasoning levels. Only the most-likely joint trajectories of the target
agents are displayed for clarity.
t+0s t+0st+5s t+5s
Figure S3. Additional qualitative results of open-loop planning. The red box is the A V and the magenta boxes are its neighboring agents;
the red trajectory is the plan of the A V and the blue ones are the predictions of neighboring agents.
18"
Learning in Imperfect Environment: Multi-Label Classification with Long-Tailed Distribution and Partial Labels,http://arxiv.org/abs/2304.10539,"Conventional multi-label classification (MLC) methods assume that all samples
are fully labeled and identically distributed. Unfortunately, this assumption
is unrealistic in large-scale MLC data that has long-tailed (LT) distribution
and partial labels (PL). To address the problem, we introduce a novel task,
Partial labeling and Long-Tailed Multi-Label Classification (PLT-MLC), to
jointly consider the above two imperfect learning environments. Not
surprisingly, we find that most LT-MLC and PL-MLC approaches fail to solve the
PLT-MLC, resulting in significant performance degradation on the two proposed
PLT-MLC benchmarks. Therefore, we propose an end-to-end learning framework:
\textbf{CO}rrection $\rightarrow$ \textbf{M}odificat\textbf{I}on $\rightarrow$
balan\textbf{C}e, abbreviated as \textbf{\method{}}. Our bootstrapping
philosophy is to simultaneously correct the missing labels (Correction) with
convinced prediction confidence over a class-aware threshold and to learn from
these recall labels during training. We next propose a novel multi-focal
modifier loss that simultaneously addresses head-tail imbalance and
positive-negative imbalance to adaptively modify the attention to different
samples (Modification) under the LT class distribution. In addition, we develop
a balanced training strategy by distilling the model's learning effect from
head and tail samples, and thus design a balanced classifier (Balance)
conditioned on the head and tail learning effect to maintain stable performance
for all samples. Our experimental study shows that the proposed \method{}
significantly outperforms general MLC, LT-MLC and PL-MLC methods in terms of
effectiveness and robustness on our newly created PLT-MLC datasets.","Learning in Imperfect Environment: Multi-Label Classiﬁcation
with Long-Tailed Distribution and Partial Labels
Wenqiao Zhang
National University of Singapore
wenqiao@nus.edu.sgChangshuo Liu
National University of Singapore
changshuo@u.nus.edu
Lingze Zeng
National University of Singapore
lingze@nus.edu.sgBeng Chin Ooi
National University of Singapore
ooibc@comp.nus.edu.sg
Siliang Tang
Zhejiang University
siliang@zju.edu.cnYueting Zhuang
Zhejiang University
yzhuang@zju.edu.cn
Abstract
Conventional multi-label classiﬁcation (MLC) meth-
ods assume that all samples are fully labeled and iden-
tically distributed. Unfortunately, this assumption is
unrealistic in large-scale MLC data that has long-tailed
(LT) distribution and partial labels (PL). To address the
problem, we introduce a novel task, Partial labeling and
Long-Tailed Multi-Label Classiﬁcation (PLT-MLC), to
jointly consider the above two imperfect learning envi-
ronments. Not surprisingly, we ﬁnd that most LT-MLC
and PL-MLC approaches fail to solve the PLT-MLC,
resulting in signiﬁcant performance degradation on the
two proposed PLT-MLC benchmarks. Therefore, we pro-
pose an end-to-end learning framework: COrrection!
Modiﬁcat Ion!balanCe, abbreviated as COMIC . Our
bootstrapping philosophy is to simultaneously correct the
missing labels (Correction) with convinced prediction
conﬁdence over a class-aware threshold and to learn
from these recall labels during training. We next pro-
pose a novel multi-focal modiﬁer loss that simultaneously
addresses head-tail imbalance and positive-negative im-
balance to adaptively modify the attention to diﬀerent
samples (Modiﬁcation) under the LT class distribution.
In addition, we develop a balanced training strategy
by distilling the model’s learning eﬀect from head and
tail samples, and thus design a balanced classiﬁer (Bal-
ance) conditioned on the head and tail learning eﬀect
to maintain stable performance for all samples. Our
experimental study shows that the proposed COMIC
signiﬁcantly outperforms general MLC, LT-MLC and
PL-MLC methods in terms of eﬀectiveness and robust-ness on our newly created PLT-MLC datasets.
1. Introduction
Images typically contain multiple objects and con-
cepts, highlighting the importance of multi-label clas-
siﬁcation (MLC) [ 35] for real-world tasks. Along with
the wide adoption of deep learning, recent MLC ap-
proaches have made remarkable progress in visual recog-
nition [37,39], but the performance is limited by two
common assumptions: all categories have comparable
numbers of instances andeach training instance has
been fully annotated with all the relevant labels . While
this conventional setting provides a perfect training
environment for various studies, it conceals a number
of complexities that typically arise in real-world appli-
cations:i)Long-Tailed (LT) Class Distribution.
With the growth of digital data, the crux of making
a large-scale dataset is no longer about where to col-
lect, but how to balance it [ 34]. However, the cost of
expanding the dataset to a larger class vocabulary with
balanced data is not linear — but exponential — since
the data is inevitably long-tailed following Zipf’s distri-
bution [31].ii)Partial Labels (PL) of Instances.
In the case of a large number of categories, it is diﬃ-
cult and even impractical to fully annotate all relevant
labels for each image [ 40,47,44]. Intuitively, humans
tend to focus on diﬀerent aspects of image contents due
tohuman bias ,i.e.,, their preference, personality and
sentiment [ 41], which indirectly aﬀects how and what
we annotate. In fact, LT and PL are often co-occurring,
and therefore, the MLC model must be suﬃciently ro-arXiv:2304.10539v1  [cs.LG]  20 Apr 2023#Instances
Category Index Frequent RarePartial Labeling Samples
 Fully Labeled Samples
Person Cat Do
gRabbitBike Antelope Tie Leopard Panda
Dog, Cat ✗ ✓Person      Tie Leopard, Antelope
✓ ✓
IterationsPerformanceHead Performance Degradation
Low Tail 
Performance
Tail 
PositiveTie
Head 
PositiveTail 
Positive
Tail 
NegativePerson
TiePerson
Tie≈ 32
1240
39
Dog, Cat, Horse…Inter -sample Intra -Sample
Negatives
Tie=78
Tie
178Decision BoundryOverview of MTL -MLC
 a
 bChallenges of MTL -MLC
IterationsPerformance
Decision Boundry
cOur Solution
Balanced LeaningMTL-MLC Data
Correction Modification Balance
MTL-MLC Data
Decrease Focal 
ofNegatives
Increase Focal 
ofPositive
Inter -Sample Focal Intra -Sample Focal Label Prior DistributionPerformance
PerformanceFigure 1: (a) illustrates an overview of the proposed PLT-MLC task. (b) depicts three key challenges of a PLT-MLC
task. (c) depicts a concise version of our proposed model for facilitating the PLT-MLC. (
 :positive,
:negative,
: falsenegative,
: corrected positive)
bust to handle diﬀerent data distributions and imperfect
datasets.
In this paper, we present a new challenge for MLC
at scale, Partial labeling and Long-Tailed Multi-Label
Classiﬁcation (PLT-MLC), with concomitant existence
of both PL setting [ 40] and LT distribution [ 34] prob-
lems. As captured in the overview of PLT-MLC in
Figure 1 (a), it has the following three challenges: i)
False Negative Training. Under the PL setting, the
MLC model treats the un-annotated labels (
 ) asneg-
atives(
), which may produce sub-optimal decision
boundary as it adds noise of false negative labels (Fig-
ure 1 (b)). The situation is further exacerbated in the
LT class distribution as some tailcategories are prone
to missing annotations in practice. For instance, in Fig-
ure 1 (a), “ person” is theheadclass in the PLT-MLC
dataset and is often notable in an image to labeling
for annotators. In contrast, the “ tie” often occupies a
tiny region in the scene compared with the “ person”.
The annotator may miss the “ tie” object, which will
aggravate the LT distribution and further increase the
diﬃculty of learning from tailclasses.ii) Head-Tail
and Positive-Negative Imbalance. There are two
imbalance issues in a PLT-MLC task: inter-instance
head-tailimbalance and intra-instance positive-negative
imbalance. As shown in Figure 1 (b), the inter-instance
ratio ofhead positive (
) “person” (
):tail positive
(
) “tie” (
)32under the LT data distribution, and
the intra-instance ratio of tail negative (
) categories
:tail positive (
)“tie” (
)= 78as an image only
contains a small fraction of the positivelabels. Con-
sequently, a robust PLT-MLC model should address
the co-occurring imbalances simultaneously. iii) Head
Overﬁtting and Tail Underﬁtting. Diﬀerent from
the general LT distribution, the classiﬁcation model
downplays the minor tailand overplays the major head.The PLT-MLC has an extreme LT distribution and
Figure 1(c) illustrates an interesting phenomenon of
MLC model learning: the general classiﬁcation model
is prone to overﬁtting to headclass with extensive sam-
ples and underﬁtting to tailclasses with a few samples.
This ﬁgure also indicates that only the medium class
shows a steady growth in performance, which means
that existing LT methods focusing on lifting up the
tailperformance may not solve the PLT-MLC problem
satisfactorily.
Suppose a trained model is used to correct the miss-
ing labels and then an LT classiﬁer is trained using the
updated labels, we might not be able to obtain a satis-
fying PLT-MLC performance, either. While machine
learning methods can easily detect the headsamples,
they may have diﬃculty in identifying the tailsamples.
As a result, the corrected labels may still exhibit an
LT distribution that inevitably hurts balanced learning.
Moreover, even when a general LT classiﬁer aﬀords the
trade-oﬀ to improve the tailperformance conditioned
on theheadperformance drop, it is still incapable of
simultaneously addressing the issue of headoverﬁtting
andtailunderﬁtting problem. Further, the decoupled
learning paradigm is impractical since it needs the “stop”
training and human “re-start” training, i.e., an end-to-
end learning scheme is more desirable. Thus, these
limitations motivate us to reconsider the solution for
the PLT-MLC task.
To this end, we propose an end-to-end PLT-MLC
framework: COrrection!ModiﬁcatIon!balanCe
(Figure 1), called COMIC , which progressively ad-
dresses the three key PLT-MLC challenges. Step 1:
TheCorrection module aims to gradually correct the
missing labels according to the predicted conﬁdence and
dynamically adjusts the classiﬁed loss of the corrected
samples under the real-time estimated class distribu-tion.Step 2: After the label correction, the Modiﬁ-
cationmodule introduces a novel Multi-Focal Modiﬁer
(MFM) Loss, which contains two focal factors to address
the two imbalance issues in PLT-MLC independently.
Motivated by [ 3], the ﬁrst is an intra-instance posi-
tive-negative factor that determines the concentration
of learning on hard negatives andpositives with dif-
ferent exponential decay factors. The second is an
inter-instance head-tailfactor that increases the impact
of rare categories, ensuring that the loss contribution of
rare samples will not be overwhelmed by frequent ones.
Step 3: Finally, the Balance module measures the
model’s optimization direction with a calculated mov-
ing average vector of the gradient over all past samples.
And thus, we devise a headmodel and a tailmodel
by subtracting or adding this moving vector, which
can respectively improve headandtailperformance.
Subsequently, a balanced classiﬁer deduces a balanced
learning eﬀect under the supervision of the headclas-
siﬁer and tailclassiﬁer. It protects the model training
from being too medium biased , and hence the balanced
classiﬁer is able to achieve the balanced learning schema.
Notably, our solution is an end-to-end learning frame-
work, which is re-training-free and eﬀectively enables
balanced prediction.
Our contributions are three-fold: (1) We present a
new challenging task: Partial labeling and Long-Tailed
Multi-Label Classiﬁcation (PLT-MLC), together with
two newly designed benchmarks: PLT-COCO and PLT-
VOC. (2) We propose an end-to-end PLT-MLC learning
framework, called COMIC, to eﬀectively perform the
PLT-MLC task as a progressive learning paradigm, i:e:,
Correction!Modiﬁcation!Balance. (3) Through an
extensive experimental study, we show that our method
improves all the prevalent LT and ML line-ups on PLT-
MLC benchmarks by a large margin.
2. Related Works
Long-Tailed MLC. Deep neural networks excel at
learning from large labeled datasets in computer vi-
sion [20,27,12,43,24,42,21] and natural language
processing tasks [ 9,14,18,29,23,41]. One of the
most popular task is Long-Tailed MLC, [ 38] is the
ﬁrst work that addresses the LT-MLC by extending the
re-balanced sampling and cost-sensitive re-weighting
methods. It proposes an optimized DB Focal method,
which does improve the recognition performance of tail
classes. Later work, [ 11] performs uniform and re-
balanced samplings from the same training set. Then a
two-branch network is developed to enforce the consis-
tency between two branches for collaborative learning
on both uniform and re-balanced samplings. However,
the above works require careful data initialization, i.e.,re-sampling, which is undesirable in practice. Moreover,
these methods have not yet considered the missing la-
beling case, which may not suﬃciently deal with the
PLT-MLC.
MLC with Partial Labels. Multi-label tasks often
involve incomplete training data, hence several methods
have been proposed to solve the problem of multi-label
learning with missing labels. A simple solution is to
treat the missing labels as negative labels [32,22,4].
However, performance will drop because a lot of ground-
truthpositivelabelsareinitializedas negative labels[15].
Current works on PL-MLC mainly focus on the design
of networks and training schemes. The common prac-
tice is to utilize the customized networks to learn label
correlations or classiﬁcation conﬁdence to realize cor-
rect recognition of missing labels [ 7,45]. However, the
corrected labels learned from a trained model are imbal-
anced due to the previous training dataset having an
LT distribution. Using such recall labels will aggravate
the LT distribution in the PLT-MLC dataset and result
in an imbalanced performance.
3. Methodology
This section describes the proposed PLT-MLC frame-
work. We will present each module and its training
strategy.
3.1. Problem Formulation
Before presenting our method, we ﬁrst intro-
duce some basic notions and terminologies. We
consider a partially annotated MLC dataset con-
tainsCclasses and Ni.i.d training samples S=
f(I(1);y(1));;(I(N);y(N))g, whereI(i)denoteith
image and label y(i)= [y(i)
1;;y(i)
c]2f0;1gC. For
a givenithexample and category c,y(i)
c= 0, 1 respec-
tively means the category is unknown and present. Our
proposed COMIC solves the PLT-MLC problem in an
end-to-end learning manner: Correction!Modiﬁca-
tion!Balance, withReﬂective Label Corrector (RLC,
in Sec.3.2), Multi-Focal Modiﬁer (MFM, in Sec.3.3) and
Head-Tail Balancer (HTB, in Sec.3.3), as illustrated in
Figure 2.
These three modules are designed to seek a balanced
modelMb(; b), parameterized by b, to predict the
presence or absence of each class given an input image.
We denotep= [p1;;pc]as the class prediction, com-
puted by the model: pc=(zc)whereis the sigmoid
function, and zcis the output logit corresponding to
classc. The optimized goal of COMIC can be deﬁned
as follows:
L((S); b)|{z}
COMIC Loss=cLrlc|{z}
RLC Loss+mLmfm|{z}
MFM Loss+bLhtb|{z}
HTB Loss(1)!!""#IterationLearning Rate
IterationLearning RateIterationLearning Rate
3Head-Tail Balancer
Head Learning Rate
AdditiveAttention
AdditiveAttentionBalanced Learning Rate
Tail Learning Rate
Estimated Distribution !
Label Prediction
Class-Specific ThresholdClass-Agnostic Threshold
Head-Tail Focal 
Label Correction
!$%&Reflective Label Corrector
3
2
1Multi-Focal ModifierPositive-Negative Focal
personpersonCupperson
Full Labeled
BackboneBackbone
BackboneHead ClassifierBalanced Classifier
Tail Classifier!!""#""
""##!""#""
!##!##
!'('MTL-MLC Data
mAP
ManyMediumFewtest datamAP
ManyMediumFewtest data
Legend
Multi-Focal Modifier  Loss
Positive SampleNegative SampleCorrectedPositive SampleLabel Correction Loss
!$%&!'('Head-Tail Balancer Loss
4
EmbeddingConcatenation
FalseNegative SamplePartial Labeled
catdogMTL-MLC DataHead PerformancemAPMedium
ManyFewtest datamAPMedium
ManyFewtest dataBalanced PerformanceTail Performance!!""#Figure 2:Overview of COMIC . RLC module ( Correction ) corrects the missing labels along with the training and
dynamically re-weights the sample weight according to the estimated class distribution. MFM module ( Modiﬁcation )
adjusts the focal of diﬀerent instances according to head-tailandpositive-negative imbalance under the extreme LT
distribution. HTB module ( Balance) measures the model’s optimization direction and correspondingly develops a
balanced learning scheme to produce stable PLT-MLC performance.
whereLrlc,LmfmandLhtbdenote the loss of RLC,
MFM and HTB, respectively. c,mandbare hyper-
parameters.
3.2. Reﬂective Label Corrector
Reﬂective Label Corrector (RLC) presents a real-
time label correction method for missing labels to al-
leviate the eﬀect of partially labeled samples. The
core idea is to examine the label likelihood pof each
training image and recall the labels with convinced pre-
diction conﬁdence during training. Interestingly, we
found that the model can distinguish a large number
of missing labels with high prediction conﬁdence in the
early training stage, which implies that we can recall
these missing labels during training to boost PTL-MLC
learning. Here, we ﬁrst deﬁne a threshold and then
check the input sample’s label likelihood pto check
whether it is greater than and then calculate the av-
erage category possibility Pcof past trained data with
classc. If predicted probabilities pcare highly conﬁdent,
i.e.,pc>maxf;Pcg, we regard that the sample misses
the label of class cand set a pseudo-label ^yc.
^yc=(
1;ifpc>maxf;Pcg;yc= 0
0;otherwise(2)Thus, the loss of RLC module, i.e.,Lrlcutilizes
the MFM loss (refer the details in Sec. 3.3) with these
corrected label ^yfor model training:
Lrlc(p)=(
L+
mfm(p); if^y= 1
1(y=1)L+
mfm(p)+1(^y=0)L 
mfm(p);otherwise
(3)
whereL+
mfm(p)andL 
mfm(p)refer to the generalized
MFM loss function for positives andnegatives . Notably,
we ﬁnd that most of the corrected labels belong to
headclass, which may aggravate the LT distribution.
To address this issue, we dynamically adjust the inter-
samplehead-tailfactor(i)
ht(details of this factor are
explained in Sec. 3.3) according to the dynamic class
distributionDt, which can increase the focal weight for
tailsamples. In addition, we also multiply Lrlc(p)by a
coeﬃcientBs
Ntin each training batch to constrain the
loss value, where Bsis the batch size and Ntis the
number of corrected labels.
Through this, RLC can gradually and dynamically
correct the potential missing labels during training,
which eﬃciently improves the classiﬁer’s performance
with recalled labels.3.3. Multi-Focal Modiﬁer
We ﬁrst revisit the focal loss [ 25], which is a widely-
used solution in the positive-negative imbalance prob-
lem. It redistributes the loss contribution of easy sam-
ples and hard samples, which greatly weakens the inﬂu-
ence of the majority of negative samples.
Lfl(p) =(
L+
fl= (1 p)log(p);ify= 1
L 
fl=plog(1 p);ify= 0(4)
whereis the focusing parameter, = 0 yields binary
cross-entropy. By setting > 0, the contribution of
easynegatives (with low probability, p 0.5) can be
down-weighted in the loss, enabling the model to focus
on harder samples.
However, the focal loss may not satisfactorily resolve
the PLT-MLC problem due to two key aspects:
•Tail Positive Gradient Elimination. When us-
ing focal loss for multi-label training, there is an
inner trade-oﬀ: high suﬃciently down-weights
thecontributionfromeasy negatives , butmayelimi-
nate the gradients from the tail positive samples [ 3].
•Head-Tail Imbalance. Imbalance among the
positivecategories also exists in MLC, i.e.,head
positive-tail positive imbalance. Rare categories
suﬀer more from severe imbalance issues than fre-
quent ones.
Thus, we propose a Multi-Focal Modiﬁer (MFM) loss
that decouples at two granularities of focal factors,
i.e., an intra-sample positive-negative (P-N) factor pn
and an inter-sample head-tail(H-T) factor ht.
(i)=(
(i)+=+
pn+w+(i)
ht;ify= 1
(i) = 
pn+w (i)
ht;ify= 0(5)
where(i)+and(i) control the focal of samples with
ithclass. Similar to [ 3],+
pnand 
pndecouple the
original decay rate as two factors, which respectively
control the focal of the positiveandnegative samples.
Since we are interested in emphasizing the contribution
ofpositive samples, we set  
pn+
pn. We achieve
better control over the contribution of positive and
negative samples through the designed loss function,
which assists the network to learn meaningful features
frompositive samples, despite their rarity. Another
focal factor (i)
htis a variable parameter ( 1) associated
with the imbalance degree of the ithclass. A bigger
value of(i)
htwill increase the weight of tailsamples
to encourage the model to pay more attention to the
positive tail samples, andviceversa. w+andw arethe
coeﬃcients that adjust the weight at a ﬁne-grained level.The(i)
htis the static class distribution Dof training set
with max normalization function  ()[30] to adjust the
head-tailfocal.
After applying the decoupled (i)+and(i) into
our MFM loss, we obtain the loss function as follows
(more discussions in the Appendix.):
Lmfm(p) =(
L+
mfm=PC
i=1(1 p)(i)+log(p);ify= 1
L 
mfm=PC
i=1p(i) log(1 p);ify= 0
(6)
By doing so, the MFM module utilizes the multi-
grained focal to alleviate the two imbalance problems in
the PLT-MLC task, yielding better classiﬁcation results.
3.4. Head-Tail Balancer
As discussed in the introduction, the extreme LT
dataset with numerous headsamples and a small num-
ber oftailsamples result in a headoverﬁtting and tail
underﬁtting learning eﬀect. Only the medium sam-
ples present a superior performance during training,
which fails to obtain the balanced performance for the
overall samples. To address this issue, we develop a
balanced strategy that measures the balanced learn-
ing eﬀect under the supervision of the headclassiﬁer
andtailclassiﬁer to achieve balanced results. Before
we delve into the balanced learning, we ﬁrst measure
the moving average of the gradient in the SGD-based
optimizer [33]:
et=et 1+ sum(gt);8t= 1;;T:(7)
where sum(gt)is the accumulated gradient at iteration
t,is the momentum decay. The average moving vector
etrecords the model’s optimization tendency by et 1
andsum(gt).
In our empirical study, we observe that only the
mediumsamples obtain a stable learning eﬀect from the
early to late training stage, mainly due to the extreme
LT distribution. To simulate the learning eﬀect towards
head/tailsamples, as depicted in Figure 2(c), we re-
duce/add the moving vector etat each step in head
modelMhandtailmodelMtrespectively, to assist
the balanced model Mbfor balanced learning. Notably,
we set diﬀerent learning rate decays for each model to
further explore the balanced learning eﬀect. The three
models are parallel-trained with their own backbone
and classiﬁer. In the feature learning stage, we develop
an additive attention [ 1] that computes the relevance of
balanced features ^fb, andheadfeaturesfh,tailfeatures
ftextracted from corresponding backbones.
fb= Attn( ^fb;[fh;ft])) + ^fb (8)
whereAttn()is the additive attention mechanism.Then updated fb,fh,ftare input to their classiﬁers to
obtain their logits. We develop the multi-head classiﬁer
with normalization [ 10,28,34], which has already been
embraced by various methods of empirical practice. The
multi-head strategy [ 36] equally divides the channel of
weights and features into Nggroups, which can be
considered as Ngtimes of ﬁne-grained sampling.
zx=
NgNgX
k=1w>
kfx
(jjwkjj+)jjfxjj;x2fh;t;bg(9)
whereis a scaling factor akin to the inverse tempera-
ture in Gibbs distribution, is a class-agnostic baseline
energy.wkis thekthlearned parameter matrix.
Subsequently, we measure the headandtaillearning
eﬀect by subtracting and adding the average moving
vectoretto the logits of headmodel and tailmodel,
respectively:
^zx=zx
NgNgX
k=1sim(zx;et)(wj)>et
jjwkjj+;x2fh;tg(10)
wheresim(;)measures the cosine similarity of vectors.
After obtaining the logits of ^zh,^ztandzb, the bal-
anced learning eﬀect needs to distill the headandtail
knowledge from ^zhand^ztto enable the stable learning
for all samples. Hence, we develop the head-tailloss:
Lhtb=hL((^zh)(zb)) +tL((^zt)(zb))
(11)
whereLisLmfmand()is softmax function. h
andtare adaptive weights for headandtaillearning
that calculated by h=(L( ^zh))
(L( ^zt))+(L( ^zh))andt=
(L( ^zt))
(L( ^zt))+(L( ^zh)), respectively. is a scaling factor and
we study its eﬀect in Sec. 4.3. Such loss can be regarded
as the empirical risk minimization (ERM) [ 6], which
adaptively distills the knowledge from the headand
tailmodels, enabling the balanced model is not biased
tomedium samples and produces a balanced learning
eﬀect for the PLT-MLC task.
4. Experiments
We verify COMIC’s eﬀectiveness on two proposed
PLT-MLC datasets and then discuss COMIC ’s proper-
ties with controlled studies.
4.1. Experimental Setup
Dataset Construction. The proposed method is an-
alyzed on the created LT versions of two MLC bench-
marks (COCO [ 26] and VOC [ 8]), called PLT-COCO and
PLT-VOC, respectively. The missing rate of PLT-COCO
is 40% and it contains 2,962 images from 80 classes.The maximum training number for each class is 1,240
and the minimum number is 6. We select 5000 images
from the test set of COCO2017 for evaluation. PLT-VOC
has the same missing rate setting and contains 2,569
images from 20 classes, in which the maximum training
number for each class is 1,117 and the minimum number
is 7. We evaluate the performance on VOC2007 test
set with 4,952 images. More details about the dataset
construction can be found in the Appendix.
Implementation Details. We employ the ResNet-
50 [13] as the backbone model to conduct the PLT-MLC
task. We train our model with a standard Adam [ 17]
optimizer in all the experiments. The images will be
randomly cropped and resized to 224 ×224 together
with standard data augmentation. Besides, we use
an identical set of hyperparameters ( B=32,Mo=0.9,
Emax=40 )1across all the datasets. More details of
implementation are in Appendix.
Evaluation Metrics. Following [ 38], we split these
classes into three groups according to the number of
their training examples: each headclass contains over
100 samples as a many shot, each medium class has
20 to 100 samples as a medium shot, and each tail
class has less than 20 samples as a low shot. The total
shot indicates all the test samples. We evaluate mean
average precision ( mAP) for all the classes and recall
for missing label settings.
Comparison of the Methods. To quantify the eﬃ-
cacy of the proposed framework, we use several base-
lines for performance comparison according to diﬀer-
ent aspects2. MLC methods: BCE [ 46], Focal [ 25],
ASL [3]. LT-MLC methods: DB [ 38], DB-Focal [ 38]
and LWS [ 16]. PL-MLC methods: Hill [ 45], Pseudo-
Label [19], ML-GCN [5] and P-ASL [2].
4.2. Overall Performance
Table 1 summarizes the quantitative PLT-MLC re-
sults of our framework and baselines on PLT-COCO
and PLT-VOC. We make the following observations:
1) In general, irrespective of the diﬀerent shot sce-
narios, compared to SoTAs, COMIC achieves the
best performance on almost all the metrics across
both datasets. In particular, COMIC outperforms
other baselines in terms of total shot’s mAP by a
large margin ( PLT-COCO :1.78%6.16%,PLT-VOC:
0.83%4.13%) for PLT-MLC task. 2) Besides, we
can observe from Table 1 that the LT methods out-
perform PL baselines in most X-shotsituations. We
believe the underlying reason behind this is that LT
1BandMorefer to the batch size and momentum in the
Adam.
2We only compare with the approaches that have open source
code.Table 1: Performance comparison of the proposed method and baselines on PLT-MLC datasets
(PLT-COCO andPLT-VOC).E2Eindicates that the PLT model is learned in an end-to-end manner. A larger score
has better performance. Improv. indicates performance improvement. Acronym notations of baselines can be found
in Sec. 4.1. We color each row as the best,second best andlowest score .
Category Methods E2EPLT-COCO Dataset PLT-VOC Dataset
Many Shot Medium Shot Few Shot Total Shot Many Shot Medium Shot Few Shot Total Shot
MLCBCE [46] /ok_sign42.570.11 56.670.19 46.400.60 48.920.23 67.370.18 88.270.39 83.790.41 78.790.14
Focal [25] /ok_sign41.050.07 58.330.12 53.580.31 51.390.15 67.020.11 87.490.18 82.820.78 78.130.23
ASL [3] /ok_sign41.600.17 58.150.15 52.670.17 51.200.08 67.670.10 87.790.13 82.230.55 78.350.11
LT-MLCDB [38] /ok_sign44.830.31 58.960.24 53.820.47 52.160.36 69.220.28 88.560.42 83.720.35 78.860.23
DB-Focal [38] /ok_sign45.760.25 59.740.21 53.850.16 52.570.27 68.960.22 88.890.18 83.420.20 78.900.26
LWS [16] -44.860.58 58.790.63 53.480.51 52.860.60 69.080.44 88.240.55 83.460.47 78.280.49
PL-MLCPseudo-Label [19] -41.410.41 57.460.35 53.120.33 51.670.37 67.380.24 87.580.35 83.260.42 78.320.30
ML-GCN [5] /ok_sign43.430.53 58.460.61 53.740.48 52.140.55 68.460.44 88.170.61 82.460.38 79.020.56
Hill [45] /ok_sign42.500.16 56.890.19 47.310.37 49.280.09 68.790.15 86.700.17 78.150.99 77.400.22
P-ASL [2] /ok_sign43.090.05 57.670.07 53.460.22 51.750.17 68.950.22 87.240.13 83.370.33 78.960.16
PLT-MLCHead Model (Ours) /ok_sign47.590.09 59.070.12 52.350.28 53.300.19 72.910.28 88.590.31 82.120.27 80.700.30
Tail Model (Ours) /ok_sign46.300.25 58.760.29 53.380.14 53.090.27 71.650.34 88.680.41 83.510.24 80.580.36
COMIC (Ours) /ok_sign49.210.2260.080.1355.360.2155.080.1473.100.3589.180.4584.530.4881.530.35
Table 2: Ablation study of diﬀerent modules.
M,C,B represent correction, modiﬁcation and balance
learning, respectively.
ModelsSetting PLT-COCO Dataset
M C B Total mAP Average mAP Recall
-RLC /ok_sign /ok_sign 54.700.13 54.420.15 85.260.08
-MFM /ok_sign /ok_sign 54.600.13 54.330.13 84.590.19
-HTB /ok_sign /ok_sign 53.650.31 53.360.31 84.190.23
COMIC /ok_sign /ok_sign /ok_sign 55.080.1454.880.1988.190.22
Table3:Performancecomparisonunderdiﬀerent
missinglabeledsettings. 0%indicatesanLTdataset
that is fully labeled.
Missing RatioPLT-COCO Dataset
Total Shot Many Shot Medium Shot Low Shot
0% 57.070.0952.210.1159.980.1261.120.24
30% 55.800.1749.970.1162.590.1554.560.17
40% 54.750.1948.930.2460.310.2154.140.21
50% 54.690.1548.740.1256.680.1657.250.24
data distribution hurts the classiﬁcation capability for
MLC models more seriously than PL. Besides, the la-
bel correction may have aggravated the LT issue and
further result in performance reduction. 3) Beneﬁting
from the carefully designed HTB module, our COMIC
not only achieves the highest total mAP score but also
yields balanced results with a narrowed performance
gap in diﬀerent shot metrics. These results demonstrate
the superiority of our proposed model.
(a) mAp of different α (b) mAp of different tau
Figure 3: Ablations with respect to coeﬃcient 
and.
(a) Performance Comparison of Losses (b) Loss VisualizationΔ2.32
Δ3.03
Figure 4: MLT-MLC results using diﬀerent
losses.
4.3. Ablation Study
Eﬀectiveness of Each Component. We conduct an
ablation study to illustrate the eﬀectiveness of each com-
ponent in Table 2. Comparing COMIC and COMIC(-
RLC) (Row 1 v.sRow 4), the label ( Correction ) mech-
anism contributes 0.38% improvement on total mAP.
The results of Row 2 show the mAP improvement ofEpochClass Index
(a) Number of TP and FP (b) Dynamic Distribution Heat MapFigure 5: In-depth analysis of label correction.
Table 4: Ablation of MFM. #indicates the mAP
decay.
MFM Factor PLT-COCO Dataset
P-N H-T Total Shot Many Shot Medium Shot Low Shot
/ok_sign54.44 (#0.64)48.65 (#0.56)60.00 (#0.08 )53.81 (#1.55 )
/ok_sign 53.70 (#1.38)48.38 (#0.83 )58.99 (#1.09 ) 52.91 (#2.45)
/ok_sign /ok_sign 55.08 49.21 60.08 55.36
the MFM ( Modiﬁcation ). Meanwhile, Row 3 indicates
that it suﬀers from noticeable performance degradation
without the ( Balance) learning. To sum up, we can
observe that the improvement of each module is distin-
guishable. Combining all the components, our COMIC
exhibits steady improvement over the baselines.
Ablation of Missing Rate. To study the eﬀect of
partial labels that aﬀect COMIC’s results, we evaluate
the performance under diﬀerent missing rates (MR) of
labels (from 0%50%). Not surprisingly, when the
MR decreases, the accuracy of COMIC increases on all
the metrics. We also ﬁnd that the performance gap
between diﬀerent shots is consistently small in all MR
settings. The results demonstrate the generalizability
of the proposed COMIC that it can produce stable and
balanced results under diﬀerent MR settings.
Hyperparameter and.We investigate the im-
pact of hyper-parameter andfor the PLT-MLC
task. The mAPs of diﬀerent hyper-parameter settings
onPLT-COCO are shown in Figure 3. This ﬁgure sug-
gests that the optimal choices of andare around 2
and0:7, respectively. Either increasing or decreasing
these values results in performance decay.
4.4. In-Depth Analysis
We further validate several vital issues of the pro-
posedCorrection!ModiﬁcatIon!Balance learning
paradigm by answering the three questions as follows.
Q1: Can the model trust the recalled labels distin-
guished by RLC? To build the insight on the eﬀective-
ness of the label correction mechanism in COMIC, we
visualize the true positive (TP) and false positive (FP)
in Figure 5(a)). This ﬁgure suggests that the RLC mod-Table 5:Results under static and dynamic distri-
bution.
DistributionPLT-COCO Dataset
Total Shot Many Shot Medium Shot Low Shot
Static 54.67 (0.41#)48.86 (0.35#)59.90 (0.18#)54.41 (1.15#)
Dynamic 55.08 49.21 60.08 55.56
ule can distinguish a large number of missing labels with
high prediction conﬁdence in the early training stage,
meanwhile, sum(TP) sum(FP). However, Figure 5(b)
of corrected samples also reveals LT class distribution
with respect to the original training set. To address this
issue, we dynamically adjust the sample weight condi-
tioned on the real-time distribution to produce a stable
performance. Table 5 reports results under diﬀerent
distributions, which shows that the mAP performance
decreases when using static weight conditioned on dy-
namic distribution, especially for the tailsamples. In
contrast, appropriately using these corrected labels with
a dynamic sample weight can eﬀectively improve the
PLT-MLC performance.
Q2: How does the MFM module aﬀect the PLT-MLC
performance? Here, we evaluate the eﬀectiveness of the
multi-focal modiﬁer (MFM) loss compared with diﬀer-
ent loss functions. Figure 4(a) shows the loss ablation
results using diﬀerent losses in our COMIC. Our devel-
oped MFM outperforms existing losses, as the designed
loss considers the key point of the head-tailandpositive-
negative imbalance under the extreme LT distribution
in the PLT-MLC task. There are two components in
MFM, which are the positive-negative (P-N) factor and
head-tail(H-T) factor. To demonstrate the eﬀect of
each component, we train the model with the individual
factor in the proposed MFM. As shown in Table. 4, both
the P-N factor and the H-T factor play signiﬁcant roles
inMFM.FortheH-Tfactor, itachievesanimprovement
from 53.7% mAP to 55.08% mAP. Meanwhile, it brings
a signiﬁcant gain on tailcategories with 2.45% mAP
improvement, indicating its eﬀectiveness to alleviate
the severe positive-negative imbalance problems in the
LT class distribution. As for the P-N factor, it brings
a steady boost on all shot settings which means it can
further alleviate the positive-negative issue. Addition-
ally, Figure 4(b) indicates that the MFM loss decreases
faster and smoother than the two variants of MFM
without diﬀerent factors, demonstrating its superiority
in the PLT-MLC task further.
Q3: How does the HTB module beneﬁt the balanced
learning? We systematically present the explicit bene-
ﬁts of the balanced learning strategy in multi-view. 1)
Figure 6 (a) and (b) show the comparison between sepa-
rate and joint training of head, balanced and tailmodel(a) Separate  Training (b) Joint  Training 
 (c) Head v.sTail (c) Loss Visualization
Figure 6: Analysis of balanced learning of COMIC. (a) and (b) depict the total mAP of separate and joint
training of COMIC within the 40 epochs. (c) summarizes the loss visualization of head, balanced and tail models with
joint training. (d) demonstrates headandtailmodels respectively optimize the headandtailclass’s performance.
with respect to the total mAP on PLT-COCO dataset. An
interesting phenomenon is that the detached head and
tailmodels slightly outperform the joint head andtail
models but suﬀer from an unstable performance. In con-
trast, the accuracy of the jointtrained balanced model
increases much faster and smoother than the detached
balanced model which also yields a stable performance
and faster convergence speed. This phenomenon is
reasonable as the main optimization objective in joint
trainingistoimprovethebalancedmodel’sperformance.
It can be regarded as the knowledge distillation eﬀect
that enables the balanced model to learn from the head
biasedandtail biased model, and this in turn facilitates
the PLT-MLC learning. 2) During the competition of
head v.s tail , theheadmodel’s loss drops faster (shown
in Figure 6 (c)) and is biased to optimizing the head
samples, while the tailmodel produces an opposite
result. Such headandtailbiased results form a foun-
dation that enables our COMIC to be trained in a
balanced and stable learning eﬀect. 3) We also perform
the analysis of the diﬀerent balanced learning blocks in
our COMIC. As presented in Table 6 (in the Appendix),
the DL, NC and AMV contribute 0.05%, 1.08% and
0.37% improvement on total shot mAP. The observa-
tions and analysis verify the eﬀectiveness of balanced
learning for being able to study from the headandtail
models, thereby achieving the PLT-MLC improvement.
5. Conclusions
We have presented a ﬁre-new task called PLT-MLC
and correspondingly developed a novel framework,
named COMIC. COMIC simultaneously addresses the
partial labeling and long-tailed environments in a Cor-
rection!Modiﬁcation!Balance learning manner.
On two newly proposed benchmarks, PLT-COCO and
PLT-VOC, we demonstrate that the proposed frame-
work signiﬁcantly outperforms existing MLC, LT-MLC
and PL-MLC approaches. Our proposed PLT-MLC
should serve as a complement to existing literature,providing new insights, and COMIC should serve as
the ﬁrst robust end-to-end baseline for the PLT-MLC
problem.
References
[1]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. Neural machine translation by jointly learning to
align and translate. arXiv preprint arXiv:1409.0473 ,
2014.
[2]Emanuel Ben-Baruch, Tal Ridnik, Itamar Friedman,
Avi Ben-Cohen, Nadav Zamir, Asaf Noy, and Lihi
Zelnik-Manor. Multi-label classiﬁcation with partial
annotations using class-aware selective loss. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 4764–4772, 2022.
[3] Emanuel Ben-Baruch, Tal Ridnik, Nadav Zamir, Asaf
Noy, Itamar Friedman, Matan Protter, and Lihi Zelnik-
Manor. Asymmetric loss for multi-label classiﬁcation.
arXiv preprint arXiv:2009.14119 , 2020.
[4]Serhat Selcuk Bucak, Rong Jin, and Anil K Jain. Multi-
label learning with incomplete class assignments. In
CVPR 2011 , pages 2801–2808. IEEE, 2011.
[5] Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yan-
wen Guo. Multi-label image recognition with graph con-
volutional networks. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition ,
pages 5177–5186, 2019.
[6]Michele Donini, Luca Oneto, Shai Ben-David, John S
Shawe-Taylor, and Massimiliano Pontil. Empirical risk
minimization under fairness constraints. Advances in
neural information processing systems , 31, 2018.
[7]Thibaut Durand, Nazanin Mehrasa, and Greg Mori.
Learning a deep convnet for multi-label classiﬁcation
with partial labels. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition ,
pages 647–657, 2019.
[8]Mark Everingham, Luc Van Gool, Christopher KI
Williams, John Winn, and Andrew Zisserman. The pas-
cal visual object classes (voc) challenge. International
journal of computer vision , 88(2):303–338, 2010.
[9]Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen
Arivazhagan, and Wei Wang. Language-agnostic bertsentence embedding. arXiv preprint arXiv:2007.01852 ,
2020.
[10]Spyros Gidaris and Nikos Komodakis. Dynamic few-
shot visual learning without forgetting. In Proceedings
of the IEEE conference on computer vision and pattern
recognition , pages 4367–4375, 2018.
[11]HaoGuoandSongWang. Long-tailedmulti-labelvisual
recognition by collaborative training on uniform and re-
balanced samplings. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recogni-
tion, pages 15089–15098, 2021.
[12]Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen,
Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao,
Chunjing Xu, Yixing Xu, et al. A survey on vision
transformer. IEEE transactions on pattern analysis
and machine intelligence , 45(1):87–110, 2022.
[13]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision
and pattern recognition , pages 770–778, 2016.
[14]Ganesh Jawahar, Benoît Sagot, and Djamé Seddah.
What does bert learn about the structure of language?
InACL 2019-57th Annual Meeting of the Association
for Computational Linguistics , 2019.
[15]Armand Joulin, Laurens van der Maaten, Allan Jabri,
and Nicolas Vasilache. Learning visual features from
large weakly supervised data. In European Conference
on Computer Vision , pages 67–84. Springer, 2016.
[16]Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng
Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis.
Decoupling representation and classiﬁer for long-tailed
recognition. arXiv preprint arXiv:1910.09217 , 2019.
[17]Diederik P Kingma and Jimmy Ba. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
[18]Kamran Kowsari, Kiana Jafari Meimandi, Mojtaba
Heidarysafa, Sanjana Mendu, Laura Barnes, and Don-
ald Brown. Text classiﬁcation algorithms: A survey.
Information , 10(4):150, 2019.
[19]Dong-Hyun Lee et al. Pseudo-label: The simple and ef-
ﬁcient semi-supervised learning method for deep neural
networks. In Workshop on challenges in representation
learning, ICML , volume 3, page 896, 2013.
[20]Juncheng Li, Xin Wang, Siliang Tang, Haizhou Shi,
Fei Wu, Yueting Zhuang, and William Yang Wang.
Unsupervised reinforcement learning of transferable
meta-skills for embodied navigation. In Proceedings of
the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 12123–12132, 2020.
[21]Juncheng Li, Junlin Xie, Linchao Zhu, Long Qian, Sil-
iang Tang, Wenqiao Zhang, Haochen Shi, Shengyu
Zhang, Longhui Wei, Qi Tian, et al. Dilated context
integrated network with cross-modal consensus for tem-
poral emotion localization in videos. arXiv preprint
arXiv:2208.01954 , 2022.
[22]Li-Jia Li and Li Fei-Fei. Optimol: automatic online
picture collection via incremental model learning. In-ternational journal of computer vision , 88(2):147–168,
2010.
[23]Mengze Li, Tianbao Wang, Haoyu Zhang, Shengyu
Zhang, Zhou Zhao, Jiaxu Miao, Wenqiao Zhang, Wen-
ming Tan, Jin Wang, Peng Wang, et al. End-to-
end modeling via information tree for one-shot nat-
ural language spatial video grounding. arXiv preprint
arXiv:2203.08013 , 2022.
[24]Mengze Li, Tianbao Wang, Haoyu Zhang, Shengyu
Zhang, Zhou Zhao, Wenqiao Zhang, Jiaxu Miao, Shil-
iang Pu, and Fei Wu. Hero: Hierarchical spatio-
temporal reasoning with contrastive action correspon-
dence for end-to-end video object grounding. In Pro-
ceedings of the 30th ACM International Conference on
Multimedia , pages 3801–3810, 2022.
[25]Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He,
and Piotr Dollár. Focal loss for dense object detection.
InProceedings of the IEEE international conference on
computer vision , pages 2980–2988, 2017.
[26]Tsung-Yi Lin, Michael Maire, Serge Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and
C Lawrence Zitnick. Microsoft coco: Common objects
in context. In European conference on computer vision ,
pages 740–755. Springer, 2014.
[27]Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei,
Zheng Zhang, Stephen Lin, and Baining Guo. Swin
transformer: Hierarchical vision transformer using
shifted windows. In Proceedings of the IEEE/CVF in-
ternational conference on computer vision , pages 10012–
10022, 2021.
[28]Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang,
Boqing Gong, and Stella X Yu. Large-scale long-tailed
recognition in an open world. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition , pages 2537–2546, 2019.
[29]Zheqi Lv, Zhengyu Chen, Shengyu Zhang, Kun Kuang,
WenqiaoZhang, MengzeLi, BengChinOoi, andFeiWu.
Ideal: Toward high-eﬃciency device-cloud collaborative
and dynamic recommendation system. arXiv preprint
arXiv:2302.07335 , 2023.
[30]SGOPAL Patro and Kishore Kumar Sahu. Nor-
malization: A preprocessing stage. arXiv preprint
arXiv:1503.06462 , 2015.
[31]William J Reed. The pareto, zipf and other power laws.
Economics letters , 74(1):15–19, 2001.
[32]Yu-Yin Sun, Yin Zhang, and Zhi-Hua Zhou. Multi-
label learning with weak label. In Twenty-fourth AAAI
conference on artiﬁcial intelligence , 2010.
[33]Ilya Sutskever, James Martens, George Dahl, and Ge-
oﬀrey Hinton. On the importance of initialization and
momentum in deep learning. In International confer-
ence on machine learning , pages 1139–1147. PMLR,
2013.
[34]Kaihua Tang, Jianqiang Huang, and Hanwang Zhang.
Long-tailed classiﬁcation by keeping the good and re-
moving the bad momentum causal eﬀect. Advances in
Neural Information Processing Systems , 33:1513–1524,
2020.[35]Grigorios Tsoumakas and Ioannis Katakis. Multi-label
classiﬁcation: An overview. International Journal of
Data Warehousing and Mining (IJDWM) , 3(3):1–13,
2007.
[36]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. Ad-
vances in neural information processing systems , 30,
2017.
[37]Jonatas Wehrmann, Ricardo Cerri, and Rodrigo Bar-
ros. Hierarchical multi-label classiﬁcation networks. In
International conference on machine learning , pages
5075–5084. PMLR, 2018.
[38]Tong Wu, Qingqiu Huang, Ziwei Liu, Yu Wang, and
Dahua Lin. Distribution-balanced loss for multi-label
classiﬁcation in long-tailed datasets. In European Con-
ference on Computer Vision , pages 162–178. Springer,
2020.
[39]Pengcheng Yang, Xu Sun, Wei Li, Shuming Ma, Wei
Wu, and Houfeng Wang. Sgm: sequence generation
model for multi-label classiﬁcation. arXiv preprint
arXiv:1806.04822 , 2018.
[40]Hsiang-Fu Yu, Prateek Jain, Purushottam Kar, and
Inderjit Dhillon. Large-scale multi-label learning with
missing labels. In International conference on machine
learning, pages 593–601. PMLR, 2014.
[41]Wenqiao Zhang, Haochen Shi, Jiannan Guo, Shengyu
Zhang, Qingpeng Cai, Juncheng Li, Sihui Luo, and
Yueting Zhuang. Magic: Multimodal relational graph
adversarial inference for diverse and unpaired text-
based image captioning. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence , volume 36, pages
3335–3343, 2022.
[42]Wenqiao Zhang, Haochen Shi, Siliang Tang, Jun Xiao,
Qiang Yu, and Yueting Zhuang. Consensus graph repre-
sentationlearningforbettergroundedimagecaptioning.
InProceedings of the AAAI Conference on Artiﬁcial
Intelligence , volume 35, pages 3394–3402, 2021.
[43]Wenqiao Zhang, Siliang Tang, Yanpeng Cao, Shiliang
Pu, Fei Wu, and Yueting Zhuang. Frame augmented
alternating attention network for video question an-
swering.IEEE Transactions on Multimedia , 22(4):1032–
1041, 2019.
[44]Wenqiao Zhang, Lei Zhu, James Hallinan, Shengyu
Zhang, AndrewMakmur, QingpengCai, andBengChin
Ooi. Boostmis: Boosting medical image semi-
supervised learning with adaptive pseudo labeling and
informative active annotation. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition , pages 20666–20676, 2022.
[45]Youcai Zhang, Yuhao Cheng, Xinyu Huang, Fei Wen,
Rui Feng, Yaqian Li, and Yandong Guo. Simple and
robust loss design for multi-label learning with missing
labels.arXiv preprint arXiv:2112.07368 , 2021.
[46]Zhilu Zhang and Mert Sabuncu. Generalized cross
entropy loss for training deep neural networks with
noisy labels. Advances in neural information processing
systems, 31, 2018.[47]Pengfei Zhu, Qian Xu, Qinghua Hu, Changqing Zhang,
and Hong Zhao. Multi-label feature selection with
missing labels. Pattern Recognition , 74:488–502, 2018."
